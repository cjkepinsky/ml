{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'libs'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/r3/hdngxsmd2vq391vqv6kg6f7w0000gq/T/ipykernel_38259/184915573.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Let's run the preprocessing on both train and test data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mlibs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimple_processing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseparate_target\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropna_rows\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremove_columns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m \u001b[0;31m# data processing, CSV file I/O (e.g. pd.read_csv)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mconstants\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msource_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'libs'"
     ]
    }
   ],
   "source": [
    "# Let's run the preprocessing on both train and test data\n",
    "from libs.simple_processing import normalize, separate_target, dropna_rows, remove_columns\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from constants import source_path, target_name, x_path, y_path\n",
    "\n",
    "DATA = pd.read_csv(source_path)\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# embedding = reducer.fit_transform(DATA)\n",
    "# # embedding.shape\n",
    "# plt.scatter(\n",
    "#     embedding[:, 0],\n",
    "#     embedding[:, 1],\n",
    "#     c=[sns.color_palette()[i] for i in DATA[target_name]])\n",
    "# # c=[sns.color_palette()[i] for i in DATA[target_name].map({\"Adelie\":0, \"Chinstrap\":1, \"Gentoo\":2})])\n",
    "# plt.gca().set_aspect('equal', 'datalim')\n",
    "# plt.title('UMAP projection', fontsize=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# DATA = remove_columns(DATA, ['citric acid'])\n",
    "# DATA = remove_columns(DATA, ['density'])\n",
    "# DATA = remove_columns(DATA, ['pH'])\n",
    "\n",
    "\n",
    "X, y = separate_target(DATA, target_name)\n",
    "X = dropna_rows(X, X.columns)\n",
    "\n",
    "# Data Normalization\n",
    "X = normalize(X)\n",
    "\n",
    "# Data Categorization\n",
    "# from libs.simple_processing import categorize\n",
    "# X_train, X_valid = categorize(X_train, X_valid)\n",
    "# print(\"Done\")\n",
    "\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Dimension reduction\n",
    "# import umap\n",
    "# import umap.plot\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "# from babyplots import Babyplot\n",
    "#\n",
    "# reducer = umap.UMAP(random_state=42)\n",
    "# embedding = reducer.fit_transform(X)\n",
    "# print(embedding.shape)\n",
    "# print(embedding)\n",
    "\n",
    "# reducer3d = umap.UMAP(random_state=42, n_components=3)\n",
    "# embedding3d = reducer3d.fit_transform(X)\n",
    "# bp = Babyplot()\n",
    "# bp.add_plot(\n",
    "#     embedding3d.tolist(),\n",
    "#     \"pointCloud\",\n",
    "#     \"categories\",\n",
    "#     y.values.tolist(),\n",
    "#     {\n",
    "#         \"colorScale\": \"Set2\",\n",
    "#         \"showLegend\": True,\n",
    "#         \"folded\": True,\n",
    "#         \"foldedEmbedding\": embedding.tolist()\n",
    "#     })\n",
    "# html = bp.save_as_html('./babyplot.html')\n",
    "\n",
    "print(\"Done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# import umap\n",
    "# import matplotlib.pyplot as plt\n",
    "#\n",
    "# # %%time\n",
    "# X_reduced = umap.UMAP(n_neighbors=5).fit(X)\n",
    "#\n",
    "# plt.scatter(X_reduced.embedding_[:, 0], X_reduced.embedding_[:, 1], s=5, c=y, cmap='Spectral')\n",
    "# plt.title('Embedding of the training set by UMAP', fontsize=24)\n",
    "#\n",
    "# X_reduced = X_reduced.embedding_\n",
    "# print(X_reduced)\n",
    "# umap.plot.points(mapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from libs.simple_processing import categorize_train_valid_test, train_test_split, categorize\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from libs.simple_hyper_tuner import predict_print_valid_scores\n",
    "from libs.simple_hyper_tuner import gridsearchcv_tuner\n",
    "import umap\n",
    "from sklearn import decomposition\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "import numpy as np\n",
    "\n",
    "splitter_params  = {'train_size': [0.8], 'random_state': [50]}\n",
    "target_dimensions = 8\n",
    "n_neighbors = 10\n",
    "\n",
    "params = [\n",
    "    # {   # F1 score:  0.6971766576002016\n",
    "    #     'splitter': splitter_params, 'cv': [2],\n",
    "    #     'model': GradientBoostingClassifier(\n",
    "    #         n_estimators=400, random_state=0, learning_rate=0.025, max_depth=5, max_features=\"auto\"),\n",
    "    #     'hyperparams': {},\n",
    "    #     'reducer': {}\n",
    "    # },\n",
    "    # {   # F1 score:  0.7174454442827287\n",
    "    #     'splitter': splitter_params, 'cv': [2],\n",
    "    #     'model': GradientBoostingClassifier(\n",
    "    #         n_estimators=1400, learning_rate=0.005, random_state=0, max_depth=5, max_features=\"auto\"),\n",
    "    #     'hyperparams': {},\n",
    "    #     'reducer': decomposition.PCA(n_components='mle')\n",
    "    # },\n",
    "    # {   # F1 score:  0.6705686795994994\n",
    "    #     'splitter': splitter_params, 'cv': [2],\n",
    "    #     'model': GradientBoostingClassifier(\n",
    "    #         n_estimators=400, random_state=0, learning_rate=0.025, max_depth=5, max_features=\"auto\"),\n",
    "    #     'hyperparams': {},\n",
    "    #     'reducer': umap.UMAP(n_components=10, n_epochs=500, learning_rate=0.001)\n",
    "    # },\n",
    "    {   # F1 score:  0.7174454442827287\n",
    "        'splitter': splitter_params, 'cv': [5],\n",
    "        'model': XGBClassifier(n_estimators=100),\n",
    "        'hyperparams': {},\n",
    "        'reducer': decomposition.PCA(n_components='mle')\n",
    "    },\n",
    "    {   # F1 score:  0.6705686795994994\n",
    "        'splitter': splitter_params, 'cv': [5],\n",
    "        'model': XGBClassifier(n_estimators=100),\n",
    "        'hyperparams': {},\n",
    "        'reducer': umap.UMAP(n_components=10, n_epochs=500, learning_rate=0.001)\n",
    "    },\n",
    "    # {   # F1 score:  0.7068835486322189\n",
    "    #     'splitter': splitter_params, 'cv': [2],\n",
    "    #     'model': GradientBoostingClassifier(\n",
    "    #         n_estimators=1400, random_state=0, learning_rate=0.025, max_depth=5, max_features=\"auto\"),\n",
    "    #     'hyperparams': {'learning_rate': np.arange(0.005, 0.025, 0.05)},\n",
    "    #     'reducer': decomposition.PCA(n_components='mle')\n",
    "    # },\n",
    "\n",
    "    # {\n",
    "    #     'splitter': splitter_params, 'cv': [2],\n",
    "    #     'model': GradientBoostingClassifier(\n",
    "    #         n_estimators=400, random_state=0, learning_rate=0.025, max_depth=5, max_features=\"auto\"),\n",
    "    #     'hyperparams': {},\n",
    "    #     'reducer': umap.UMAP(n_components=10)\n",
    "    # },\n",
    "    # {\n",
    "    #     'splitter': splitter_params, 'cv': [2],\n",
    "    #     'model': GradientBoostingClassifier(\n",
    "    #         n_estimators=400, random_state=0, learning_rate=0.025, max_depth=5, max_features=\"auto\"),\n",
    "    #     'hyperparams': {},\n",
    "    #     'reducer': umap.UMAP(n_components=10, n_epochs=500, learning_rate=0.025)\n",
    "    # },\n",
    "    # {   # F1 score:  0.6493902043719906\n",
    "    #     'splitter': splitter_params, 'cv': [2],\n",
    "    #     'model': GradientBoostingClassifier(\n",
    "    #         n_estimators=400, random_state=0, learning_rate=0.025, max_depth=5, max_features=\"auto\"),\n",
    "    #     'hyperparams': {},\n",
    "    #     'reducer': umap.UMAP(n_components=10, n_epochs=1000, learning_rate=0.001)\n",
    "    # },\n",
    "    # {\n",
    "    #     'splitter': splitter_params, 'cv': [2],\n",
    "    #     'model': GradientBoostingClassifier(\n",
    "    #         n_estimators=400, random_state=0, learning_rate=0.025, max_depth=5, max_features=\"auto\"\n",
    "    #     ),\n",
    "    #     'hyperparams': {},\n",
    "    #     'reducer': umap.UMAP(n_neighbors=n_neighbors, n_components=target_dimensions),\n",
    "    # },\n",
    "    # {\n",
    "    #     'splitter': splitter_params, 'cv': [2],\n",
    "    #     'model': svm.SVC(\n",
    "    #         # kernel=\"poly\"\n",
    "    #         # , decision_function_shape=\"ovr\"\n",
    "    #         # , C=1\n",
    "    #         # , probability=True\n",
    "    #     ),\n",
    "    #     'hyperparams': {},\n",
    "    #     'reducer': umap.UMAP(n_neighbors=n_neighbors, n_components=target_dimensions),\n",
    "    # },\n",
    "    # {\n",
    "    #     'splitter': splitter_params, 'cv': [2],\n",
    "    #     'model': svm.LinearSVC(max_iter=1000),\n",
    "    #     'hyperparams': {},\n",
    "    #     'reducer': umap.UMAP(n_neighbors=n_neighbors, n_components=target_dimensions),\n",
    "    # },\n",
    "    #\n",
    "    # {   # F1 score:  0.5226810499043859\n",
    "    #     'splitter': splitter_params, 'cv': [2],\n",
    "    #     'model': AdaBoostClassifier(n_estimators=1500, random_state=50),\n",
    "    #     'hyperparams': {},\n",
    "    #     'reducer': decomposition.PCA(n_components='mle')\n",
    "    # },\n",
    "    # {   # F1 score:  0.5167932412790698\n",
    "    #     'splitter': splitter_params, 'cv': [4],\n",
    "    #     'model': AdaBoostClassifier(),\n",
    "    #     'hyperparams': {},\n",
    "    #     'reducer': umap.UMAP(n_neighbors=n_neighbors, n_components=target_dimensions)\n",
    "    # },\n",
    "    # {\n",
    "    #     'splitter': splitter_params, 'cv': [4],\n",
    "    #     'model': LogisticRegression(max_iter=1000),\n",
    "    #     'hyperparams': {},\n",
    "    #     'reducer': decomposition.PCA(n_components=target_dimensions)\n",
    "    # },\n",
    "    # {\n",
    "    #     'splitter': splitter_params, 'cv': [4],\n",
    "    #     'model': LogisticRegression(max_iter=1000),\n",
    "    #     'hyperparams': {},\n",
    "    #     'reducer': umap.UMAP(n_neighbors=n_neighbors, n_components=target_dimensions)\n",
    "    # },\n",
    "    # {\n",
    "    #     'splitter': splitter_params, 'cv': [2],\n",
    "    #     'model': GaussianNB(),\n",
    "    #     'hyperparams': {},\n",
    "    #     'reducer': decomposition.PCA(n_components=7)\n",
    "    # },\n",
    "    # {\n",
    "    #     'splitter': splitter_params, 'cv': [2],\n",
    "    #     'model': GaussianNB(),\n",
    "    #     'hyperparams': {},\n",
    "    #     'reducer': umap.UMAP(n_neighbors=10, n_components=7)\n",
    "    # },\n",
    "    # {\n",
    "    #     'splitter': splitter_params, 'cv': [2],\n",
    "    #     'model': GradientBoostingClassifier(\n",
    "    #         n_estimators=400, random_state=0, learning_rate=0.025, max_depth=5, max_features=\"auto\"\n",
    "    #     ),\n",
    "    #     'hyperparams': {},\n",
    "    #     'reducer': decomposition.PCA(n_components=6)\n",
    "    # },\n",
    "    # {\n",
    "    #     'splitter': splitter_params, 'cv': [2],\n",
    "    #     'model': GradientBoostingClassifier(\n",
    "    #         n_estimators=400, random_state=0, learning_rate=0.025, max_depth=5, max_features=\"auto\"\n",
    "    #     ),\n",
    "    #     'hyperparams': {},\n",
    "    #     'reducer': decomposition.PCA(n_components=target_dimensions)\n",
    "    # },\n",
    "    # {\n",
    "    #     'splitter': splitter_params, 'cv': [2],\n",
    "    #     'model': XGBClassifier(),\n",
    "    #     'hyperparams': {},\n",
    "    #     'reducer': decomposition.PCA(n_components=target_dimensions)\n",
    "    # },\n",
    "    # {\n",
    "    #     'splitter': splitter_params, 'cv': [2],\n",
    "    #     'model': svm.SVC(\n",
    "    #         # kernel=\"poly\"\n",
    "    #         # , decision_function_shape=\"ovr\"\n",
    "    #         # , C=1\n",
    "    #         # , probability=True\n",
    "    #     ),\n",
    "    #     'hyperparams': {},\n",
    "    #     'reducer': decomposition.PCA(n_components=target_dimensions)\n",
    "    # },\n",
    "    # {\n",
    "    #     'splitter': splitter_params, 'cv': [2],\n",
    "    #     'model': svm.LinearSVC(max_iter=1000),\n",
    "    #     'hyperparams': {},\n",
    "    #     'reducer': decomposition.PCA(n_components=target_dimensions)\n",
    "    # }\n",
    "]\n",
    "\n",
    "winner = gridsearchcv_tuner(X, y, params, 0, False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X.to_csv(x_path)\n",
    "y.to_csv(y_path)\n",
    "\n",
    "print(\"Done\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
