{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": "   Unnamed: 0        RI        Na        Mg        Al        Si         K  \\\n0           0  0.432836  0.437594  1.000000  0.252336  0.351786  0.009662   \n1           1  0.283582  0.475188  0.801782  0.333333  0.521429  0.077295   \n2           2  0.220808  0.421053  0.790646  0.389408  0.567857  0.062802   \n3           3  0.285777  0.372932  0.821826  0.311526  0.500000  0.091787   \n4           4  0.275241  0.381955  0.806236  0.295950  0.583929  0.088567   \n\n         Ca   Ba   Fe  \n0  0.308550  0.0  0.0  \n1  0.223048  0.0  0.0  \n2  0.218401  0.0  0.0  \n3  0.259294  0.0  0.0  \n4  0.245353  0.0  0.0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>RI</th>\n      <th>Na</th>\n      <th>Mg</th>\n      <th>Al</th>\n      <th>Si</th>\n      <th>K</th>\n      <th>Ca</th>\n      <th>Ba</th>\n      <th>Fe</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0.432836</td>\n      <td>0.437594</td>\n      <td>1.000000</td>\n      <td>0.252336</td>\n      <td>0.351786</td>\n      <td>0.009662</td>\n      <td>0.308550</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>0.283582</td>\n      <td>0.475188</td>\n      <td>0.801782</td>\n      <td>0.333333</td>\n      <td>0.521429</td>\n      <td>0.077295</td>\n      <td>0.223048</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>0.220808</td>\n      <td>0.421053</td>\n      <td>0.790646</td>\n      <td>0.389408</td>\n      <td>0.567857</td>\n      <td>0.062802</td>\n      <td>0.218401</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>0.285777</td>\n      <td>0.372932</td>\n      <td>0.821826</td>\n      <td>0.311526</td>\n      <td>0.500000</td>\n      <td>0.091787</td>\n      <td>0.259294</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>0.275241</td>\n      <td>0.381955</td>\n      <td>0.806236</td>\n      <td>0.295950</td>\n      <td>0.583929</td>\n      <td>0.088567</td>\n      <td>0.245353</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from constants import source_path, target_name, x_path, y_path\n",
    "import pandas as pd  # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from libs.simple_hyper_tuner import gridsearchcv_tuner\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn import svm\n",
    "import numpy as np # linear algebra\n",
    "\n",
    "cv = [2]\n",
    "random_state = [50]\n",
    "train_size = [0.8]\n",
    "\n",
    "X = pd.read_csv(x_path)\n",
    "y = pd.read_csv(y_path)[target_name]\n",
    "\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Model: SVC\n",
      "- Accuracy score:  0.8837209302325582\n",
      "- Accuracy count:  38 / 43\n",
      "- Precision score:  0.9147286821705425\n",
      "- Recall score:  0.8837209302325582\n",
      "- F1 score:  0.8848343359971267\n",
      "GridSearchCV Training Results:\n",
      "- Best Score:  0.9238714090287278\n",
      "Params:\n",
      "- cv:  2\n",
      "- Splitter Params:  {'train_size': 0.8, 'random_state': 50}\n",
      "- Model Params:  SVC()\n",
      "- Best H-Params:  {'decision_function_shape': 'ovr', 'kernel': 'poly'}\n",
      "\n",
      "Done.\n"
     ]
    },
    {
     "data": {
      "text/plain": "SVC(kernel='poly')"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = [\n",
    "    {   # Binary or Multiclass - One-Vs-One and One-vs-Rest\n",
    "        # https://www.baeldung.com/cs/svm-multiclass-classification\n",
    "        'splitter': {'train_size': train_size, 'random_state': random_state},\n",
    "        'cv': cv,\n",
    "        'model': svm.SVC(),\n",
    "        'hyperparams': {\n",
    "            'decision_function_shape': ['ovr', 'ovo']\n",
    "            , 'kernel': ['rbf', 'poly']\n",
    "            # , 'shrinking': [True, False]\n",
    "            # , 'coef0': [0, 0.2, 0.4]\n",
    "            # , 'gamma' : ['scale', 'auto']\n",
    "            # , 'degree': [1, 2, 3, 4, 5]\n",
    "            # , 'C': [1, 0.1, 0.4, 0.7, 1.2]\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "gridsearchcv_tuner(X, y, params, 1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Model: LinearRegression\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of multiclass and continuous targets",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[0;32m/var/folders/r3/hdngxsmd2vq391vqv6kg6f7w0000gn/T/ipykernel_94410/867121118.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     10\u001B[0m ]\n\u001B[1;32m     11\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 12\u001B[0;31m \u001B[0mgridsearchcv_tuner\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mparams\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m~/git/python/libs/simple_hyper_tuner.py\u001B[0m in \u001B[0;36mgridsearchcv_tuner\u001B[0;34m(X, y, params, verbose)\u001B[0m\n\u001B[1;32m    185\u001B[0m                     \u001B[0mgrid_model\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX_train\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my_train\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    186\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 187\u001B[0;31m                     \u001B[0mf1\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mpredict_print_valid_scores\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mgrid_model\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mX_valid\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my_valid\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mverbose\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    188\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    189\u001B[0m                     \u001B[0;32mif\u001B[0m \u001B[0mverbose\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/git/python/libs/simple_hyper_tuner.py\u001B[0m in \u001B[0;36mpredict_print_valid_scores\u001B[0;34m(model, X_valid, y_valid, verbose)\u001B[0m\n\u001B[1;32m    212\u001B[0m     \u001B[0my_pred\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mmodel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpredict\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX_valid\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    213\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mverbose\u001B[0m \u001B[0;34m>\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 214\u001B[0;31m         \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'- Accuracy score: '\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0maccuracy_score\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0my_valid\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my_pred\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnormalize\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    215\u001B[0m         \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'- Accuracy count: '\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0maccuracy_score\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0my_valid\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my_pred\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnormalize\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mFalse\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'/'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my_pred\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    216\u001B[0m         \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'- Precision score: '\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mprecision_score\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0my_valid\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my_pred\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0maverage\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m'weighted'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\u001B[0m in \u001B[0;36maccuracy_score\u001B[0;34m(y_true, y_pred, normalize, sample_weight)\u001B[0m\n\u001B[1;32m    209\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    210\u001B[0m     \u001B[0;31m# Compute accuracy for each possible representation\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 211\u001B[0;31m     \u001B[0my_type\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my_true\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my_pred\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0m_check_targets\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0my_true\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my_pred\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    212\u001B[0m     \u001B[0mcheck_consistent_length\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0my_true\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my_pred\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msample_weight\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    213\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0my_type\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstartswith\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"multilabel\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\u001B[0m in \u001B[0;36m_check_targets\u001B[0;34m(y_true, y_pred)\u001B[0m\n\u001B[1;32m     91\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     92\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0my_type\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m>\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 93\u001B[0;31m         raise ValueError(\n\u001B[0m\u001B[1;32m     94\u001B[0m             \"Classification metrics can't handle a mix of {0} and {1} targets\".format(\n\u001B[1;32m     95\u001B[0m                 \u001B[0mtype_true\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtype_pred\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mValueError\u001B[0m: Classification metrics can't handle a mix of multiclass and continuous targets"
     ]
    }
   ],
   "source": [
    "params = [\n",
    "    {\n",
    "        'splitter': {'train_size': train_size, 'random_state': random_state},\n",
    "        'cv': cv,\n",
    "        'model': LinearRegression(copy_X=True),\n",
    "        'hyperparams': {\n",
    "            # 'fit_intercept': [True, False]\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "gridsearchcv_tuner(X, y, params, 1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Model: RandomForestClassifier\n",
      "- Accuracy score:  1.0\n",
      "- Accuracy count:  43 / 43\n",
      "- Precision score:  1.0\n",
      "- Recall score:  1.0\n",
      "- F1 score:  1.0\n",
      "GridSearchCV Training Results:\n",
      "- Best Score:  0.9589603283173734\n",
      "Params:\n",
      "- cv:  2\n",
      "- Splitter Params:  {'train_size': 0.8, 'random_state': 50}\n",
      "- Model Params:  RandomForestClassifier()\n",
      "- Best H-Params:  {}\n",
      "\n",
      "Done.\n"
     ]
    },
    {
     "data": {
      "text/plain": "RandomForestClassifier()"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = [\n",
    "    {\n",
    "        'splitter': {'train_size': train_size, 'random_state': random_state},\n",
    "        'cv': cv,\n",
    "        'model': RandomForestClassifier(\n",
    "            # max_depth=6, max_features=\"auto\", max_samples=70, bootstrap=True, oob_score=True, random_state=0\n",
    "            # , criterion='entropy', n_estimators=110\n",
    "            # , warm_start=True\n",
    "        ),\n",
    "        'hyperparams': {\n",
    "            # 'warm_start':[True, False]\n",
    "            # 'criterion': [\"gini\", \"entropy\"]\n",
    "                    # 'max_features':[\"auto\", \"sqrt\", \"log2\"]\n",
    "                    # , 'max_samples': range(50, 80, 5)\n",
    "                    # , 'n_estimators': range(80, 150, 10)\n",
    "                    # 'random_state': range(0, 50, 10)\n",
    "                    # , 'max_depth': range(4, 8, 1)\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "gridsearchcv_tuner(X, y, params, 1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Model: XGBClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kkepins-macwro/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/kkepins-macwro/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/kkepins-macwro/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/kkepins-macwro/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/kkepins-macwro/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/kkepins-macwro/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/kkepins-macwro/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/kkepins-macwro/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/kkepins-macwro/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/kkepins-macwro/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/kkepins-macwro/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/kkepins-macwro/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/kkepins-macwro/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/kkepins-macwro/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/kkepins-macwro/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/kkepins-macwro/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/kkepins-macwro/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/kkepins-macwro/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/kkepins-macwro/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/kkepins-macwro/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/kkepins-macwro/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/kkepins-macwro/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/kkepins-macwro/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/kkepins-macwro/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/kkepins-macwro/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:38:41] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "- Accuracy score:  0.9302325581395349\n",
      "- Accuracy count:  40 / 43\n",
      "- Precision score:  0.936046511627907\n",
      "- Recall score:  0.9302325581395349\n",
      "- F1 score:  0.9313881265347392\n",
      "GridSearchCV Training Results:\n",
      "- Best Score:  0.9884033613445379\n",
      "Params:\n",
      "- cv:  5\n",
      "- Splitter Params:  {'train_size': 0.8, 'random_state': 50}\n",
      "- Model Params:  XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None)\n",
      "- Best H-Params:  {'n_estimators': 5}\n",
      "\n",
      "Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kkepins-macwro/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n              colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n              gamma=0, gpu_id=-1, importance_type=None,\n              interaction_constraints='', learning_rate=0.300000012,\n              max_delta_step=0, max_depth=6, min_child_weight=1, missing=nan,\n              monotone_constraints='()', n_estimators=5, n_jobs=8,\n              num_parallel_tree=1, objective='multi:softprob', predictor='auto',\n              random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=None,\n              subsample=1, tree_method='exact', validate_parameters=1,\n              verbosity=None)"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "params = [\n",
    "    {\n",
    "        'splitter': {'train_size': train_size, 'random_state': random_state},\n",
    "        'cv': [5],\n",
    "        'model': XGBClassifier(\n",
    "            # n_estimators=70, learning_rate=0.08, max_depth=8,\n",
    "            # use_label_encoder=False\n",
    "            # , num_parallel_tree=10\n",
    "            # , min_samples_leaf=1, min_samples_split=3\n",
    "            #   use_label_encoder=False, eval_metric='error'\n",
    "            # , max_leaf_nodes=1, validation_fraction=0\n",
    "            # , tol=0, ccp_alpha=0, n_iter_no_change=1\n",
    "        ),\n",
    "        'hyperparams': {\n",
    "            'n_estimators':range(1, 10, 2)\n",
    "            # 'min_samples_split':np.arange(3, 6, 1),\n",
    "            # 'min_samples_leaf':np.arange(1, 4, 1),\n",
    "            # 'subsample':np.arange(0.6, 0.9, 0.1),\n",
    "            # 'criterion': ['friedman_mse', 'squared_error'],\n",
    "            # , 'max_depth': range(5, 9, 1)\n",
    "            # , 'learning_rate':np.arange(0.09, 0.13, 0.01)\n",
    "            # , 'min_weight_fraction_leaf':np.arange(0, 0.14, 0.02)\n",
    "            # , 'min_impurity_decrease':np.arange(0, 0.14, 0.02)\n",
    "            # 'max_leaf_nodes':range(1, 7, 1)\n",
    "            # , 'warm_start': [True, False]\n",
    "            # 'validation_fraction': np.arange(0, 0.005, 0.001)\n",
    "            # 'tol': np.arange(0, 0.005, 0.001)\n",
    "            # 'ccp_alpha': np.arange(0, 0.005, 0.001)\n",
    "            # 'n_iter_no_change':range(1, 7, 1)\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "gridsearchcv_tuner(X, y, params, 1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}