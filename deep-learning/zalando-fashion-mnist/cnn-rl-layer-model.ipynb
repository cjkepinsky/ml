{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "version": "3.6.4",
   "file_extension": ".py",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "name": "python",
   "mimetype": "text/x-python"
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "from subprocess import check_output\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import TensorBoard\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "num_classes = 10\n",
    "epochs = 20\n",
    "\n",
    "train_df = pd.read_csv('./input/fashion-mnist_train.csv', sep=',')\n",
    "test_df = pd.read_csv('./input/fashion-mnist_test.csv', sep = ',')\n",
    "\n",
    "# print(check_output([\"ls\", \"./input\"]).decode(\"utf8\"))\n",
    "print(train_df.head())\n",
    "print(train_df.shape)\n"
   ],
   "metadata": {
    "_cell_guid": "dec05004-ccb3-490e-b588-27c0f4f06d1e",
    "_uuid": "41907ec74cae883fa8d56f6556cade5c67c8f3e0",
    "_kg_hide-input": true,
    "trusted": true
   },
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fashion-mnist_test.csv\n",
      "fashion-mnist_train.csv\n",
      "t10k-images-idx3-ubyte\n",
      "t10k-labels-idx1-ubyte\n",
      "train-images-idx3-ubyte\n",
      "train-labels-idx1-ubyte\n",
      "\n",
      "   label  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
      "0      2       0       0       0       0       0       0       0       0   \n",
      "1      9       0       0       0       0       0       0       0       0   \n",
      "2      6       0       0       0       0       0       0       0       5   \n",
      "3      0       0       0       0       1       2       0       0       0   \n",
      "4      3       0       0       0       0       0       0       0       0   \n",
      "\n",
      "   pixel9  ...  pixel775  pixel776  pixel777  pixel778  pixel779  pixel780  \\\n",
      "0       0  ...         0         0         0         0         0         0   \n",
      "1       0  ...         0         0         0         0         0         0   \n",
      "2       0  ...         0         0         0        30        43         0   \n",
      "3       0  ...         3         0         0         0         0         1   \n",
      "4       0  ...         0         0         0         0         0         0   \n",
      "\n",
      "   pixel781  pixel782  pixel783  pixel784  \n",
      "0         0         0         0         0  \n",
      "1         0         0         0         0  \n",
      "2         0         0         0         0  \n",
      "3         0         0         0         0  \n",
      "4         0         0         0         0  \n",
      "\n",
      "[5 rows x 785 columns]\n",
      "(60000, 785)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import Input, Conv2D, BatchNormalization, Activation, Add, Flatten, Dense\n",
    "from keras.models import Model\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "class_names = ['T_shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "\n",
    "x_train = train_df.iloc[:, 1:].values.reshape(-1, 28, 28, 1)\n",
    "y_train = to_categorical(train_df.iloc[:, 0].values, 10)\n",
    "x_test = test_df.iloc[:, 1:].values.reshape(-1, 28, 28, 1)\n",
    "y_test = to_categorical(test_df.iloc[:, 0].values, 10)\n",
    "\n",
    "x_train, x_validate, y_train, y_validate = train_test_split(x_train, y_train, test_size = 0.2, random_state = 12345)\n",
    "\n",
    "\n",
    "# Definicja bloku resztkowego\n",
    "def residual_block(inputs, filters):\n",
    "    x = Conv2D(filters, kernel_size=(3, 3), padding='same')(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv2D(filters, kernel_size=(3, 3), padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Add()([x, inputs])\n",
    "    x = Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "inputs = Input(shape=(28, 28, 1))\n",
    "x = Conv2D(64, kernel_size=(3, 3), padding='same')(inputs)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "\n",
    "x = residual_block(x, 64)\n",
    "x = residual_block(x, 64)\n",
    "\n",
    "x = Conv2D(128, kernel_size=(3, 3), padding='same', strides=(2, 2))(x)\n",
    "x = residual_block(x, 128)\n",
    "x = residual_block(x, 128)\n",
    "\n",
    "x = Conv2D(256, kernel_size=(3, 3), padding='same', strides=(2, 2))(x)\n",
    "x = residual_block(x, 256)\n",
    "x = residual_block(x, 256)\n",
    "\n",
    "x = Flatten()(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "outputs = Dense(10, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs, outputs)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(x_train, y_train, batch_size=64, epochs=10, validation_data=(x_validate, y_validate))\n",
    "\n",
    "loss, accuracy = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('===========================')\n",
    "print('Test loss:', loss)\n",
    "print('Test accuracy:', accuracy)\n",
    "print('===========================')\n"
   ],
   "metadata": {
    "_uuid": "d97ee0d425a0b27b2a827ea7ced09b32f160b5ef",
    "trusted": true
   },
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-23 09:56:39.271242: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - ETA: 0s - loss: 0.8652 - accuracy: 0.7341"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-23 09:58:35.606487: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 126s 167ms/step - loss: 0.8652 - accuracy: 0.7341 - val_loss: 0.3446 - val_accuracy: 0.8766\n",
      "Epoch 2/10\n",
      "750/750 [==============================] - 126s 168ms/step - loss: 0.4167 - accuracy: 0.8587 - val_loss: 0.3088 - val_accuracy: 0.8872\n",
      "Epoch 3/10\n",
      "750/750 [==============================] - 122s 162ms/step - loss: 0.2997 - accuracy: 0.8923 - val_loss: 0.2698 - val_accuracy: 0.8994\n",
      "Epoch 4/10\n",
      "750/750 [==============================] - 121s 161ms/step - loss: 0.2608 - accuracy: 0.9049 - val_loss: 0.2815 - val_accuracy: 0.8977\n",
      "Epoch 5/10\n",
      "750/750 [==============================] - 124s 165ms/step - loss: 0.2285 - accuracy: 0.9168 - val_loss: 0.2588 - val_accuracy: 0.9075\n",
      "Epoch 6/10\n",
      "750/750 [==============================] - 127s 170ms/step - loss: 0.2037 - accuracy: 0.9256 - val_loss: 0.2438 - val_accuracy: 0.9116\n",
      "Epoch 7/10\n",
      "750/750 [==============================] - 129s 172ms/step - loss: 0.1894 - accuracy: 0.9313 - val_loss: 0.2671 - val_accuracy: 0.9047\n",
      "Epoch 8/10\n",
      "750/750 [==============================] - 127s 169ms/step - loss: 0.1721 - accuracy: 0.9367 - val_loss: 0.2343 - val_accuracy: 0.9174\n",
      "Epoch 9/10\n",
      "750/750 [==============================] - 119s 159ms/step - loss: 0.1552 - accuracy: 0.9429 - val_loss: 0.2387 - val_accuracy: 0.9152\n",
      "Epoch 10/10\n",
      "750/750 [==============================] - 135s 180ms/step - loss: 0.1381 - accuracy: 0.9485 - val_loss: 0.2480 - val_accuracy: 0.9174\n",
      "Test loss: 0.24200686812400818\n",
      "Test accuracy: 0.9181000590324402\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import classification_report\n",
    "import tensorflow as tf\n",
    "\n",
    "# , 'pool_size': 2 # down sampling the output instead of 28*28 it is 14*14\n",
    "params = [\n",
    "    # # -0.01\n",
    "    # {     'filters': 32\n",
    "    #     , 'kernel_size': 3\n",
    "    #     , 'pool_size': 2\n",
    "    #     , 'dropout': 0.2\n",
    "    #     , 'dense_units': 32\n",
    "    #     , 'adam_lr': 0.0005\n",
    "    #     , 'batch_size': 4096\n",
    "    #     , 'epochs': 75},\n",
    "    # + 0.12\n",
    "\n",
    "    {   'model': Sequential([\n",
    "            Conv2D(filters=16, kernel_size=4, activation='relu', input_shape = image_shape),\n",
    "            Dropout(0.2),\n",
    "            MaxPooling2D(pool_size=2),\n",
    "            Dropout(0.2), Flatten(),\n",
    "            Dense(16, activation='relu'),\n",
    "            Dense(10, activation = 'softmax')])\n",
    "        , 'adam_lr': 0.0025\n",
    "        , 'batch_size': 64\n",
    "        , 'epochs': 30},\n",
    "\n",
    "    # {   'model': Sequential([\n",
    "    #         Conv2D(filters=16, kernel_size=4, activation='relu', input_shape = image_shape),\n",
    "    #         Dropout(0.2),\n",
    "    #         MaxPooling2D(pool_size=2),\n",
    "    #         Dropout(0.2), Flatten(),\n",
    "    #         Dense(16, activation='relu'),\n",
    "    #         Dense(10, activation = 'softmax')])\n",
    "    #     , 'adam_lr': 0.0025\n",
    "    #     , 'batch_size': 128\n",
    "    #     , 'epochs': 30},\n",
    "\n",
    "\n",
    "    # {   'model': Sequential([\n",
    "    #         Conv2D(filters=16, kernel_size=4, activation='relu', input_shape = image_shape),\n",
    "    #         Dropout(0.2),\n",
    "    #         MaxPooling2D(pool_size=2),\n",
    "    #         Dropout(0.2), Flatten(),\n",
    "    #         Dense(32, activation='relu'),\n",
    "    #         Dense(10, activation = 'softmax')])\n",
    "    #     , 'adam_lr': 0.0025\n",
    "    #     , 'batch_size': 1024\n",
    "    #     , 'epochs': 30},\n",
    "\n",
    "    # {   'model': Sequential([\n",
    "    #         Conv2D(filters=16, kernel_size=4, activation='relu', input_shape = image_shape),\n",
    "    #         MaxPooling2D(pool_size=2), Dropout(0.2), Flatten(),\n",
    "    #         Dense(32, activation='relu'),\n",
    "    #         Dense(10, activation = 'softmax')])\n",
    "    #     , 'adam_lr': 0.0025\n",
    "    #     , 'batch_size': 1024\n",
    "    #     , 'epochs': 30},\n",
    "\n",
    "    # {     'filters': 32\n",
    "    #     , 'kernel_size': 4\n",
    "    #     , 'pool_size': 2\n",
    "    #     , 'dropout': 0.2\n",
    "    #     , 'dense_units': 32\n",
    "    #     , 'adam_lr': 0.0025\n",
    "    #     , 'batch_size': 1024\n",
    "    #     , 'epochs': 30},\n",
    "\n",
    "    # {     'filters': 32\n",
    "    #     , 'kernel_size': 3\n",
    "    #     , 'pool_size': 2\n",
    "    #     , 'dropout': 0.2\n",
    "    #     , 'dense_units': 32\n",
    "    #     , 'adam_lr': 0.0025\n",
    "    #     , 'batch_size': 1024\n",
    "    #     , 'epochs': 30},\n",
    "    #\n",
    "    # {     'filters': 32\n",
    "    #     , 'kernel_size': 3\n",
    "    #     , 'pool_size': 2\n",
    "    #     , 'dropout': 0.2\n",
    "    #     , 'dense_units': 32\n",
    "    #     , 'adam_lr': 0.0025\n",
    "    #     , 'batch_size': 2048\n",
    "    #     , 'epochs': 30},\n",
    "\n",
    "    # -.01\n",
    "    # {     'filters': 32\n",
    "    #     , 'kernel_size': 3\n",
    "    #     , 'pool_size': 2\n",
    "    #     , 'dropout': 0.2\n",
    "    #     , 'dense_units': 32\n",
    "    #     , 'adam_lr': 0.0025\n",
    "    #     , 'batch_size': 4096\n",
    "    #     , 'epochs': 30},\n",
    "\n",
    "    # -.01\n",
    "    # {     'filters': 32\n",
    "    #     , 'kernel_size': 3\n",
    "    #     , 'pool_size': 2\n",
    "    #     , 'dropout': 0.2\n",
    "    #     , 'dense_units': 32\n",
    "    #     , 'adam_lr': 0.002\n",
    "    #     , 'batch_size': 4096\n",
    "    #     , 'epochs': 30},\n",
    "    # -.01\n",
    "    # {     'filters': 32\n",
    "    #     , 'kernel_size': 3\n",
    "    #     , 'pool_size': 2\n",
    "    #     , 'dropout': 0.2\n",
    "    #     , 'dense_units': 24\n",
    "    #     , 'adam_lr': 0.001\n",
    "    #     , 'batch_size': 4096\n",
    "    #     , 'epochs': 35},\n",
    "    # {     'filters': 32\n",
    "    #     , 'kernel_size': 3\n",
    "    #     , 'pool_size': 2\n",
    "    #     , 'dropout': 0.2\n",
    "    #     , 'dense_units': 32\n",
    "    #     , 'adam_lr': 0.001\n",
    "    #     , 'batch_size': 4096\n",
    "    #     , 'epochs': 35},\n",
    "]\n",
    "\n",
    "for p in params:\n",
    "    print('>>> Params: ', p)\n",
    "    cnn_model = p['model']\n",
    "    cnn_model.compile(loss='sparse_categorical_crossentropy', optimizer=Adam(lr=p['adam_lr']), metrics =['accuracy'])\n",
    "    history = cnn_model.fit(\n",
    "        x_train,\n",
    "        y_train,\n",
    "        batch_size=p['batch_size'],\n",
    "        epochs=p['epochs'],\n",
    "        verbose=0,\n",
    "        validation_data=(x_validate, y_validate),\n",
    "    )\n",
    "    score = cnn_model.evaluate(x_test, y_test, verbose=0)\n",
    "    print('===========================')\n",
    "    print('>>>> Test Loss : {:.4f}'.format(score[0]))\n",
    "    print('>>>> Test Accuracy : {:.4f}'.format(score[1]))\n",
    "    print('===========================\\n\\n')\n",
    "    cnn_model.reset_states()\n",
    "    del cnn_model"
   ],
   "metadata": {
    "_uuid": "3e7ac49b5d3af585ba0ea700fffcc2640b90bfe0",
    "_kg_hide-input": true,
    "trusted": true
   },
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Params:  {'model': <keras.engine.sequential.Sequential object at 0x3f97d85b0>, 'adam_lr': 0.0025, 'batch_size': 64, 'epochs': 30}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-22 16:45:16.285451: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-02-22 16:45:21.766472: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===========================\n",
      ">>>> Test Loss : 0.2555\n",
      ">>>> Test Accuracy : 0.9085\n",
      "===========================\n",
      "\n",
      "\n",
      ">>> Params:  {'model': <keras.engine.sequential.Sequential object at 0x46e56ec80>, 'adam_lr': 0.0025, 'batch_size': 128, 'epochs': 30}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-22 16:48:21.537224: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-02-22 16:48:25.935315: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===========================\n",
      ">>>> Test Loss : 0.2714\n",
      ">>>> Test Accuracy : 0.9071\n",
      "===========================\n",
      "\n",
      "\n"
     ]
    }
   ]
  }
 ]
}
