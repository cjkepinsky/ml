{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "version": "3.6.4",
   "file_extension": ".py",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "name": "python",
   "mimetype": "text/x-python"
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "from subprocess import check_output\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import TensorBoard\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "num_classes = 10\n",
    "epochs = 20\n",
    "class_names = ['T_shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "\n",
    "train_df = pd.read_csv('./input/fashion-mnist_train.csv', sep=',')\n",
    "test_df = pd.read_csv('./input/fashion-mnist_test.csv', sep = ',')\n",
    "\n",
    "# print(check_output([\"ls\", \"./input\"]).decode(\"utf8\"))\n",
    "# print(train_df.head())\n",
    "print(train_df.shape)\n"
   ],
   "metadata": {
    "_cell_guid": "dec05004-ccb3-490e-b588-27c0f4f06d1e",
    "_uuid": "41907ec74cae883fa8d56f6556cade5c67c8f3e0",
    "_kg_hide-input": true,
    "trusted": true
   },
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 785)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Residual Learning\n",
    "RL (Residual Learning) to technika stosowana w sieciach neuronowych, w szczególności w warstwach konwolucyjnych, która pozwala na zwiększenie wydajności uczenia poprzez zmniejszenie problemu gradientu zanikającego (ang. vanishing gradient problem).\n",
    "\n",
    "Warstwa RL (Residual Layer) składa się z bloku resztkowego (ang. residual block), który dodaje oryginalne dane wejściowe do wyników operacji konwolucji i normalizacji, a następnie poddaje je funkcji aktywacji. Dzięki temu warstwa RL uczy się reszty (ang. residual), czyli różnicy pomiędzy oryginalnymi danymi wejściowymi a wynikami operacji konwolucji. W przypadku, gdy blok resztkowy nie będzie w stanie nauczyć się reszty, model wciąż będzie miał dostęp do oryginalnych danych wejściowych, co poprawia wydajność uczenia i zwiększa dokładność modelu.\n",
    "\n",
    "Warstwy RL są szczególnie przydatne przy budowie bardzo głębokich sieci neuronowych, w których problem gradientu zanikającego może znacznie wpłynąć na wydajność uczenia. Warstwy RL są stosowane w sieciach konwolucyjnych, ale również w innych rodzajach sieci neuronowych, takich jak sieci ResNet i DenseNet.\n",
    "\n",
    "## Same Padding\n",
    "\"Same padding\" to jedna z technik używanych w sieciach konwolucyjnych (CNN), która polega na uzupełnianiu danych wejściowych tak, aby wyjście miało tę samą wymiarowość co wejście.\n",
    "\n",
    "W przypadku konwolucji w sieciach neuronowych, wymiarowość wyjściowego obrazu zależy od rozmiaru filtra konwolucyjnego i sposobu, w jaki filtry są przesuwane po obrazie wejściowym. Bez uzupełniania danych, podczas stosowania filtrów konwolucyjnych, wyjście z każdej warstwy konwolucyjnej zmniejszałoby się, co prowadziłoby do utraty informacji i pogorszenia dokładności modelu.\n",
    "\n",
    "W technice same padding, dane wejściowe są uzupełniane tak, aby ich wymiarowość po przetworzeniu przez filtr konwolucyjny pozostawała niezmieniona. W przypadku filtrów o nieparzystych rozmiarach, takich jak 3x3, 5x5 itd., padding jest dodawany symetrycznie z obu stron wejściowego obrazu. Natomiast w przypadku filtrów o parzystych rozmiarach, takich jak 2x2, 4x4 itd., padding jest dodawany z jednej strony wejściowego obrazu.\n",
    "\n",
    "Technika same padding ma na celu zapobieganie utracie informacji i zapewnienie, że wyjście z każdej warstwy konwolucyjnej będzie miało tę samą wymiarowość co wejście, co ułatwia tworzenie głębszych sieci neuronowych i poprawia jakość klasyfikacji lub segmentacji obrazu."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-06 15:36:49.814783: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - ETA: 0s - loss: 0.8848 - accuracy: 0.7626"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-06 15:38:50.500614: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 131s 172ms/step - loss: 0.8848 - accuracy: 0.7626 - val_loss: 0.3727 - val_accuracy: 0.8650\n",
      "Epoch 2/3\n",
      "750/750 [==============================] - 129s 172ms/step - loss: 0.3329 - accuracy: 0.8786 - val_loss: 0.3018 - val_accuracy: 0.8905\n",
      "Epoch 3/3\n",
      "750/750 [==============================] - 127s 170ms/step - loss: 0.2798 - accuracy: 0.8968 - val_loss: 0.2970 - val_accuracy: 0.8899\n",
      "===========================\n",
      "Test loss: 0.28871530294418335\n",
      "Test accuracy: 0.8927000164985657\n",
      "===========================\n",
      "It took me 6.60 mins\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import Input, Conv2D, BatchNormalization, Activation, Add, Flatten, Dense\n",
    "from keras.models import Model\n",
    "from keras.utils import to_categorical\n",
    "import time\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "x_train = train_df.iloc[:, 1:].values.reshape(-1, 28, 28, 1)\n",
    "y_train = to_categorical(train_df.iloc[:, 0].values, 10)\n",
    "x_test = test_df.iloc[:, 1:].values.reshape(-1, 28, 28, 1)\n",
    "y_test = to_categorical(test_df.iloc[:, 0].values, 10)\n",
    "\n",
    "x_train, x_validate, y_train, y_validate = train_test_split(x_train, y_train, test_size = 0.2, random_state = 12345)\n",
    "\n",
    "\n",
    "# Definicja bloku resztkowego\n",
    "def residual_block(inputs, filters):\n",
    "    x = Conv2D(filters, kernel_size=(3, 3), padding='same')(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv2D(filters, kernel_size=(3, 3), padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Add()([x, inputs])\n",
    "    x = Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "inputs = Input(shape=(28, 28, 1))\n",
    "x = Conv2D(64, kernel_size=(3, 3), padding='same')(inputs)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "\n",
    "x = residual_block(x, 64)\n",
    "x = residual_block(x, 64)\n",
    "\n",
    "x = Conv2D(128, kernel_size=(3, 3), padding='same', strides=(2, 2))(x)\n",
    "x = residual_block(x, 128)\n",
    "x = residual_block(x, 128)\n",
    "\n",
    "x = Conv2D(256, kernel_size=(3, 3), padding='same', strides=(2, 2))(x)\n",
    "x = residual_block(x, 256)\n",
    "x = residual_block(x, 256)\n",
    "\n",
    "x = Flatten()(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "outputs = Dense(10, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs, outputs)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(x_train, y_train, batch_size=64, epochs=3, validation_data=(x_validate, y_validate))\n",
    "\n",
    "loss, accuracy = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('===========================')\n",
    "print('Test loss:', loss)\n",
    "print('Test accuracy:', accuracy)\n",
    "print('===========================')\n",
    "diff = time.time() - start\n",
    "print('It took me {:.2f} mins'.format(diff/60))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 8s 24ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " T_shirt/top       0.90      0.76      0.82      1000\n",
      "     Trouser       0.99      0.98      0.99      1000\n",
      "    Pullover       0.87      0.78      0.82      1000\n",
      "       Dress       0.92      0.93      0.92      1000\n",
      "        Coat       0.79      0.90      0.84      1000\n",
      "      Sandal       0.94      0.98      0.96      1000\n",
      "       Shirt       0.74      0.74      0.74      1000\n",
      "     Sneaker       0.97      0.90      0.93      1000\n",
      "         Bag       0.90      1.00      0.95      1000\n",
      "  Ankle boot       0.94      0.97      0.95      1000\n",
      "\n",
      "    accuracy                           0.89     10000\n",
      "   macro avg       0.89      0.89      0.89     10000\n",
      "weighted avg       0.89      0.89      0.89     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "pred = model.predict(x_test)\n",
    "predicted_classes = np.argmax(pred, axis=-1)\n",
    "y_test = test_df.iloc[:, 0]\n",
    "\n",
    "print(classification_report(y_test, predicted_classes, target_names=class_names))"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ]
}
