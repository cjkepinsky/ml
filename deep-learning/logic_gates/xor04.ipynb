{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 2)\n",
      "y: (4,)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from libs.simple_processing import separate_target\n",
    "\n",
    "DATA = pd.read_csv('xor.csv', delimiter=';')\n",
    "\n",
    "X, y = separate_target(DATA, 'y')\n",
    "\n",
    "# class_names = ['00', '01', '10', '11']\n",
    "\n",
    "print(X.shape)\n",
    "print('y:', y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2]\n",
      "(4, 2)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# patience below 7 cuts to early\n",
    "early_stopping = EarlyStopping(\n",
    "    min_delta=0.0005,  # minimium amount of change to count as an improvement\n",
    "    patience=7,  # how many epochs to wait before stopping\n",
    "    restore_best_weights=True,\n",
    ")\n",
    "# X_train, X_valid, y_train, y_valid = train_test_split(X, y, train_size=0.6, random_state=40)\n",
    "\n",
    "X_train = X.copy()\n",
    "y_train = y.copy()\n",
    "X_valid = X.copy()\n",
    "y_valid = y.copy()\n",
    "\n",
    "input_shape = [X_train.shape[1]]\n",
    "print(input_shape)\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   x1  x2\n",
      "0   0   0\n",
      "1   0   1\n",
      "2   1   0\n",
      "3   1   1\n",
      "0    0\n",
      "1    1\n",
      "2    1\n",
      "3    0\n",
      "Name: y, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(X_train)\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": "<IPython.core.display.Image object>"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from keras.layers.core import Activation\n",
    "# from tensorflow.keras import layers\n",
    "from tensorflow.keras import activations\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(layers.Dense(2, activation=Activation(activations.relu), input_shape=input_shape))\n",
    "# model.add(layers.Flatten(input_shape=input_shape))\n",
    "model.add(layers.Dense(8, activation=Activation(activations.relu)))\n",
    "model.add(layers.Dense(1))\n",
    "\n",
    "keras.utils.plot_model(model, show_shapes=True, rankdir=\"LR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/450\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-01 19:30:29.139924: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step - loss: 4.7566 - binary_accuracy: 0.5000 - val_loss: 4.7136 - val_binary_accuracy: 0.5000\n",
      "Epoch 2/450\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 4.7136 - binary_accuracy: 0.5000 - val_loss: 4.6826 - val_binary_accuracy: 0.5000\n",
      "Epoch 3/450\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-01 19:30:29.447982: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 50ms/step - loss: 4.6826 - binary_accuracy: 0.5000 - val_loss: 4.6568 - val_binary_accuracy: 0.5000\n",
      "Epoch 4/450\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.6568 - binary_accuracy: 0.5000 - val_loss: 4.6341 - val_binary_accuracy: 0.5000\n",
      "Epoch 5/450\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.6341 - binary_accuracy: 0.5000 - val_loss: 4.6133 - val_binary_accuracy: 0.5000\n",
      "Epoch 6/450\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.6133 - binary_accuracy: 0.5000 - val_loss: 4.5939 - val_binary_accuracy: 0.5000\n",
      "Epoch 7/450\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.5939 - binary_accuracy: 0.5000 - val_loss: 4.5757 - val_binary_accuracy: 0.5000\n",
      "Epoch 8/450\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.5757 - binary_accuracy: 0.5000 - val_loss: 4.5582 - val_binary_accuracy: 0.5000\n",
      "Epoch 9/450\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 4.5582 - binary_accuracy: 0.5000 - val_loss: 4.5414 - val_binary_accuracy: 0.5000\n",
      "Epoch 10/450\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 4.5414 - binary_accuracy: 0.5000 - val_loss: 4.5252 - val_binary_accuracy: 0.5000\n",
      "Epoch 11/450\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.5252 - binary_accuracy: 0.5000 - val_loss: 4.5095 - val_binary_accuracy: 0.5000\n",
      "Epoch 12/450\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.5095 - binary_accuracy: 0.5000 - val_loss: 4.4941 - val_binary_accuracy: 0.5000\n",
      "Epoch 13/450\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 4.4941 - binary_accuracy: 0.5000 - val_loss: 4.4791 - val_binary_accuracy: 0.5000\n",
      "Epoch 14/450\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 4.4791 - binary_accuracy: 0.5000 - val_loss: 4.4643 - val_binary_accuracy: 0.5000\n",
      "Epoch 15/450\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 4.4643 - binary_accuracy: 0.5000 - val_loss: 4.4499 - val_binary_accuracy: 0.5000\n",
      "Epoch 16/450\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 4.4499 - binary_accuracy: 0.5000 - val_loss: 4.4356 - val_binary_accuracy: 0.5000\n",
      "Epoch 17/450\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 4.4356 - binary_accuracy: 0.5000 - val_loss: 4.4215 - val_binary_accuracy: 0.5000\n",
      "Epoch 18/450\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.4215 - binary_accuracy: 0.5000 - val_loss: 4.4076 - val_binary_accuracy: 0.5000\n",
      "Epoch 19/450\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.4076 - binary_accuracy: 0.5000 - val_loss: 4.3938 - val_binary_accuracy: 0.5000\n",
      "Epoch 20/450\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 4.3938 - binary_accuracy: 0.5000 - val_loss: 4.3802 - val_binary_accuracy: 0.5000\n",
      "Epoch 21/450\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.3802 - binary_accuracy: 0.5000 - val_loss: 4.3667 - val_binary_accuracy: 0.5000\n",
      "Epoch 22/450\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 4.3667 - binary_accuracy: 0.5000 - val_loss: 4.3533 - val_binary_accuracy: 0.5000\n",
      "Epoch 23/450\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 4.3533 - binary_accuracy: 0.5000 - val_loss: 4.3400 - val_binary_accuracy: 0.5000\n",
      "Epoch 24/450\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 4.3400 - binary_accuracy: 0.5000 - val_loss: 4.3269 - val_binary_accuracy: 0.5000\n",
      "Epoch 25/450\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 4.3269 - binary_accuracy: 0.5000 - val_loss: 4.3138 - val_binary_accuracy: 0.5000\n",
      "Epoch 26/450\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 4.3138 - binary_accuracy: 0.5000 - val_loss: 4.3007 - val_binary_accuracy: 0.5000\n",
      "Epoch 27/450\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.3007 - binary_accuracy: 0.5000 - val_loss: 4.2878 - val_binary_accuracy: 0.5000\n",
      "Epoch 28/450\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.2878 - binary_accuracy: 0.5000 - val_loss: 4.2749 - val_binary_accuracy: 0.5000\n",
      "Epoch 29/450\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.2749 - binary_accuracy: 0.5000 - val_loss: 4.2621 - val_binary_accuracy: 0.5000\n",
      "Epoch 30/450\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 4.2621 - binary_accuracy: 0.5000 - val_loss: 4.2493 - val_binary_accuracy: 0.5000\n",
      "Epoch 31/450\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.2493 - binary_accuracy: 0.5000 - val_loss: 4.2366 - val_binary_accuracy: 0.5000\n",
      "Epoch 32/450\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.2366 - binary_accuracy: 0.5000 - val_loss: 4.2239 - val_binary_accuracy: 0.5000\n",
      "Epoch 33/450\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.2239 - binary_accuracy: 0.5000 - val_loss: 4.2113 - val_binary_accuracy: 0.5000\n",
      "Epoch 34/450\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.2113 - binary_accuracy: 0.5000 - val_loss: 4.1987 - val_binary_accuracy: 0.5000\n",
      "Epoch 35/450\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.1987 - binary_accuracy: 0.5000 - val_loss: 4.1862 - val_binary_accuracy: 0.5000\n",
      "Epoch 36/450\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.1862 - binary_accuracy: 0.5000 - val_loss: 4.1737 - val_binary_accuracy: 0.5000\n",
      "Epoch 37/450\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1737 - binary_accuracy: 0.5000 - val_loss: 4.1613 - val_binary_accuracy: 0.5000\n",
      "Epoch 38/450\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.1613 - binary_accuracy: 0.5000 - val_loss: 4.1489 - val_binary_accuracy: 0.5000\n",
      "Epoch 39/450\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.1489 - binary_accuracy: 0.5000 - val_loss: 4.1365 - val_binary_accuracy: 0.5000\n",
      "Epoch 40/450\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.1365 - binary_accuracy: 0.5000 - val_loss: 4.1242 - val_binary_accuracy: 0.5000\n",
      "Epoch 41/450\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.1242 - binary_accuracy: 0.5000 - val_loss: 4.1119 - val_binary_accuracy: 0.5000\n",
      "Epoch 42/450\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.1119 - binary_accuracy: 0.5000 - val_loss: 4.0996 - val_binary_accuracy: 0.5000\n",
      "Epoch 43/450\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.0996 - binary_accuracy: 0.5000 - val_loss: 4.0873 - val_binary_accuracy: 0.5000\n",
      "Epoch 44/450\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 4.0873 - binary_accuracy: 0.5000 - val_loss: 4.0751 - val_binary_accuracy: 0.5000\n",
      "Epoch 45/450\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.0751 - binary_accuracy: 0.5000 - val_loss: 4.0630 - val_binary_accuracy: 0.5000\n",
      "Epoch 46/450\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.0630 - binary_accuracy: 0.5000 - val_loss: 4.0508 - val_binary_accuracy: 0.5000\n",
      "Epoch 47/450\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 4.0508 - binary_accuracy: 0.5000 - val_loss: 4.0387 - val_binary_accuracy: 0.5000\n",
      "Epoch 48/450\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 4.0387 - binary_accuracy: 0.5000 - val_loss: 4.0266 - val_binary_accuracy: 0.5000\n",
      "Epoch 49/450\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 4.0266 - binary_accuracy: 0.5000 - val_loss: 4.0145 - val_binary_accuracy: 0.5000\n",
      "Epoch 50/450\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 4.0145 - binary_accuracy: 0.5000 - val_loss: 4.0025 - val_binary_accuracy: 0.5000\n",
      "Epoch 51/450\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.0025 - binary_accuracy: 0.5000 - val_loss: 3.9905 - val_binary_accuracy: 0.5000\n",
      "Epoch 52/450\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 3.9905 - binary_accuracy: 0.5000 - val_loss: 3.9785 - val_binary_accuracy: 0.5000\n",
      "Epoch 53/450\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.9785 - binary_accuracy: 0.5000 - val_loss: 3.9665 - val_binary_accuracy: 0.5000\n",
      "Epoch 54/450\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 3.9665 - binary_accuracy: 0.5000 - val_loss: 3.9546 - val_binary_accuracy: 0.5000\n",
      "Epoch 55/450\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 3.9546 - binary_accuracy: 0.5000 - val_loss: 3.9427 - val_binary_accuracy: 0.5000\n",
      "Epoch 56/450\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.9427 - binary_accuracy: 0.5000 - val_loss: 3.9308 - val_binary_accuracy: 0.5000\n",
      "Epoch 57/450\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 3.9308 - binary_accuracy: 0.5000 - val_loss: 3.9190 - val_binary_accuracy: 0.5000\n",
      "Epoch 58/450\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 3.9190 - binary_accuracy: 0.5000 - val_loss: 3.9071 - val_binary_accuracy: 0.5000\n",
      "Epoch 59/450\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.9071 - binary_accuracy: 0.5000 - val_loss: 3.8953 - val_binary_accuracy: 0.5000\n",
      "Epoch 60/450\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 3.8953 - binary_accuracy: 0.5000 - val_loss: 3.8835 - val_binary_accuracy: 0.5000\n",
      "Epoch 61/450\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.8835 - binary_accuracy: 0.5000 - val_loss: 3.8718 - val_binary_accuracy: 0.5000\n",
      "Epoch 62/450\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 3.8718 - binary_accuracy: 0.5000 - val_loss: 3.8600 - val_binary_accuracy: 0.5000\n",
      "Epoch 63/450\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.8600 - binary_accuracy: 0.5000 - val_loss: 3.8483 - val_binary_accuracy: 0.5000\n",
      "Epoch 64/450\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 3.8483 - binary_accuracy: 0.5000 - val_loss: 3.8366 - val_binary_accuracy: 0.5000\n",
      "Epoch 65/450\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.8366 - binary_accuracy: 0.5000 - val_loss: 3.8250 - val_binary_accuracy: 0.5000\n",
      "Epoch 66/450\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.8250 - binary_accuracy: 0.5000 - val_loss: 3.8133 - val_binary_accuracy: 0.5000\n",
      "Epoch 67/450\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 3.8133 - binary_accuracy: 0.5000 - val_loss: 3.8017 - val_binary_accuracy: 0.5000\n",
      "Epoch 68/450\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 3.8017 - binary_accuracy: 0.5000 - val_loss: 3.7901 - val_binary_accuracy: 0.5000\n",
      "Epoch 69/450\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7901 - binary_accuracy: 0.5000 - val_loss: 3.7786 - val_binary_accuracy: 0.5000\n",
      "Epoch 70/450\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7786 - binary_accuracy: 0.5000 - val_loss: 3.7670 - val_binary_accuracy: 0.5000\n",
      "Epoch 71/450\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7670 - binary_accuracy: 0.5000 - val_loss: 3.7555 - val_binary_accuracy: 0.5000\n",
      "Epoch 72/450\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7555 - binary_accuracy: 0.5000 - val_loss: 3.7440 - val_binary_accuracy: 0.5000\n",
      "Epoch 73/450\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7440 - binary_accuracy: 0.5000 - val_loss: 3.7325 - val_binary_accuracy: 0.5000\n",
      "Epoch 74/450\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7325 - binary_accuracy: 0.5000 - val_loss: 3.7211 - val_binary_accuracy: 0.5000\n",
      "Epoch 75/450\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7211 - binary_accuracy: 0.5000 - val_loss: 3.7096 - val_binary_accuracy: 0.5000\n",
      "Epoch 76/450\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.7096 - binary_accuracy: 0.5000 - val_loss: 3.6982 - val_binary_accuracy: 0.5000\n",
      "Epoch 77/450\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 3.6982 - binary_accuracy: 0.5000 - val_loss: 3.6868 - val_binary_accuracy: 0.5000\n",
      "Epoch 78/450\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.6868 - binary_accuracy: 0.5000 - val_loss: 3.6755 - val_binary_accuracy: 0.5000\n",
      "Epoch 79/450\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.6755 - binary_accuracy: 0.5000 - val_loss: 3.6641 - val_binary_accuracy: 0.5000\n",
      "Epoch 80/450\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.6641 - binary_accuracy: 0.5000 - val_loss: 3.6528 - val_binary_accuracy: 0.5000\n",
      "Epoch 81/450\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 3.6528 - binary_accuracy: 0.5000 - val_loss: 3.6415 - val_binary_accuracy: 0.5000\n",
      "Epoch 82/450\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.6415 - binary_accuracy: 0.5000 - val_loss: 3.6302 - val_binary_accuracy: 0.5000\n",
      "Epoch 83/450\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.6302 - binary_accuracy: 0.5000 - val_loss: 3.6190 - val_binary_accuracy: 0.5000\n",
      "Epoch 84/450\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 3.6190 - binary_accuracy: 0.5000 - val_loss: 3.6078 - val_binary_accuracy: 0.5000\n",
      "Epoch 85/450\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 3.6078 - binary_accuracy: 0.5000 - val_loss: 3.5966 - val_binary_accuracy: 0.5000\n",
      "Epoch 86/450\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.5966 - binary_accuracy: 0.5000 - val_loss: 3.5854 - val_binary_accuracy: 0.5000\n",
      "Epoch 87/450\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 3.5854 - binary_accuracy: 0.5000 - val_loss: 3.5742 - val_binary_accuracy: 0.5000\n",
      "Epoch 88/450\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.5742 - binary_accuracy: 0.5000 - val_loss: 3.5631 - val_binary_accuracy: 0.5000\n",
      "Epoch 89/450\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.5631 - binary_accuracy: 0.5000 - val_loss: 3.5520 - val_binary_accuracy: 0.5000\n",
      "Epoch 90/450\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 3.5520 - binary_accuracy: 0.5000 - val_loss: 3.5409 - val_binary_accuracy: 0.5000\n",
      "Epoch 91/450\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 3.5409 - binary_accuracy: 0.5000 - val_loss: 3.5298 - val_binary_accuracy: 0.5000\n",
      "Epoch 92/450\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.5298 - binary_accuracy: 0.5000 - val_loss: 3.5188 - val_binary_accuracy: 0.5000\n",
      "Epoch 93/450\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 3.5188 - binary_accuracy: 0.5000 - val_loss: 3.5077 - val_binary_accuracy: 0.5000\n",
      "Epoch 94/450\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 3.5077 - binary_accuracy: 0.5000 - val_loss: 3.4967 - val_binary_accuracy: 0.5000\n",
      "Epoch 95/450\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.4967 - binary_accuracy: 0.5000 - val_loss: 3.4858 - val_binary_accuracy: 0.5000\n",
      "Epoch 96/450\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.4858 - binary_accuracy: 0.5000 - val_loss: 3.4748 - val_binary_accuracy: 0.5000\n",
      "Epoch 97/450\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.4748 - binary_accuracy: 0.5000 - val_loss: 3.4639 - val_binary_accuracy: 0.5000\n",
      "Epoch 98/450\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 3.4639 - binary_accuracy: 0.5000 - val_loss: 3.4529 - val_binary_accuracy: 0.5000\n",
      "Epoch 99/450\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.4529 - binary_accuracy: 0.5000 - val_loss: 3.4420 - val_binary_accuracy: 0.5000\n",
      "Epoch 100/450\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 3.4420 - binary_accuracy: 0.5000 - val_loss: 3.4312 - val_binary_accuracy: 0.5000\n",
      "Epoch 101/450\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 3.4312 - binary_accuracy: 0.5000 - val_loss: 3.4203 - val_binary_accuracy: 0.5000\n",
      "Epoch 102/450\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.4203 - binary_accuracy: 0.5000 - val_loss: 3.4095 - val_binary_accuracy: 0.5000\n",
      "Epoch 103/450\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 3.4095 - binary_accuracy: 0.5000 - val_loss: 3.3987 - val_binary_accuracy: 0.5000\n",
      "Epoch 104/450\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.3987 - binary_accuracy: 0.5000 - val_loss: 3.3879 - val_binary_accuracy: 0.5000\n",
      "Epoch 105/450\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.3879 - binary_accuracy: 0.5000 - val_loss: 3.3772 - val_binary_accuracy: 0.5000\n",
      "Epoch 106/450\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.3772 - binary_accuracy: 0.5000 - val_loss: 3.3664 - val_binary_accuracy: 0.5000\n",
      "Epoch 107/450\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.3664 - binary_accuracy: 0.5000 - val_loss: 3.3557 - val_binary_accuracy: 0.5000\n",
      "Epoch 108/450\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.3557 - binary_accuracy: 0.5000 - val_loss: 3.3450 - val_binary_accuracy: 0.5000\n",
      "Epoch 109/450\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.3450 - binary_accuracy: 0.5000 - val_loss: 3.3343 - val_binary_accuracy: 0.5000\n",
      "Epoch 110/450\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.3343 - binary_accuracy: 0.5000 - val_loss: 3.3237 - val_binary_accuracy: 0.5000\n",
      "Epoch 111/450\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.3237 - binary_accuracy: 0.5000 - val_loss: 3.3130 - val_binary_accuracy: 0.5000\n",
      "Epoch 112/450\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.3130 - binary_accuracy: 0.5000 - val_loss: 3.3024 - val_binary_accuracy: 0.5000\n",
      "Epoch 113/450\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.3024 - binary_accuracy: 0.5000 - val_loss: 3.2919 - val_binary_accuracy: 0.5000\n",
      "Epoch 114/450\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.2919 - binary_accuracy: 0.5000 - val_loss: 3.2813 - val_binary_accuracy: 0.5000\n",
      "Epoch 115/450\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.2813 - binary_accuracy: 0.5000 - val_loss: 3.2707 - val_binary_accuracy: 0.5000\n",
      "Epoch 116/450\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.2707 - binary_accuracy: 0.5000 - val_loss: 3.2602 - val_binary_accuracy: 0.5000\n",
      "Epoch 117/450\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 3.2602 - binary_accuracy: 0.5000 - val_loss: 3.2497 - val_binary_accuracy: 0.5000\n",
      "Epoch 118/450\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.2497 - binary_accuracy: 0.5000 - val_loss: 3.2392 - val_binary_accuracy: 0.5000\n",
      "Epoch 119/450\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.2392 - binary_accuracy: 0.5000 - val_loss: 3.2288 - val_binary_accuracy: 0.5000\n",
      "Epoch 120/450\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 3.2288 - binary_accuracy: 0.5000 - val_loss: 3.2184 - val_binary_accuracy: 0.5000\n",
      "Epoch 121/450\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.2184 - binary_accuracy: 0.5000 - val_loss: 3.2079 - val_binary_accuracy: 0.5000\n",
      "Epoch 122/450\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 3.2079 - binary_accuracy: 0.5000 - val_loss: 3.1976 - val_binary_accuracy: 0.5000\n",
      "Epoch 123/450\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.1976 - binary_accuracy: 0.5000 - val_loss: 3.1872 - val_binary_accuracy: 0.5000\n",
      "Epoch 124/450\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.1872 - binary_accuracy: 0.5000 - val_loss: 3.1768 - val_binary_accuracy: 0.5000\n",
      "Epoch 125/450\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 3.1768 - binary_accuracy: 0.5000 - val_loss: 3.1665 - val_binary_accuracy: 0.5000\n",
      "Epoch 126/450\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.1665 - binary_accuracy: 0.5000 - val_loss: 3.1562 - val_binary_accuracy: 0.5000\n",
      "Epoch 127/450\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 3.1562 - binary_accuracy: 0.5000 - val_loss: 3.1459 - val_binary_accuracy: 0.5000\n",
      "Epoch 128/450\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.1459 - binary_accuracy: 0.5000 - val_loss: 3.1357 - val_binary_accuracy: 0.5000\n",
      "Epoch 129/450\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.1357 - binary_accuracy: 0.5000 - val_loss: 3.1254 - val_binary_accuracy: 0.5000\n",
      "Epoch 130/450\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 3.1254 - binary_accuracy: 0.5000 - val_loss: 3.1152 - val_binary_accuracy: 0.5000\n",
      "Epoch 131/450\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.1152 - binary_accuracy: 0.5000 - val_loss: 3.1050 - val_binary_accuracy: 0.5000\n",
      "Epoch 132/450\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.1050 - binary_accuracy: 0.5000 - val_loss: 3.0948 - val_binary_accuracy: 0.5000\n",
      "Epoch 133/450\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 3.0948 - binary_accuracy: 0.5000 - val_loss: 3.0847 - val_binary_accuracy: 0.5000\n",
      "Epoch 134/450\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 3.0847 - binary_accuracy: 0.5000 - val_loss: 3.0745 - val_binary_accuracy: 0.5000\n",
      "Epoch 135/450\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 3.0745 - binary_accuracy: 0.5000 - val_loss: 3.0644 - val_binary_accuracy: 0.5000\n",
      "Epoch 136/450\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.0644 - binary_accuracy: 0.5000 - val_loss: 3.0543 - val_binary_accuracy: 0.5000\n",
      "Epoch 137/450\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 3.0543 - binary_accuracy: 0.5000 - val_loss: 3.0443 - val_binary_accuracy: 0.5000\n",
      "Epoch 138/450\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.0443 - binary_accuracy: 0.5000 - val_loss: 3.0342 - val_binary_accuracy: 0.5000\n",
      "Epoch 139/450\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 3.0342 - binary_accuracy: 0.5000 - val_loss: 3.0242 - val_binary_accuracy: 0.5000\n",
      "Epoch 140/450\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 3.0242 - binary_accuracy: 0.5000 - val_loss: 3.0142 - val_binary_accuracy: 0.5000\n",
      "Epoch 141/450\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 3.0142 - binary_accuracy: 0.5000 - val_loss: 3.0042 - val_binary_accuracy: 0.5000\n",
      "Epoch 142/450\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 3.0042 - binary_accuracy: 0.5000 - val_loss: 2.9942 - val_binary_accuracy: 0.5000\n",
      "Epoch 143/450\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 2.9942 - binary_accuracy: 0.5000 - val_loss: 2.9843 - val_binary_accuracy: 0.5000\n",
      "Epoch 144/450\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 2.9843 - binary_accuracy: 0.5000 - val_loss: 2.9743 - val_binary_accuracy: 0.5000\n",
      "Epoch 145/450\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 2.9743 - binary_accuracy: 0.5000 - val_loss: 2.9644 - val_binary_accuracy: 0.5000\n",
      "Epoch 146/450\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 2.9644 - binary_accuracy: 0.5000 - val_loss: 2.9546 - val_binary_accuracy: 0.5000\n",
      "Epoch 147/450\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 2.9546 - binary_accuracy: 0.5000 - val_loss: 2.9447 - val_binary_accuracy: 0.5000\n",
      "Epoch 148/450\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 2.9447 - binary_accuracy: 0.5000 - val_loss: 2.9349 - val_binary_accuracy: 0.5000\n",
      "Epoch 149/450\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 2.9349 - binary_accuracy: 0.5000 - val_loss: 2.9250 - val_binary_accuracy: 0.5000\n",
      "Epoch 150/450\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 2.9250 - binary_accuracy: 0.5000 - val_loss: 2.9152 - val_binary_accuracy: 0.5000\n",
      "Epoch 151/450\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 2.9152 - binary_accuracy: 0.5000 - val_loss: 2.9055 - val_binary_accuracy: 0.5000\n",
      "Epoch 152/450\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 2.9055 - binary_accuracy: 0.5000 - val_loss: 2.8957 - val_binary_accuracy: 0.5000\n",
      "Epoch 153/450\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 2.8957 - binary_accuracy: 0.5000 - val_loss: 2.8860 - val_binary_accuracy: 0.5000\n",
      "Epoch 154/450\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 2.8860 - binary_accuracy: 0.5000 - val_loss: 2.8763 - val_binary_accuracy: 0.5000\n",
      "Epoch 155/450\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 2.8763 - binary_accuracy: 0.5000 - val_loss: 2.8666 - val_binary_accuracy: 0.5000\n",
      "Epoch 156/450\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 2.8666 - binary_accuracy: 0.5000 - val_loss: 2.8569 - val_binary_accuracy: 0.5000\n",
      "Epoch 157/450\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 2.8569 - binary_accuracy: 0.5000 - val_loss: 2.8472 - val_binary_accuracy: 0.5000\n",
      "Epoch 158/450\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 2.8472 - binary_accuracy: 0.5000 - val_loss: 2.8376 - val_binary_accuracy: 0.5000\n",
      "Epoch 159/450\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 2.8376 - binary_accuracy: 0.5000 - val_loss: 2.8280 - val_binary_accuracy: 0.5000\n",
      "Epoch 160/450\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 2.8280 - binary_accuracy: 0.5000 - val_loss: 2.8184 - val_binary_accuracy: 0.5000\n",
      "Epoch 161/450\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 2.8184 - binary_accuracy: 0.5000 - val_loss: 2.8088 - val_binary_accuracy: 0.5000\n",
      "Epoch 162/450\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 2.8088 - binary_accuracy: 0.5000 - val_loss: 2.7993 - val_binary_accuracy: 0.5000\n",
      "Epoch 163/450\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 2.7993 - binary_accuracy: 0.5000 - val_loss: 2.7898 - val_binary_accuracy: 0.5000\n",
      "Epoch 164/450\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 2.7898 - binary_accuracy: 0.5000 - val_loss: 2.7803 - val_binary_accuracy: 0.5000\n",
      "Epoch 165/450\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 2.7803 - binary_accuracy: 0.5000 - val_loss: 2.7708 - val_binary_accuracy: 0.5000\n",
      "Epoch 166/450\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 2.7708 - binary_accuracy: 0.5000 - val_loss: 2.7613 - val_binary_accuracy: 0.5000\n",
      "Epoch 167/450\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 2.7613 - binary_accuracy: 0.5000 - val_loss: 2.7519 - val_binary_accuracy: 0.5000\n",
      "Epoch 168/450\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 2.7519 - binary_accuracy: 0.5000 - val_loss: 2.7424 - val_binary_accuracy: 0.5000\n",
      "Epoch 169/450\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 2.7424 - binary_accuracy: 0.5000 - val_loss: 2.7330 - val_binary_accuracy: 0.5000\n",
      "Epoch 170/450\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 2.7330 - binary_accuracy: 0.5000 - val_loss: 2.7236 - val_binary_accuracy: 0.5000\n",
      "Epoch 171/450\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 2.7236 - binary_accuracy: 0.5000 - val_loss: 2.7143 - val_binary_accuracy: 0.5000\n",
      "Epoch 172/450\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 2.7143 - binary_accuracy: 0.5000 - val_loss: 2.7049 - val_binary_accuracy: 0.5000\n",
      "Epoch 173/450\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 2.7049 - binary_accuracy: 0.5000 - val_loss: 2.6956 - val_binary_accuracy: 0.5000\n",
      "Epoch 174/450\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 2.6956 - binary_accuracy: 0.5000 - val_loss: 2.6863 - val_binary_accuracy: 0.5000\n",
      "Epoch 175/450\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 2.6863 - binary_accuracy: 0.5000 - val_loss: 2.6770 - val_binary_accuracy: 0.5000\n",
      "Epoch 176/450\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 2.6770 - binary_accuracy: 0.5000 - val_loss: 2.6678 - val_binary_accuracy: 0.5000\n",
      "Epoch 177/450\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 2.6678 - binary_accuracy: 0.5000 - val_loss: 2.6585 - val_binary_accuracy: 0.5000\n",
      "Epoch 178/450\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 2.6585 - binary_accuracy: 0.5000 - val_loss: 2.6493 - val_binary_accuracy: 0.5000\n",
      "Epoch 179/450\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 2.6493 - binary_accuracy: 0.5000 - val_loss: 2.6401 - val_binary_accuracy: 0.5000\n",
      "Epoch 180/450\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 2.6401 - binary_accuracy: 0.5000 - val_loss: 2.6309 - val_binary_accuracy: 0.5000\n",
      "Epoch 181/450\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 2.6309 - binary_accuracy: 0.5000 - val_loss: 2.6217 - val_binary_accuracy: 0.5000\n",
      "Epoch 182/450\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 2.6217 - binary_accuracy: 0.5000 - val_loss: 2.6126 - val_binary_accuracy: 0.5000\n",
      "Epoch 183/450\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 2.6126 - binary_accuracy: 0.5000 - val_loss: 2.6035 - val_binary_accuracy: 0.5000\n",
      "Epoch 184/450\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 2.6035 - binary_accuracy: 0.5000 - val_loss: 2.5944 - val_binary_accuracy: 0.5000\n",
      "Epoch 185/450\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 2.5944 - binary_accuracy: 0.5000 - val_loss: 2.5853 - val_binary_accuracy: 0.5000\n",
      "Epoch 186/450\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 2.5853 - binary_accuracy: 0.5000 - val_loss: 2.5762 - val_binary_accuracy: 0.5000\n",
      "Epoch 187/450\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 2.5762 - binary_accuracy: 0.5000 - val_loss: 2.5672 - val_binary_accuracy: 0.5000\n",
      "Epoch 188/450\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 2.5672 - binary_accuracy: 0.5000 - val_loss: 2.5582 - val_binary_accuracy: 0.5000\n",
      "Epoch 189/450\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 2.5582 - binary_accuracy: 0.5000 - val_loss: 2.5492 - val_binary_accuracy: 0.5000\n",
      "Epoch 190/450\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 2.5492 - binary_accuracy: 0.5000 - val_loss: 2.5402 - val_binary_accuracy: 0.5000\n",
      "Epoch 191/450\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 2.5402 - binary_accuracy: 0.5000 - val_loss: 2.5312 - val_binary_accuracy: 0.5000\n",
      "Epoch 192/450\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 2.5312 - binary_accuracy: 0.5000 - val_loss: 2.5223 - val_binary_accuracy: 0.5000\n",
      "Epoch 193/450\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 2.5223 - binary_accuracy: 0.5000 - val_loss: 2.5134 - val_binary_accuracy: 0.5000\n",
      "Epoch 194/450\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 2.5134 - binary_accuracy: 0.5000 - val_loss: 2.5044 - val_binary_accuracy: 0.5000\n",
      "Epoch 195/450\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 2.5044 - binary_accuracy: 0.5000 - val_loss: 2.4956 - val_binary_accuracy: 0.5000\n",
      "Epoch 196/450\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 2.4956 - binary_accuracy: 0.5000 - val_loss: 2.4867 - val_binary_accuracy: 0.5000\n",
      "Epoch 197/450\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 2.4867 - binary_accuracy: 0.5000 - val_loss: 2.4779 - val_binary_accuracy: 0.5000\n",
      "Epoch 198/450\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 2.4779 - binary_accuracy: 0.5000 - val_loss: 2.4690 - val_binary_accuracy: 0.5000\n",
      "Epoch 199/450\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 2.4690 - binary_accuracy: 0.5000 - val_loss: 2.4602 - val_binary_accuracy: 0.5000\n",
      "Epoch 200/450\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 2.4602 - binary_accuracy: 0.5000 - val_loss: 2.4514 - val_binary_accuracy: 0.5000\n",
      "Epoch 201/450\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 2.4514 - binary_accuracy: 0.5000 - val_loss: 2.4427 - val_binary_accuracy: 0.5000\n",
      "Epoch 202/450\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 2.4427 - binary_accuracy: 0.5000 - val_loss: 2.4339 - val_binary_accuracy: 0.5000\n",
      "Epoch 203/450\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 2.4339 - binary_accuracy: 0.5000 - val_loss: 2.4252 - val_binary_accuracy: 0.5000\n",
      "Epoch 204/450\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 2.4252 - binary_accuracy: 0.5000 - val_loss: 2.4165 - val_binary_accuracy: 0.5000\n",
      "Epoch 205/450\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 2.4165 - binary_accuracy: 0.5000 - val_loss: 2.4078 - val_binary_accuracy: 0.5000\n",
      "Epoch 206/450\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 2.4078 - binary_accuracy: 0.5000 - val_loss: 2.3992 - val_binary_accuracy: 0.5000\n",
      "Epoch 207/450\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 2.3992 - binary_accuracy: 0.5000 - val_loss: 2.3905 - val_binary_accuracy: 0.5000\n",
      "Epoch 208/450\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 2.3905 - binary_accuracy: 0.5000 - val_loss: 2.3819 - val_binary_accuracy: 0.5000\n",
      "Epoch 209/450\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 2.3819 - binary_accuracy: 0.5000 - val_loss: 2.3733 - val_binary_accuracy: 0.5000\n",
      "Epoch 210/450\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 2.3733 - binary_accuracy: 0.5000 - val_loss: 2.3647 - val_binary_accuracy: 0.5000\n",
      "Epoch 211/450\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 2.3647 - binary_accuracy: 0.5000 - val_loss: 2.3561 - val_binary_accuracy: 0.5000\n",
      "Epoch 212/450\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 2.3561 - binary_accuracy: 0.5000 - val_loss: 2.3476 - val_binary_accuracy: 0.5000\n",
      "Epoch 213/450\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 2.3476 - binary_accuracy: 0.5000 - val_loss: 2.3390 - val_binary_accuracy: 0.5000\n",
      "Epoch 214/450\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.3390 - binary_accuracy: 0.5000 - val_loss: 2.3305 - val_binary_accuracy: 0.5000\n",
      "Epoch 215/450\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 2.3305 - binary_accuracy: 0.5000 - val_loss: 2.3220 - val_binary_accuracy: 0.5000\n",
      "Epoch 216/450\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 2.3220 - binary_accuracy: 0.5000 - val_loss: 2.3136 - val_binary_accuracy: 0.5000\n",
      "Epoch 217/450\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 2.3136 - binary_accuracy: 0.5000 - val_loss: 2.3051 - val_binary_accuracy: 0.5000\n",
      "Epoch 218/450\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 2.3051 - binary_accuracy: 0.5000 - val_loss: 2.2967 - val_binary_accuracy: 0.5000\n",
      "Epoch 219/450\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 2.2967 - binary_accuracy: 0.5000 - val_loss: 2.2883 - val_binary_accuracy: 0.5000\n",
      "Epoch 220/450\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 2.2883 - binary_accuracy: 0.5000 - val_loss: 2.2799 - val_binary_accuracy: 0.5000\n",
      "Epoch 221/450\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 2.2799 - binary_accuracy: 0.5000 - val_loss: 2.2715 - val_binary_accuracy: 0.5000\n",
      "Epoch 222/450\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 2.2715 - binary_accuracy: 0.5000 - val_loss: 2.2631 - val_binary_accuracy: 0.5000\n",
      "Epoch 223/450\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 2.2631 - binary_accuracy: 0.5000 - val_loss: 2.2548 - val_binary_accuracy: 0.5000\n",
      "Epoch 224/450\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 2.2548 - binary_accuracy: 0.5000 - val_loss: 2.2465 - val_binary_accuracy: 0.5000\n",
      "Epoch 225/450\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 2.2465 - binary_accuracy: 0.5000 - val_loss: 2.2382 - val_binary_accuracy: 0.5000\n",
      "Epoch 226/450\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 2.2382 - binary_accuracy: 0.5000 - val_loss: 2.2299 - val_binary_accuracy: 0.5000\n",
      "Epoch 227/450\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 2.2299 - binary_accuracy: 0.5000 - val_loss: 2.2216 - val_binary_accuracy: 0.5000\n",
      "Epoch 228/450\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 2.2216 - binary_accuracy: 0.5000 - val_loss: 2.2134 - val_binary_accuracy: 0.5000\n",
      "Epoch 229/450\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 2.2134 - binary_accuracy: 0.5000 - val_loss: 2.2052 - val_binary_accuracy: 0.5000\n",
      "Epoch 230/450\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 2.2052 - binary_accuracy: 0.5000 - val_loss: 2.1970 - val_binary_accuracy: 0.5000\n",
      "Epoch 231/450\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 2.1970 - binary_accuracy: 0.5000 - val_loss: 2.1888 - val_binary_accuracy: 0.5000\n",
      "Epoch 232/450\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 2.1888 - binary_accuracy: 0.5000 - val_loss: 2.1806 - val_binary_accuracy: 0.5000\n",
      "Epoch 233/450\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 2.1806 - binary_accuracy: 0.5000 - val_loss: 2.1725 - val_binary_accuracy: 0.5000\n",
      "Epoch 234/450\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 2.1725 - binary_accuracy: 0.5000 - val_loss: 2.1643 - val_binary_accuracy: 0.5000\n",
      "Epoch 235/450\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 2.1643 - binary_accuracy: 0.5000 - val_loss: 2.1562 - val_binary_accuracy: 0.5000\n",
      "Epoch 236/450\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 2.1562 - binary_accuracy: 0.5000 - val_loss: 2.1481 - val_binary_accuracy: 0.5000\n",
      "Epoch 237/450\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 2.1481 - binary_accuracy: 0.5000 - val_loss: 2.1401 - val_binary_accuracy: 0.5000\n",
      "Epoch 238/450\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 2.1401 - binary_accuracy: 0.5000 - val_loss: 2.1320 - val_binary_accuracy: 0.5000\n",
      "Epoch 239/450\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 2.1320 - binary_accuracy: 0.5000 - val_loss: 2.1240 - val_binary_accuracy: 0.5000\n",
      "Epoch 240/450\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 2.1240 - binary_accuracy: 0.5000 - val_loss: 2.1160 - val_binary_accuracy: 0.5000\n",
      "Epoch 241/450\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 2.1160 - binary_accuracy: 0.5000 - val_loss: 2.1080 - val_binary_accuracy: 0.5000\n",
      "Epoch 242/450\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 2.1080 - binary_accuracy: 0.5000 - val_loss: 2.1000 - val_binary_accuracy: 0.5000\n",
      "Epoch 243/450\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 2.1000 - binary_accuracy: 0.5000 - val_loss: 2.0920 - val_binary_accuracy: 0.5000\n",
      "Epoch 244/450\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 2.0920 - binary_accuracy: 0.5000 - val_loss: 2.0841 - val_binary_accuracy: 0.5000\n",
      "Epoch 245/450\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 2.0841 - binary_accuracy: 0.5000 - val_loss: 2.0762 - val_binary_accuracy: 0.5000\n",
      "Epoch 246/450\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.0762 - binary_accuracy: 0.5000 - val_loss: 2.0683 - val_binary_accuracy: 0.5000\n",
      "Epoch 247/450\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 2.0683 - binary_accuracy: 0.5000 - val_loss: 2.0604 - val_binary_accuracy: 0.5000\n",
      "Epoch 248/450\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 2.0604 - binary_accuracy: 0.5000 - val_loss: 2.0525 - val_binary_accuracy: 0.5000\n",
      "Epoch 249/450\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 2.0525 - binary_accuracy: 0.5000 - val_loss: 2.0447 - val_binary_accuracy: 0.5000\n",
      "Epoch 250/450\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 2.0447 - binary_accuracy: 0.5000 - val_loss: 2.0368 - val_binary_accuracy: 0.5000\n",
      "Epoch 251/450\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 2.0368 - binary_accuracy: 0.5000 - val_loss: 2.0290 - val_binary_accuracy: 0.5000\n",
      "Epoch 252/450\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 2.0290 - binary_accuracy: 0.5000 - val_loss: 2.0212 - val_binary_accuracy: 0.5000\n",
      "Epoch 253/450\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 2.0212 - binary_accuracy: 0.5000 - val_loss: 2.0135 - val_binary_accuracy: 0.5000\n",
      "Epoch 254/450\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 2.0135 - binary_accuracy: 0.5000 - val_loss: 2.0057 - val_binary_accuracy: 0.5000\n",
      "Epoch 255/450\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 2.0057 - binary_accuracy: 0.5000 - val_loss: 1.9980 - val_binary_accuracy: 0.5000\n",
      "Epoch 256/450\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 1.9980 - binary_accuracy: 0.5000 - val_loss: 1.9902 - val_binary_accuracy: 0.5000\n",
      "Epoch 257/450\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 1.9902 - binary_accuracy: 0.5000 - val_loss: 1.9825 - val_binary_accuracy: 0.5000\n",
      "Epoch 258/450\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.9825 - binary_accuracy: 0.5000 - val_loss: 1.9749 - val_binary_accuracy: 0.5000\n",
      "Epoch 259/450\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 1.9749 - binary_accuracy: 0.5000 - val_loss: 1.9672 - val_binary_accuracy: 0.5000\n",
      "Epoch 260/450\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 1.9672 - binary_accuracy: 0.5000 - val_loss: 1.9595 - val_binary_accuracy: 0.5000\n",
      "Epoch 261/450\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 1.9595 - binary_accuracy: 0.5000 - val_loss: 1.9519 - val_binary_accuracy: 0.5000\n",
      "Epoch 262/450\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 1.9519 - binary_accuracy: 0.5000 - val_loss: 1.9443 - val_binary_accuracy: 0.5000\n",
      "Epoch 263/450\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 1.9443 - binary_accuracy: 0.5000 - val_loss: 1.9367 - val_binary_accuracy: 0.5000\n",
      "Epoch 264/450\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 1.9367 - binary_accuracy: 0.5000 - val_loss: 1.9291 - val_binary_accuracy: 0.5000\n",
      "Epoch 265/450\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 1.9291 - binary_accuracy: 0.5000 - val_loss: 1.9216 - val_binary_accuracy: 0.5000\n",
      "Epoch 266/450\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 1.9216 - binary_accuracy: 0.5000 - val_loss: 1.9141 - val_binary_accuracy: 0.5000\n",
      "Epoch 267/450\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 1.9141 - binary_accuracy: 0.5000 - val_loss: 1.9065 - val_binary_accuracy: 0.5000\n",
      "Epoch 268/450\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 1.9065 - binary_accuracy: 0.5000 - val_loss: 1.8990 - val_binary_accuracy: 0.5000\n",
      "Epoch 269/450\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 1.8990 - binary_accuracy: 0.5000 - val_loss: 1.8916 - val_binary_accuracy: 0.5000\n",
      "Epoch 270/450\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 1.8916 - binary_accuracy: 0.5000 - val_loss: 1.8841 - val_binary_accuracy: 0.5000\n",
      "Epoch 271/450\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 1.8841 - binary_accuracy: 0.5000 - val_loss: 1.8766 - val_binary_accuracy: 0.5000\n",
      "Epoch 272/450\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 1.8766 - binary_accuracy: 0.5000 - val_loss: 1.8692 - val_binary_accuracy: 0.5000\n",
      "Epoch 273/450\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 1.8692 - binary_accuracy: 0.5000 - val_loss: 1.8618 - val_binary_accuracy: 0.5000\n",
      "Epoch 274/450\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 1.8618 - binary_accuracy: 0.5000 - val_loss: 1.8544 - val_binary_accuracy: 0.5000\n",
      "Epoch 275/450\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 1.8544 - binary_accuracy: 0.5000 - val_loss: 1.8470 - val_binary_accuracy: 0.5000\n",
      "Epoch 276/450\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 1.8470 - binary_accuracy: 0.5000 - val_loss: 1.8397 - val_binary_accuracy: 0.5000\n",
      "Epoch 277/450\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 1.8397 - binary_accuracy: 0.5000 - val_loss: 1.8323 - val_binary_accuracy: 0.5000\n",
      "Epoch 278/450\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 1.8323 - binary_accuracy: 0.5000 - val_loss: 1.8250 - val_binary_accuracy: 0.5000\n",
      "Epoch 279/450\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 1.8250 - binary_accuracy: 0.5000 - val_loss: 1.8180 - val_binary_accuracy: 0.5000\n",
      "Epoch 280/450\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 1.8180 - binary_accuracy: 0.5000 - val_loss: 1.8114 - val_binary_accuracy: 0.5000\n",
      "Epoch 281/450\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 1.8114 - binary_accuracy: 0.5000 - val_loss: 1.8047 - val_binary_accuracy: 0.5000\n",
      "Epoch 282/450\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 1.8047 - binary_accuracy: 0.5000 - val_loss: 1.7980 - val_binary_accuracy: 0.5000\n",
      "Epoch 283/450\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 1.7980 - binary_accuracy: 0.5000 - val_loss: 1.7914 - val_binary_accuracy: 0.5000\n",
      "Epoch 284/450\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 1.7914 - binary_accuracy: 0.5000 - val_loss: 1.7847 - val_binary_accuracy: 0.5000\n",
      "Epoch 285/450\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 1.7847 - binary_accuracy: 0.5000 - val_loss: 1.7780 - val_binary_accuracy: 0.5000\n",
      "Epoch 286/450\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 1.7780 - binary_accuracy: 0.5000 - val_loss: 1.7714 - val_binary_accuracy: 0.5000\n",
      "Epoch 287/450\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 1.7714 - binary_accuracy: 0.5000 - val_loss: 1.7647 - val_binary_accuracy: 0.5000\n",
      "Epoch 288/450\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 1.7647 - binary_accuracy: 0.5000 - val_loss: 1.7581 - val_binary_accuracy: 0.5000\n",
      "Epoch 289/450\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 1.7581 - binary_accuracy: 0.5000 - val_loss: 1.7514 - val_binary_accuracy: 0.5000\n",
      "Epoch 290/450\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 1.7514 - binary_accuracy: 0.5000 - val_loss: 1.7448 - val_binary_accuracy: 0.5000\n",
      "Epoch 291/450\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 1.7448 - binary_accuracy: 0.5000 - val_loss: 1.7382 - val_binary_accuracy: 0.5000\n",
      "Epoch 292/450\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 1.7382 - binary_accuracy: 0.5000 - val_loss: 1.7315 - val_binary_accuracy: 0.5000\n",
      "Epoch 293/450\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 1.7315 - binary_accuracy: 0.5000 - val_loss: 1.7249 - val_binary_accuracy: 0.5000\n",
      "Epoch 294/450\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 1.7249 - binary_accuracy: 0.5000 - val_loss: 1.7183 - val_binary_accuracy: 0.5000\n",
      "Epoch 295/450\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 1.7183 - binary_accuracy: 0.5000 - val_loss: 1.7117 - val_binary_accuracy: 0.5000\n",
      "Epoch 296/450\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 1.7117 - binary_accuracy: 0.5000 - val_loss: 1.7051 - val_binary_accuracy: 0.5000\n",
      "Epoch 297/450\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 1.7051 - binary_accuracy: 0.5000 - val_loss: 1.6985 - val_binary_accuracy: 0.5000\n",
      "Epoch 298/450\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 1.6985 - binary_accuracy: 0.5000 - val_loss: 1.6919 - val_binary_accuracy: 0.5000\n",
      "Epoch 299/450\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 1.6919 - binary_accuracy: 0.5000 - val_loss: 1.6853 - val_binary_accuracy: 0.5000\n",
      "Epoch 300/450\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 1.6853 - binary_accuracy: 0.5000 - val_loss: 1.6788 - val_binary_accuracy: 0.5000\n",
      "Epoch 301/450\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 1.6788 - binary_accuracy: 0.5000 - val_loss: 1.6722 - val_binary_accuracy: 0.5000\n",
      "Epoch 302/450\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 1.6722 - binary_accuracy: 0.5000 - val_loss: 1.6657 - val_binary_accuracy: 0.5000\n",
      "Epoch 303/450\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 1.6657 - binary_accuracy: 0.5000 - val_loss: 1.6592 - val_binary_accuracy: 0.5000\n",
      "Epoch 304/450\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 1.6592 - binary_accuracy: 0.5000 - val_loss: 1.6527 - val_binary_accuracy: 0.5000\n",
      "Epoch 305/450\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 1.6527 - binary_accuracy: 0.5000 - val_loss: 1.6461 - val_binary_accuracy: 0.5000\n",
      "Epoch 306/450\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 1.6462 - binary_accuracy: 0.5000 - val_loss: 1.6397 - val_binary_accuracy: 0.5000\n",
      "Epoch 307/450\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 1.6397 - binary_accuracy: 0.5000 - val_loss: 1.6332 - val_binary_accuracy: 0.5000\n",
      "Epoch 308/450\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 1.6332 - binary_accuracy: 0.5000 - val_loss: 1.6267 - val_binary_accuracy: 0.5000\n",
      "Epoch 309/450\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 1.6267 - binary_accuracy: 0.5000 - val_loss: 1.6203 - val_binary_accuracy: 0.5000\n",
      "Epoch 310/450\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 1.6203 - binary_accuracy: 0.5000 - val_loss: 1.6138 - val_binary_accuracy: 0.5000\n",
      "Epoch 311/450\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 1.6138 - binary_accuracy: 0.5000 - val_loss: 1.6074 - val_binary_accuracy: 0.5000\n",
      "Epoch 312/450\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 1.6074 - binary_accuracy: 0.5000 - val_loss: 1.6010 - val_binary_accuracy: 0.5000\n",
      "Epoch 313/450\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 1.6010 - binary_accuracy: 0.5000 - val_loss: 1.5946 - val_binary_accuracy: 0.5000\n",
      "Epoch 314/450\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 1.5946 - binary_accuracy: 0.5000 - val_loss: 1.5882 - val_binary_accuracy: 0.5000\n",
      "Epoch 315/450\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 1.5882 - binary_accuracy: 0.5000 - val_loss: 1.5818 - val_binary_accuracy: 0.5000\n",
      "Epoch 316/450\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 1.5818 - binary_accuracy: 0.5000 - val_loss: 1.5754 - val_binary_accuracy: 0.5000\n",
      "Epoch 317/450\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 1.5754 - binary_accuracy: 0.5000 - val_loss: 1.5691 - val_binary_accuracy: 0.5000\n",
      "Epoch 318/450\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 1.5691 - binary_accuracy: 0.5000 - val_loss: 1.5627 - val_binary_accuracy: 0.5000\n",
      "Epoch 319/450\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 1.5627 - binary_accuracy: 0.5000 - val_loss: 1.5564 - val_binary_accuracy: 0.5000\n",
      "Epoch 320/450\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 1.5564 - binary_accuracy: 0.5000 - val_loss: 1.5501 - val_binary_accuracy: 0.5000\n",
      "Epoch 321/450\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 1.5501 - binary_accuracy: 0.5000 - val_loss: 1.5438 - val_binary_accuracy: 0.5000\n",
      "Epoch 322/450\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 1.5438 - binary_accuracy: 0.5000 - val_loss: 1.5375 - val_binary_accuracy: 0.5000\n",
      "Epoch 323/450\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 1.5375 - binary_accuracy: 0.5000 - val_loss: 1.5313 - val_binary_accuracy: 0.5000\n",
      "Epoch 324/450\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 1.5313 - binary_accuracy: 0.5000 - val_loss: 1.5250 - val_binary_accuracy: 0.5000\n",
      "Epoch 325/450\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 1.5250 - binary_accuracy: 0.5000 - val_loss: 1.5188 - val_binary_accuracy: 0.5000\n",
      "Epoch 326/450\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 1.5188 - binary_accuracy: 0.5000 - val_loss: 1.5126 - val_binary_accuracy: 0.5000\n",
      "Epoch 327/450\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 1.5126 - binary_accuracy: 0.5000 - val_loss: 1.5064 - val_binary_accuracy: 0.5000\n",
      "Epoch 328/450\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 1.5064 - binary_accuracy: 0.5000 - val_loss: 1.5002 - val_binary_accuracy: 0.5000\n",
      "Epoch 329/450\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 1.5002 - binary_accuracy: 0.5000 - val_loss: 1.4940 - val_binary_accuracy: 0.5000\n",
      "Epoch 330/450\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 1.4940 - binary_accuracy: 0.5000 - val_loss: 1.4878 - val_binary_accuracy: 0.5000\n",
      "Epoch 331/450\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 1.4878 - binary_accuracy: 0.5000 - val_loss: 1.4817 - val_binary_accuracy: 0.5000\n",
      "Epoch 332/450\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 1.4817 - binary_accuracy: 0.5000 - val_loss: 1.4755 - val_binary_accuracy: 0.5000\n",
      "Epoch 333/450\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 1.4755 - binary_accuracy: 0.5000 - val_loss: 1.4694 - val_binary_accuracy: 0.5000\n",
      "Epoch 334/450\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 1.4694 - binary_accuracy: 0.5000 - val_loss: 1.4633 - val_binary_accuracy: 0.5000\n",
      "Epoch 335/450\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 1.4633 - binary_accuracy: 0.5000 - val_loss: 1.4572 - val_binary_accuracy: 0.5000\n",
      "Epoch 336/450\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 1.4572 - binary_accuracy: 0.5000 - val_loss: 1.4511 - val_binary_accuracy: 0.5000\n",
      "Epoch 337/450\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 1.4511 - binary_accuracy: 0.5000 - val_loss: 1.4451 - val_binary_accuracy: 0.5000\n",
      "Epoch 338/450\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.4451 - binary_accuracy: 0.5000 - val_loss: 1.4390 - val_binary_accuracy: 0.5000\n",
      "Epoch 339/450\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 1.4390 - binary_accuracy: 0.5000 - val_loss: 1.4330 - val_binary_accuracy: 0.5000\n",
      "Epoch 340/450\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 1.4330 - binary_accuracy: 0.5000 - val_loss: 1.4269 - val_binary_accuracy: 0.5000\n",
      "Epoch 341/450\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 1.4269 - binary_accuracy: 0.5000 - val_loss: 1.4209 - val_binary_accuracy: 0.5000\n",
      "Epoch 342/450\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 1.4209 - binary_accuracy: 0.5000 - val_loss: 1.4149 - val_binary_accuracy: 0.5000\n",
      "Epoch 343/450\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 1.4149 - binary_accuracy: 0.5000 - val_loss: 1.4089 - val_binary_accuracy: 0.5000\n",
      "Epoch 344/450\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 1.4089 - binary_accuracy: 0.5000 - val_loss: 1.4030 - val_binary_accuracy: 0.5000\n",
      "Epoch 345/450\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 1.4030 - binary_accuracy: 0.5000 - val_loss: 1.3970 - val_binary_accuracy: 0.5000\n",
      "Epoch 346/450\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 1.3970 - binary_accuracy: 0.5000 - val_loss: 1.3911 - val_binary_accuracy: 0.5000\n",
      "Epoch 347/450\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 1.3911 - binary_accuracy: 0.5000 - val_loss: 1.3852 - val_binary_accuracy: 0.5000\n",
      "Epoch 348/450\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 1.3852 - binary_accuracy: 0.5000 - val_loss: 1.3793 - val_binary_accuracy: 0.5000\n",
      "Epoch 349/450\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 1.3793 - binary_accuracy: 0.5000 - val_loss: 1.3734 - val_binary_accuracy: 0.5000\n",
      "Epoch 350/450\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 1.3734 - binary_accuracy: 0.5000 - val_loss: 1.3675 - val_binary_accuracy: 0.5000\n",
      "Epoch 351/450\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 1.3675 - binary_accuracy: 0.5000 - val_loss: 1.3616 - val_binary_accuracy: 0.5000\n",
      "Epoch 352/450\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 1.3616 - binary_accuracy: 0.5000 - val_loss: 1.3558 - val_binary_accuracy: 0.5000\n",
      "Epoch 353/450\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 1.3558 - binary_accuracy: 0.5000 - val_loss: 1.3499 - val_binary_accuracy: 0.5000\n",
      "Epoch 354/450\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 1.3499 - binary_accuracy: 0.5000 - val_loss: 1.3441 - val_binary_accuracy: 0.5000\n",
      "Epoch 355/450\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 1.3441 - binary_accuracy: 0.5000 - val_loss: 1.3383 - val_binary_accuracy: 0.5000\n",
      "Epoch 356/450\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 1.3383 - binary_accuracy: 0.5000 - val_loss: 1.3325 - val_binary_accuracy: 0.5000\n",
      "Epoch 357/450\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 1.3325 - binary_accuracy: 0.5000 - val_loss: 1.3267 - val_binary_accuracy: 0.5000\n",
      "Epoch 358/450\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 1.3267 - binary_accuracy: 0.5000 - val_loss: 1.3209 - val_binary_accuracy: 0.5000\n",
      "Epoch 359/450\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 1.3209 - binary_accuracy: 0.5000 - val_loss: 1.3152 - val_binary_accuracy: 0.5000\n",
      "Epoch 360/450\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 1.3152 - binary_accuracy: 0.5000 - val_loss: 1.3094 - val_binary_accuracy: 0.5000\n",
      "Epoch 361/450\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 1.3094 - binary_accuracy: 0.5000 - val_loss: 1.3037 - val_binary_accuracy: 0.5000\n",
      "Epoch 362/450\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 1.3037 - binary_accuracy: 0.5000 - val_loss: 1.2980 - val_binary_accuracy: 0.5000\n",
      "Epoch 363/450\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 1.2980 - binary_accuracy: 0.5000 - val_loss: 1.2923 - val_binary_accuracy: 0.5000\n",
      "Epoch 364/450\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 1.2923 - binary_accuracy: 0.5000 - val_loss: 1.2866 - val_binary_accuracy: 0.5000\n",
      "Epoch 365/450\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 1.2866 - binary_accuracy: 0.5000 - val_loss: 1.2809 - val_binary_accuracy: 0.5000\n",
      "Epoch 366/450\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 1.2809 - binary_accuracy: 0.5000 - val_loss: 1.2753 - val_binary_accuracy: 0.5000\n",
      "Epoch 367/450\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 1.2753 - binary_accuracy: 0.5000 - val_loss: 1.2696 - val_binary_accuracy: 0.5000\n",
      "Epoch 368/450\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 1.2696 - binary_accuracy: 0.5000 - val_loss: 1.2640 - val_binary_accuracy: 0.5000\n",
      "Epoch 369/450\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 1.2640 - binary_accuracy: 0.5000 - val_loss: 1.2584 - val_binary_accuracy: 0.5000\n",
      "Epoch 370/450\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 1.2584 - binary_accuracy: 0.5000 - val_loss: 1.2528 - val_binary_accuracy: 0.5000\n",
      "Epoch 371/450\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 1.2528 - binary_accuracy: 0.5000 - val_loss: 1.2472 - val_binary_accuracy: 0.5000\n",
      "Epoch 372/450\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 1.2472 - binary_accuracy: 0.5000 - val_loss: 1.2416 - val_binary_accuracy: 0.5000\n",
      "Epoch 373/450\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 1.2416 - binary_accuracy: 0.5000 - val_loss: 1.2360 - val_binary_accuracy: 0.5000\n",
      "Epoch 374/450\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 1.2360 - binary_accuracy: 0.5000 - val_loss: 1.2305 - val_binary_accuracy: 0.5000\n",
      "Epoch 375/450\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 1.2305 - binary_accuracy: 0.5000 - val_loss: 1.2250 - val_binary_accuracy: 0.5000\n",
      "Epoch 376/450\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 1.2250 - binary_accuracy: 0.5000 - val_loss: 1.2194 - val_binary_accuracy: 0.5000\n",
      "Epoch 377/450\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 1.2194 - binary_accuracy: 0.5000 - val_loss: 1.2139 - val_binary_accuracy: 0.5000\n",
      "Epoch 378/450\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 1.2139 - binary_accuracy: 0.5000 - val_loss: 1.2084 - val_binary_accuracy: 0.5000\n",
      "Epoch 379/450\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 1.2084 - binary_accuracy: 0.5000 - val_loss: 1.2030 - val_binary_accuracy: 0.5000\n",
      "Epoch 380/450\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 1.2030 - binary_accuracy: 0.5000 - val_loss: 1.1975 - val_binary_accuracy: 0.5000\n",
      "Epoch 381/450\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 1.1975 - binary_accuracy: 0.5000 - val_loss: 1.1920 - val_binary_accuracy: 0.5000\n",
      "Epoch 382/450\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 1.1920 - binary_accuracy: 0.5000 - val_loss: 1.1866 - val_binary_accuracy: 0.5000\n",
      "Epoch 383/450\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 1.1866 - binary_accuracy: 0.5000 - val_loss: 1.1812 - val_binary_accuracy: 0.5000\n",
      "Epoch 384/450\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 1.1812 - binary_accuracy: 0.5000 - val_loss: 1.1758 - val_binary_accuracy: 0.5000\n",
      "Epoch 385/450\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 1.1758 - binary_accuracy: 0.5000 - val_loss: 1.1704 - val_binary_accuracy: 0.5000\n",
      "Epoch 386/450\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 1.1704 - binary_accuracy: 0.5000 - val_loss: 1.1650 - val_binary_accuracy: 0.5000\n",
      "Epoch 387/450\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 1.1650 - binary_accuracy: 0.5000 - val_loss: 1.1596 - val_binary_accuracy: 0.5000\n",
      "Epoch 388/450\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 1.1596 - binary_accuracy: 0.5000 - val_loss: 1.1542 - val_binary_accuracy: 0.5000\n",
      "Epoch 389/450\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 1.1542 - binary_accuracy: 0.5000 - val_loss: 1.1489 - val_binary_accuracy: 0.5000\n",
      "Epoch 390/450\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 1.1489 - binary_accuracy: 0.5000 - val_loss: 1.1436 - val_binary_accuracy: 0.5000\n",
      "Epoch 391/450\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 1.1436 - binary_accuracy: 0.5000 - val_loss: 1.1383 - val_binary_accuracy: 0.5000\n",
      "Epoch 392/450\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 1.1383 - binary_accuracy: 0.5000 - val_loss: 1.1330 - val_binary_accuracy: 0.5000\n",
      "Epoch 393/450\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 1.1330 - binary_accuracy: 0.5000 - val_loss: 1.1277 - val_binary_accuracy: 0.5000\n",
      "Epoch 394/450\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 1.1277 - binary_accuracy: 0.5000 - val_loss: 1.1224 - val_binary_accuracy: 0.5000\n",
      "Epoch 395/450\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 1.1224 - binary_accuracy: 0.5000 - val_loss: 1.1171 - val_binary_accuracy: 0.5000\n",
      "Epoch 396/450\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 1.1171 - binary_accuracy: 0.5000 - val_loss: 1.1119 - val_binary_accuracy: 0.5000\n",
      "Epoch 397/450\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 1.1119 - binary_accuracy: 0.5000 - val_loss: 1.1066 - val_binary_accuracy: 0.5000\n",
      "Epoch 398/450\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 1.1066 - binary_accuracy: 0.5000 - val_loss: 1.1014 - val_binary_accuracy: 0.5000\n",
      "Epoch 399/450\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 1.1014 - binary_accuracy: 0.5000 - val_loss: 1.0962 - val_binary_accuracy: 0.5000\n",
      "Epoch 400/450\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 1.0962 - binary_accuracy: 0.5000 - val_loss: 1.0910 - val_binary_accuracy: 0.5000\n",
      "Epoch 401/450\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 1.0910 - binary_accuracy: 0.5000 - val_loss: 1.0858 - val_binary_accuracy: 0.5000\n",
      "Epoch 402/450\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 1.0858 - binary_accuracy: 0.5000 - val_loss: 1.0806 - val_binary_accuracy: 0.5000\n",
      "Epoch 403/450\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 1.0806 - binary_accuracy: 0.5000 - val_loss: 1.0755 - val_binary_accuracy: 0.5000\n",
      "Epoch 404/450\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 1.0755 - binary_accuracy: 0.5000 - val_loss: 1.0703 - val_binary_accuracy: 0.5000\n",
      "Epoch 405/450\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 1.0703 - binary_accuracy: 0.5000 - val_loss: 1.0652 - val_binary_accuracy: 0.5000\n",
      "Epoch 406/450\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 1.0652 - binary_accuracy: 0.5000 - val_loss: 1.0601 - val_binary_accuracy: 0.5000\n",
      "Epoch 407/450\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 1.0601 - binary_accuracy: 0.5000 - val_loss: 1.0550 - val_binary_accuracy: 0.5000\n",
      "Epoch 408/450\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 1.0550 - binary_accuracy: 0.5000 - val_loss: 1.0499 - val_binary_accuracy: 0.5000\n",
      "Epoch 409/450\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 1.0499 - binary_accuracy: 0.5000 - val_loss: 1.0448 - val_binary_accuracy: 0.5000\n",
      "Epoch 410/450\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 1.0448 - binary_accuracy: 0.5000 - val_loss: 1.0397 - val_binary_accuracy: 0.5000\n",
      "Epoch 411/450\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 1.0397 - binary_accuracy: 0.5000 - val_loss: 1.0347 - val_binary_accuracy: 0.5000\n",
      "Epoch 412/450\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 1.0347 - binary_accuracy: 0.5000 - val_loss: 1.0296 - val_binary_accuracy: 0.5000\n",
      "Epoch 413/450\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 1.0296 - binary_accuracy: 0.5000 - val_loss: 1.0246 - val_binary_accuracy: 0.5000\n",
      "Epoch 414/450\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 1.0246 - binary_accuracy: 0.5000 - val_loss: 1.0196 - val_binary_accuracy: 0.5000\n",
      "Epoch 415/450\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 1.0196 - binary_accuracy: 0.5000 - val_loss: 1.0146 - val_binary_accuracy: 0.5000\n",
      "Epoch 416/450\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 1.0146 - binary_accuracy: 0.5000 - val_loss: 1.0096 - val_binary_accuracy: 0.5000\n",
      "Epoch 417/450\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 1.0096 - binary_accuracy: 0.5000 - val_loss: 1.0046 - val_binary_accuracy: 0.5000\n",
      "Epoch 418/450\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 1.0046 - binary_accuracy: 0.5000 - val_loss: 0.9997 - val_binary_accuracy: 0.5000\n",
      "Epoch 419/450\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.9997 - binary_accuracy: 0.5000 - val_loss: 0.9947 - val_binary_accuracy: 0.5000\n",
      "Epoch 420/450\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.9947 - binary_accuracy: 0.5000 - val_loss: 0.9898 - val_binary_accuracy: 0.5000\n",
      "Epoch 421/450\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.9898 - binary_accuracy: 0.5000 - val_loss: 0.9849 - val_binary_accuracy: 0.5000\n",
      "Epoch 422/450\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.9849 - binary_accuracy: 0.5000 - val_loss: 0.9800 - val_binary_accuracy: 0.5000\n",
      "Epoch 423/450\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.9800 - binary_accuracy: 0.5000 - val_loss: 0.9751 - val_binary_accuracy: 0.5000\n",
      "Epoch 424/450\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.9751 - binary_accuracy: 0.5000 - val_loss: 0.9702 - val_binary_accuracy: 0.5000\n",
      "Epoch 425/450\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.9702 - binary_accuracy: 0.5000 - val_loss: 0.9653 - val_binary_accuracy: 0.5000\n",
      "Epoch 426/450\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.9653 - binary_accuracy: 0.5000 - val_loss: 0.9604 - val_binary_accuracy: 0.5000\n",
      "Epoch 427/450\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.9604 - binary_accuracy: 0.5000 - val_loss: 0.9556 - val_binary_accuracy: 0.5000\n",
      "Epoch 428/450\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.9556 - binary_accuracy: 0.5000 - val_loss: 0.9508 - val_binary_accuracy: 0.5000\n",
      "Epoch 429/450\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.9508 - binary_accuracy: 0.5000 - val_loss: 0.9459 - val_binary_accuracy: 0.5000\n",
      "Epoch 430/450\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.9459 - binary_accuracy: 0.5000 - val_loss: 0.9411 - val_binary_accuracy: 0.5000\n",
      "Epoch 431/450\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.9411 - binary_accuracy: 0.5000 - val_loss: 0.9363 - val_binary_accuracy: 0.5000\n",
      "Epoch 432/450\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.9363 - binary_accuracy: 0.5000 - val_loss: 0.9315 - val_binary_accuracy: 0.5000\n",
      "Epoch 433/450\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.9315 - binary_accuracy: 0.5000 - val_loss: 0.9268 - val_binary_accuracy: 0.5000\n",
      "Epoch 434/450\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.9268 - binary_accuracy: 0.5000 - val_loss: 0.9220 - val_binary_accuracy: 0.5000\n",
      "Epoch 435/450\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.9220 - binary_accuracy: 0.5000 - val_loss: 0.9173 - val_binary_accuracy: 0.5000\n",
      "Epoch 436/450\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.9173 - binary_accuracy: 0.5000 - val_loss: 0.9125 - val_binary_accuracy: 0.5000\n",
      "Epoch 437/450\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.9125 - binary_accuracy: 0.5000 - val_loss: 0.9078 - val_binary_accuracy: 0.5000\n",
      "Epoch 438/450\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.9078 - binary_accuracy: 0.5000 - val_loss: 0.9031 - val_binary_accuracy: 0.5000\n",
      "Epoch 439/450\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.9031 - binary_accuracy: 0.5000 - val_loss: 0.8984 - val_binary_accuracy: 0.5000\n",
      "Epoch 440/450\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.8984 - binary_accuracy: 0.5000 - val_loss: 0.8937 - val_binary_accuracy: 0.5000\n",
      "Epoch 441/450\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.8937 - binary_accuracy: 0.5000 - val_loss: 0.8891 - val_binary_accuracy: 0.5000\n",
      "Epoch 442/450\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.8891 - binary_accuracy: 0.5000 - val_loss: 0.8844 - val_binary_accuracy: 0.5000\n",
      "Epoch 443/450\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.8844 - binary_accuracy: 0.5000 - val_loss: 0.8798 - val_binary_accuracy: 0.5000\n",
      "Epoch 444/450\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.8798 - binary_accuracy: 0.5000 - val_loss: 0.8751 - val_binary_accuracy: 0.5000\n",
      "Epoch 445/450\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.8751 - binary_accuracy: 0.5000 - val_loss: 0.8705 - val_binary_accuracy: 0.5000\n",
      "Epoch 446/450\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.8705 - binary_accuracy: 0.5000 - val_loss: 0.8659 - val_binary_accuracy: 0.5000\n",
      "Epoch 447/450\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.8659 - binary_accuracy: 0.5000 - val_loss: 0.8613 - val_binary_accuracy: 0.5000\n",
      "Epoch 448/450\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.8613 - binary_accuracy: 0.5000 - val_loss: 0.8567 - val_binary_accuracy: 0.5000\n",
      "Epoch 449/450\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.8567 - binary_accuracy: 0.5000 - val_loss: 0.8521 - val_binary_accuracy: 0.5000\n",
      "Epoch 450/450\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.8521 - binary_accuracy: 0.5000 - val_loss: 0.8476 - val_binary_accuracy: 0.5000\n",
      "Minimum Validation Loss: 0.84758\n"
     ]
    }
   ],
   "source": [
    "\n",
    "accuracy = tf.keras.metrics.BinaryAccuracy(\n",
    "    name=\"binary_accuracy\", dtype=None, threshold=0.5\n",
    ")\n",
    "\n",
    "model.compile(\n",
    "    # optimizer='adam',\n",
    "     loss='mae',\n",
    "    # loss='mean_squared_error',\n",
    "    # loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    # metrics=[accuracy]\n",
    "    metrics=['binary_accuracy']\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_valid, y_valid),\n",
    "    batch_size=4,# grupy danych\n",
    "    epochs=450\n",
    "    # ,callbacks=[early_stopping]\n",
    ")\n",
    "# print(model.summary())\n",
    "\n",
    "# Generates pdf with network structure\n",
    "# ann_viz(model, title=\"XOR\")\n",
    "# graph = Source.from_file('network.gv')\n",
    "# graph\n",
    "\n",
    "history_df = pd.DataFrame(history.history)\n",
    "print(\"Minimum Validation Loss: {:0.5f}\".format(history_df['val_loss'].min()));"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 14ms/step\n",
      "-5\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "[[-5.681402]]\n"
     ]
    }
   ],
   "source": [
    "print(int(model.predict(np.array([[0, 1]]))))\n",
    "print(model.predict(np.array([[0, 1]])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights:  [[ 0.04757896  0.69323766  0.49377072  0.5555716  -0.37558532  0.22841941\n",
      "   0.55715024  0.67320645]\n",
      " [ 0.63070005 -0.23502812  0.35738727 -0.8802934  -0.6858322  -0.14399374\n",
      "  -0.8802146  -0.57518524]]\n",
      "biases:  [-4.4502180e-02  9.5919124e-05  2.2936973e-01 -2.6172181e-03\n",
      "  0.0000000e+00  2.2141884e-01 -2.2290740e-04 -5.1573571e-04]\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "history_df.loc[109:, ['loss', 'val_loss']].plot()\n",
    "weights = model.layers[1].get_weights()[0]\n",
    "biases = model.layers[1].get_weights()[1]\n",
    "print('weights: ', weights)\n",
    "print('biases: ', biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unknown activation function: max_pool. Please ensure this object is passed to the `custom_objects` argument. See https://www.tensorflow.org/guide/keras/save_and_serialize#registering_the_custom_object for details.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[8], line 9\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mmatplotlib\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpyplot\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mplt\u001B[39;00m\n\u001B[1;32m      7\u001B[0m \u001B[38;5;66;03m# print(tf.__version__)\u001B[39;00m\n\u001B[0;32m----> 9\u001B[0m activation_layer \u001B[38;5;241m=\u001B[39m \u001B[43mlayers\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mActivation\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mmax_pool\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m     11\u001B[0m x \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39mlinspace(\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m3.0\u001B[39m, \u001B[38;5;241m3.0\u001B[39m, \u001B[38;5;241m100\u001B[39m)\n\u001B[1;32m     12\u001B[0m y \u001B[38;5;241m=\u001B[39m activation_layer(x)  \u001B[38;5;66;03m# once created, a layer is callable just like a function\u001B[39;00m\n",
      "File \u001B[0;32m~/.local/share/virtualenvs/data-science-upskills-eseJr18D/lib/python3.10/site-packages/keras/layers/core/activation.py:56\u001B[0m, in \u001B[0;36mActivation.__init__\u001B[0;34m(self, activation, **kwargs)\u001B[0m\n\u001B[1;32m     54\u001B[0m \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m     55\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msupports_masking \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m---> 56\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mactivation \u001B[38;5;241m=\u001B[39m \u001B[43mactivations\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[43mactivation\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.local/share/virtualenvs/data-science-upskills-eseJr18D/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:153\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    151\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    152\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[0;32m--> 153\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28mNone\u001B[39m\n\u001B[1;32m    154\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m    155\u001B[0m   \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "File \u001B[0;32m~/.local/share/virtualenvs/data-science-upskills-eseJr18D/lib/python3.10/site-packages/keras/activations.py:609\u001B[0m, in \u001B[0;36mget\u001B[0;34m(identifier)\u001B[0m\n\u001B[1;32m    607\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m linear\n\u001B[1;32m    608\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(identifier, (\u001B[38;5;28mstr\u001B[39m, \u001B[38;5;28mdict\u001B[39m)):\n\u001B[0;32m--> 609\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mdeserialize\u001B[49m\u001B[43m(\u001B[49m\u001B[43midentifier\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    610\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m callable(identifier):\n\u001B[1;32m    611\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m identifier\n",
      "File \u001B[0;32m~/.local/share/virtualenvs/data-science-upskills-eseJr18D/lib/python3.10/site-packages/keras/activations.py:568\u001B[0m, in \u001B[0;36mdeserialize\u001B[0;34m(name, custom_objects)\u001B[0m\n\u001B[1;32m    560\u001B[0m \u001B[38;5;66;03m# we put 'current_module' after 'activation_layers' to prefer the local one\u001B[39;00m\n\u001B[1;32m    561\u001B[0m \u001B[38;5;66;03m# if there is a collision\u001B[39;00m\n\u001B[1;32m    562\u001B[0m generic_utils\u001B[38;5;241m.\u001B[39mpopulate_dict_with_module_objects(\n\u001B[1;32m    563\u001B[0m     activation_functions,\n\u001B[1;32m    564\u001B[0m     (activation_layers, current_module),\n\u001B[1;32m    565\u001B[0m     obj_filter\u001B[38;5;241m=\u001B[39mcallable,\n\u001B[1;32m    566\u001B[0m )\n\u001B[0;32m--> 568\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mgeneric_utils\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdeserialize_keras_object\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    569\u001B[0m \u001B[43m    \u001B[49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    570\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmodule_objects\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mactivation_functions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    571\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcustom_objects\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcustom_objects\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    572\u001B[0m \u001B[43m    \u001B[49m\u001B[43mprintable_module_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mactivation function\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    573\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.local/share/virtualenvs/data-science-upskills-eseJr18D/lib/python3.10/site-packages/keras/utils/generic_utils.py:769\u001B[0m, in \u001B[0;36mdeserialize_keras_object\u001B[0;34m(identifier, module_objects, custom_objects, printable_module_name)\u001B[0m\n\u001B[1;32m    767\u001B[0m     obj \u001B[38;5;241m=\u001B[39m module_objects\u001B[38;5;241m.\u001B[39mget(object_name)\n\u001B[1;32m    768\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m obj \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 769\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    770\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mUnknown \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mprintable_module_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mobject_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m. Please \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    771\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mensure this object is passed to the `custom_objects` \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    772\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124margument. See \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    773\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhttps://www.tensorflow.org/guide/keras/save_and_serialize\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    774\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m#registering_the_custom_object for details.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    775\u001B[0m         )\n\u001B[1;32m    777\u001B[0m \u001B[38;5;66;03m# Classes passed by name are instantiated with no args, functions are\u001B[39;00m\n\u001B[1;32m    778\u001B[0m \u001B[38;5;66;03m# returned as-is.\u001B[39;00m\n\u001B[1;32m    779\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m tf_inspect\u001B[38;5;241m.\u001B[39misclass(obj):\n",
      "\u001B[0;31mValueError\u001B[0m: Unknown activation function: max_pool. Please ensure this object is passed to the `custom_objects` argument. See https://www.tensorflow.org/guide/keras/save_and_serialize#registering_the_custom_object for details."
     ]
    }
   ],
   "source": [
    "# Change 'relu' to 'elu', 'selu', 'swish', sigmoid... or something else\n",
    "# How different activation functions look like\n",
    "\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# print(tf.__version__)\n",
    "\n",
    "activation_layer = layers.Activation('max_pool')\n",
    "\n",
    "x = tf.linspace(-3.0, 3.0, 100)\n",
    "y = activation_layer(x)  # once created, a layer is callable just like a function\n",
    "\n",
    "plt.figure(dpi=100)\n",
    "plt.plot(x, y)\n",
    "plt.xlim(-3, 3)\n",
    "plt.xlabel(\"Input\")\n",
    "plt.ylabel(\"Output\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}