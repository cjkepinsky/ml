{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 2)\n",
      "y: (4,)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from libs.simple_processing import separate_target\n",
    "\n",
    "DATA = pd.read_csv('xor.csv', delimiter=';')\n",
    "\n",
    "X, y = separate_target(DATA, 'y')\n",
    "\n",
    "print(X.shape)\n",
    "print('y:', y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   x1  x2\n",
      "0   0   0\n",
      "1   0   1\n",
      "2   1   0\n",
      "3   1   1\n",
      "0    0\n",
      "1    1\n",
      "2    1\n",
      "3    0\n",
      "Name: y, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(X.head())\n",
    "print(y.head())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2]\n",
      "(4, 2)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# patience below 7 cuts to early\n",
    "early_stopping = EarlyStopping(\n",
    "    min_delta=0.0005,  # minimium amount of change to count as an improvement\n",
    "    patience=7,  # how many epochs to wait before stopping\n",
    "    restore_best_weights=True,\n",
    ")\n",
    "# X_train, X_valid, y_train, y_valid = train_test_split(X, y, train_size=0.6, random_state=40)\n",
    "\n",
    "X_train = X.copy()\n",
    "y_train = y.copy()\n",
    "X_valid = X.copy()\n",
    "y_valid = y.copy()\n",
    "\n",
    "input_shape = [X_train.shape[1]]\n",
    "print(input_shape)\n",
    "print(X_train.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0\n",
      "1    1\n",
      "2    1\n",
      "3    0\n",
      "Name: y, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1629 - binary_accuracy: 0.7500"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-10 17:38:03.375871: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 501ms/step - loss: 0.1629 - binary_accuracy: 0.7500 - val_loss: 0.1526 - val_binary_accuracy: 0.7500\n",
      "Epoch 2/250\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.1526 - binary_accuracy: 0.7500 - val_loss: 0.1455 - val_binary_accuracy: 0.7500\n",
      "Epoch 3/250\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.1455 - binary_accuracy: 0.7500 - val_loss: 0.1397 - val_binary_accuracy: 0.7500\n",
      "Epoch 4/250\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.1397 - binary_accuracy: 0.7500 - val_loss: 0.1348 - val_binary_accuracy: 0.7500\n",
      "Epoch 5/250\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.1348 - binary_accuracy: 0.7500 - val_loss: 0.1304 - val_binary_accuracy: 0.7500\n",
      "Epoch 6/250\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.1304 - binary_accuracy: 0.7500 - val_loss: 0.1265 - val_binary_accuracy: 0.7500\n",
      "Epoch 7/250\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1265 - binary_accuracy: 0.7500"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-10 17:38:03.622758: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1265 - binary_accuracy: 0.7500 - val_loss: 0.1228 - val_binary_accuracy: 0.7500\n",
      "Epoch 8/250\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.1228 - binary_accuracy: 0.7500 - val_loss: 0.1194 - val_binary_accuracy: 0.7500\n",
      "Epoch 9/250\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.1194 - binary_accuracy: 0.7500 - val_loss: 0.1162 - val_binary_accuracy: 0.7500\n",
      "Epoch 10/250\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1162 - binary_accuracy: 0.7500 - val_loss: 0.1132 - val_binary_accuracy: 0.7500\n",
      "Epoch 11/250\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1132 - binary_accuracy: 0.7500 - val_loss: 0.1103 - val_binary_accuracy: 0.7500\n",
      "Epoch 12/250\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.1103 - binary_accuracy: 0.7500 - val_loss: 0.1076 - val_binary_accuracy: 0.7500\n",
      "Epoch 13/250\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.1076 - binary_accuracy: 0.7500 - val_loss: 0.1050 - val_binary_accuracy: 0.7500\n",
      "Epoch 14/250\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.1050 - binary_accuracy: 0.7500 - val_loss: 0.1025 - val_binary_accuracy: 0.7500\n",
      "Epoch 15/250\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.1025 - binary_accuracy: 0.7500 - val_loss: 0.1000 - val_binary_accuracy: 0.7500\n",
      "Epoch 16/250\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1000 - binary_accuracy: 0.7500 - val_loss: 0.0977 - val_binary_accuracy: 0.7500\n",
      "Epoch 17/250\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0977 - binary_accuracy: 0.7500 - val_loss: 0.0955 - val_binary_accuracy: 0.7500\n",
      "Epoch 18/250\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0955 - binary_accuracy: 0.7500 - val_loss: 0.0933 - val_binary_accuracy: 0.7500\n",
      "Epoch 19/250\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0933 - binary_accuracy: 0.7500 - val_loss: 0.0913 - val_binary_accuracy: 0.7500\n",
      "Epoch 20/250\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0913 - binary_accuracy: 0.7500 - val_loss: 0.0893 - val_binary_accuracy: 0.7500\n",
      "Epoch 21/250\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0893 - binary_accuracy: 0.7500 - val_loss: 0.0873 - val_binary_accuracy: 0.7500\n",
      "Epoch 22/250\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0873 - binary_accuracy: 0.7500 - val_loss: 0.0854 - val_binary_accuracy: 0.7500\n",
      "Epoch 23/250\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0854 - binary_accuracy: 0.7500 - val_loss: 0.0836 - val_binary_accuracy: 0.7500\n",
      "Epoch 24/250\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0836 - binary_accuracy: 0.7500 - val_loss: 0.0819 - val_binary_accuracy: 0.7500\n",
      "Epoch 25/250\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0819 - binary_accuracy: 0.7500 - val_loss: 0.0802 - val_binary_accuracy: 0.7500\n",
      "Epoch 26/250\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0802 - binary_accuracy: 0.7500 - val_loss: 0.0785 - val_binary_accuracy: 1.0000\n",
      "Epoch 27/250\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0785 - binary_accuracy: 1.0000 - val_loss: 0.0770 - val_binary_accuracy: 1.0000\n",
      "Epoch 28/250\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0770 - binary_accuracy: 1.0000 - val_loss: 0.0754 - val_binary_accuracy: 1.0000\n",
      "Epoch 29/250\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0754 - binary_accuracy: 1.0000 - val_loss: 0.0739 - val_binary_accuracy: 1.0000\n",
      "Epoch 30/250\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0739 - binary_accuracy: 1.0000 - val_loss: 0.0725 - val_binary_accuracy: 1.0000\n",
      "Epoch 31/250\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0725 - binary_accuracy: 1.0000 - val_loss: 0.0711 - val_binary_accuracy: 1.0000\n",
      "Epoch 32/250\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0711 - binary_accuracy: 1.0000 - val_loss: 0.0698 - val_binary_accuracy: 1.0000\n",
      "Epoch 33/250\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0698 - binary_accuracy: 1.0000 - val_loss: 0.0685 - val_binary_accuracy: 1.0000\n",
      "Epoch 34/250\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0685 - binary_accuracy: 1.0000 - val_loss: 0.0673 - val_binary_accuracy: 1.0000\n",
      "Epoch 35/250\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0673 - binary_accuracy: 1.0000 - val_loss: 0.0661 - val_binary_accuracy: 1.0000\n",
      "Epoch 36/250\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0661 - binary_accuracy: 1.0000 - val_loss: 0.0649 - val_binary_accuracy: 1.0000\n",
      "Epoch 37/250\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0649 - binary_accuracy: 1.0000 - val_loss: 0.0638 - val_binary_accuracy: 1.0000\n",
      "Epoch 38/250\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0638 - binary_accuracy: 1.0000 - val_loss: 0.0627 - val_binary_accuracy: 1.0000\n",
      "Epoch 39/250\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0627 - binary_accuracy: 1.0000 - val_loss: 0.0617 - val_binary_accuracy: 1.0000\n",
      "Epoch 40/250\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0617 - binary_accuracy: 1.0000 - val_loss: 0.0607 - val_binary_accuracy: 1.0000\n",
      "Epoch 41/250\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0607 - binary_accuracy: 1.0000 - val_loss: 0.0597 - val_binary_accuracy: 1.0000\n",
      "Epoch 42/250\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0597 - binary_accuracy: 1.0000 - val_loss: 0.0588 - val_binary_accuracy: 1.0000\n",
      "Epoch 43/250\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0588 - binary_accuracy: 1.0000 - val_loss: 0.0579 - val_binary_accuracy: 1.0000\n",
      "Epoch 44/250\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0579 - binary_accuracy: 1.0000 - val_loss: 0.0570 - val_binary_accuracy: 1.0000\n",
      "Epoch 45/250\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0570 - binary_accuracy: 1.0000 - val_loss: 0.0562 - val_binary_accuracy: 1.0000\n",
      "Epoch 46/250\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0562 - binary_accuracy: 1.0000 - val_loss: 0.0554 - val_binary_accuracy: 1.0000\n",
      "Epoch 47/250\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0554 - binary_accuracy: 1.0000 - val_loss: 0.0547 - val_binary_accuracy: 1.0000\n",
      "Epoch 48/250\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0547 - binary_accuracy: 1.0000 - val_loss: 0.0540 - val_binary_accuracy: 1.0000\n",
      "Epoch 49/250\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0540 - binary_accuracy: 1.0000 - val_loss: 0.0533 - val_binary_accuracy: 1.0000\n",
      "Epoch 50/250\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0533 - binary_accuracy: 1.0000 - val_loss: 0.0527 - val_binary_accuracy: 1.0000\n",
      "Epoch 51/250\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0527 - binary_accuracy: 1.0000 - val_loss: 0.0520 - val_binary_accuracy: 1.0000\n",
      "Epoch 52/250\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0520 - binary_accuracy: 1.0000 - val_loss: 0.0514 - val_binary_accuracy: 1.0000\n",
      "Epoch 53/250\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0514 - binary_accuracy: 1.0000 - val_loss: 0.0508 - val_binary_accuracy: 1.0000\n",
      "Epoch 54/250\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0508 - binary_accuracy: 1.0000 - val_loss: 0.0502 - val_binary_accuracy: 1.0000\n",
      "Epoch 55/250\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0502 - binary_accuracy: 1.0000 - val_loss: 0.0496 - val_binary_accuracy: 1.0000\n",
      "Epoch 56/250\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0496 - binary_accuracy: 1.0000 - val_loss: 0.0491 - val_binary_accuracy: 1.0000\n",
      "Epoch 57/250\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0491 - binary_accuracy: 1.0000 - val_loss: 0.0485 - val_binary_accuracy: 1.0000\n",
      "Epoch 58/250\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0485 - binary_accuracy: 1.0000 - val_loss: 0.0480 - val_binary_accuracy: 1.0000\n",
      "Epoch 59/250\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0480 - binary_accuracy: 1.0000 - val_loss: 0.0474 - val_binary_accuracy: 1.0000\n",
      "Epoch 60/250\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0474 - binary_accuracy: 1.0000 - val_loss: 0.0469 - val_binary_accuracy: 1.0000\n",
      "Epoch 61/250\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0469 - binary_accuracy: 1.0000 - val_loss: 0.0464 - val_binary_accuracy: 1.0000\n",
      "Epoch 62/250\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0464 - binary_accuracy: 1.0000 - val_loss: 0.0458 - val_binary_accuracy: 1.0000\n",
      "Epoch 63/250\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0458 - binary_accuracy: 1.0000 - val_loss: 0.0453 - val_binary_accuracy: 1.0000\n",
      "Epoch 64/250\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0453 - binary_accuracy: 1.0000 - val_loss: 0.0448 - val_binary_accuracy: 1.0000\n",
      "Epoch 65/250\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0448 - binary_accuracy: 1.0000 - val_loss: 0.0443 - val_binary_accuracy: 1.0000\n",
      "Epoch 66/250\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0443 - binary_accuracy: 1.0000 - val_loss: 0.0438 - val_binary_accuracy: 1.0000\n",
      "Epoch 67/250\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0438 - binary_accuracy: 1.0000 - val_loss: 0.0433 - val_binary_accuracy: 1.0000\n",
      "Epoch 68/250\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0433 - binary_accuracy: 1.0000 - val_loss: 0.0428 - val_binary_accuracy: 1.0000\n",
      "Epoch 69/250\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0428 - binary_accuracy: 1.0000 - val_loss: 0.0423 - val_binary_accuracy: 1.0000\n",
      "Epoch 70/250\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0423 - binary_accuracy: 1.0000 - val_loss: 0.0418 - val_binary_accuracy: 1.0000\n",
      "Epoch 71/250\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0418 - binary_accuracy: 1.0000 - val_loss: 0.0413 - val_binary_accuracy: 1.0000\n",
      "Epoch 72/250\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0413 - binary_accuracy: 1.0000 - val_loss: 0.0408 - val_binary_accuracy: 1.0000\n",
      "Epoch 73/250\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0408 - binary_accuracy: 1.0000 - val_loss: 0.0403 - val_binary_accuracy: 1.0000\n",
      "Epoch 74/250\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0403 - binary_accuracy: 1.0000 - val_loss: 0.0398 - val_binary_accuracy: 1.0000\n",
      "Epoch 75/250\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0398 - binary_accuracy: 1.0000 - val_loss: 0.0393 - val_binary_accuracy: 1.0000\n",
      "Epoch 76/250\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0393 - binary_accuracy: 1.0000 - val_loss: 0.0388 - val_binary_accuracy: 1.0000\n",
      "Epoch 77/250\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0388 - binary_accuracy: 1.0000 - val_loss: 0.0383 - val_binary_accuracy: 1.0000\n",
      "Epoch 78/250\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0383 - binary_accuracy: 1.0000 - val_loss: 0.0378 - val_binary_accuracy: 1.0000\n",
      "Epoch 79/250\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0378 - binary_accuracy: 1.0000 - val_loss: 0.0373 - val_binary_accuracy: 1.0000\n",
      "Epoch 80/250\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0373 - binary_accuracy: 1.0000 - val_loss: 0.0369 - val_binary_accuracy: 1.0000\n",
      "Epoch 81/250\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0369 - binary_accuracy: 1.0000 - val_loss: 0.0364 - val_binary_accuracy: 1.0000\n",
      "Epoch 82/250\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0364 - binary_accuracy: 1.0000 - val_loss: 0.0359 - val_binary_accuracy: 1.0000\n",
      "Epoch 83/250\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0359 - binary_accuracy: 1.0000 - val_loss: 0.0354 - val_binary_accuracy: 1.0000\n",
      "Epoch 84/250\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0354 - binary_accuracy: 1.0000 - val_loss: 0.0349 - val_binary_accuracy: 1.0000\n",
      "Epoch 85/250\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0349 - binary_accuracy: 1.0000 - val_loss: 0.0345 - val_binary_accuracy: 1.0000\n",
      "Epoch 86/250\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0345 - binary_accuracy: 1.0000 - val_loss: 0.0340 - val_binary_accuracy: 1.0000\n",
      "Epoch 87/250\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0340 - binary_accuracy: 1.0000 - val_loss: 0.0336 - val_binary_accuracy: 1.0000\n",
      "Epoch 88/250\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0336 - binary_accuracy: 1.0000 - val_loss: 0.0332 - val_binary_accuracy: 1.0000\n",
      "Epoch 89/250\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0332 - binary_accuracy: 1.0000 - val_loss: 0.0327 - val_binary_accuracy: 1.0000\n",
      "Epoch 90/250\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0327 - binary_accuracy: 1.0000 - val_loss: 0.0323 - val_binary_accuracy: 1.0000\n",
      "Epoch 91/250\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0323 - binary_accuracy: 1.0000 - val_loss: 0.0319 - val_binary_accuracy: 1.0000\n",
      "Epoch 92/250\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0319 - binary_accuracy: 1.0000 - val_loss: 0.0315 - val_binary_accuracy: 1.0000\n",
      "Epoch 93/250\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0315 - binary_accuracy: 1.0000 - val_loss: 0.0311 - val_binary_accuracy: 1.0000\n",
      "Epoch 94/250\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0311 - binary_accuracy: 1.0000 - val_loss: 0.0307 - val_binary_accuracy: 1.0000\n",
      "Epoch 95/250\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0307 - binary_accuracy: 1.0000 - val_loss: 0.0303 - val_binary_accuracy: 1.0000\n",
      "Epoch 96/250\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0303 - binary_accuracy: 1.0000 - val_loss: 0.0299 - val_binary_accuracy: 1.0000\n",
      "Epoch 97/250\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0299 - binary_accuracy: 1.0000 - val_loss: 0.0295 - val_binary_accuracy: 1.0000\n",
      "Epoch 98/250\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0295 - binary_accuracy: 1.0000 - val_loss: 0.0291 - val_binary_accuracy: 1.0000\n",
      "Epoch 99/250\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0291 - binary_accuracy: 1.0000 - val_loss: 0.0287 - val_binary_accuracy: 1.0000\n",
      "Epoch 100/250\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0287 - binary_accuracy: 1.0000 - val_loss: 0.0283 - val_binary_accuracy: 1.0000\n",
      "Epoch 101/250\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0283 - binary_accuracy: 1.0000 - val_loss: 0.0280 - val_binary_accuracy: 1.0000\n",
      "Epoch 102/250\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0280 - binary_accuracy: 1.0000 - val_loss: 0.0276 - val_binary_accuracy: 1.0000\n",
      "Epoch 103/250\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0276 - binary_accuracy: 1.0000 - val_loss: 0.0272 - val_binary_accuracy: 1.0000\n",
      "Epoch 104/250\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0272 - binary_accuracy: 1.0000 - val_loss: 0.0268 - val_binary_accuracy: 1.0000\n",
      "Epoch 105/250\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0268 - binary_accuracy: 1.0000 - val_loss: 0.0264 - val_binary_accuracy: 1.0000\n",
      "Epoch 106/250\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0264 - binary_accuracy: 1.0000 - val_loss: 0.0260 - val_binary_accuracy: 1.0000\n",
      "Epoch 107/250\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0260 - binary_accuracy: 1.0000 - val_loss: 0.0256 - val_binary_accuracy: 1.0000\n",
      "Epoch 108/250\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0256 - binary_accuracy: 1.0000 - val_loss: 0.0252 - val_binary_accuracy: 1.0000\n",
      "Epoch 109/250\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0252 - binary_accuracy: 1.0000 - val_loss: 0.0249 - val_binary_accuracy: 1.0000\n",
      "Epoch 110/250\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0249 - binary_accuracy: 1.0000 - val_loss: 0.0245 - val_binary_accuracy: 1.0000\n",
      "Epoch 111/250\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0245 - binary_accuracy: 1.0000 - val_loss: 0.0241 - val_binary_accuracy: 1.0000\n",
      "Epoch 112/250\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0241 - binary_accuracy: 1.0000 - val_loss: 0.0238 - val_binary_accuracy: 1.0000\n",
      "Epoch 113/250\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0238 - binary_accuracy: 1.0000 - val_loss: 0.0234 - val_binary_accuracy: 1.0000\n",
      "Epoch 114/250\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0234 - binary_accuracy: 1.0000 - val_loss: 0.0230 - val_binary_accuracy: 1.0000\n",
      "Epoch 115/250\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0230 - binary_accuracy: 1.0000 - val_loss: 0.0226 - val_binary_accuracy: 1.0000\n",
      "Epoch 116/250\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0226 - binary_accuracy: 1.0000 - val_loss: 0.0223 - val_binary_accuracy: 1.0000\n",
      "Epoch 117/250\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0223 - binary_accuracy: 1.0000 - val_loss: 0.0219 - val_binary_accuracy: 1.0000\n",
      "Epoch 118/250\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0219 - binary_accuracy: 1.0000 - val_loss: 0.0215 - val_binary_accuracy: 1.0000\n",
      "Epoch 119/250\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0215 - binary_accuracy: 1.0000 - val_loss: 0.0212 - val_binary_accuracy: 1.0000\n",
      "Epoch 120/250\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0212 - binary_accuracy: 1.0000 - val_loss: 0.0208 - val_binary_accuracy: 1.0000\n",
      "Epoch 121/250\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0208 - binary_accuracy: 1.0000 - val_loss: 0.0205 - val_binary_accuracy: 1.0000\n",
      "Epoch 122/250\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0205 - binary_accuracy: 1.0000 - val_loss: 0.0201 - val_binary_accuracy: 1.0000\n",
      "Epoch 123/250\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0201 - binary_accuracy: 1.0000 - val_loss: 0.0198 - val_binary_accuracy: 1.0000\n",
      "Epoch 124/250\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0198 - binary_accuracy: 1.0000 - val_loss: 0.0194 - val_binary_accuracy: 1.0000\n",
      "Epoch 125/250\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0194 - binary_accuracy: 1.0000 - val_loss: 0.0191 - val_binary_accuracy: 1.0000\n",
      "Epoch 126/250\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0191 - binary_accuracy: 1.0000 - val_loss: 0.0187 - val_binary_accuracy: 1.0000\n",
      "Epoch 127/250\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0187 - binary_accuracy: 1.0000 - val_loss: 0.0184 - val_binary_accuracy: 1.0000\n",
      "Epoch 128/250\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0184 - binary_accuracy: 1.0000 - val_loss: 0.0180 - val_binary_accuracy: 1.0000\n",
      "Epoch 129/250\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0180 - binary_accuracy: 1.0000 - val_loss: 0.0177 - val_binary_accuracy: 1.0000\n",
      "Epoch 130/250\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0177 - binary_accuracy: 1.0000 - val_loss: 0.0174 - val_binary_accuracy: 1.0000\n",
      "Epoch 131/250\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0174 - binary_accuracy: 1.0000 - val_loss: 0.0170 - val_binary_accuracy: 1.0000\n",
      "Epoch 132/250\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0170 - binary_accuracy: 1.0000 - val_loss: 0.0167 - val_binary_accuracy: 1.0000\n",
      "Epoch 133/250\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0167 - binary_accuracy: 1.0000 - val_loss: 0.0164 - val_binary_accuracy: 1.0000\n",
      "Epoch 134/250\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0164 - binary_accuracy: 1.0000 - val_loss: 0.0160 - val_binary_accuracy: 1.0000\n",
      "Epoch 135/250\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0160 - binary_accuracy: 1.0000 - val_loss: 0.0157 - val_binary_accuracy: 1.0000\n",
      "Epoch 136/250\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0157 - binary_accuracy: 1.0000 - val_loss: 0.0154 - val_binary_accuracy: 1.0000\n",
      "Epoch 137/250\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0154 - binary_accuracy: 1.0000 - val_loss: 0.0151 - val_binary_accuracy: 1.0000\n",
      "Epoch 138/250\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0151 - binary_accuracy: 1.0000 - val_loss: 0.0148 - val_binary_accuracy: 1.0000\n",
      "Epoch 139/250\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0148 - binary_accuracy: 1.0000 - val_loss: 0.0145 - val_binary_accuracy: 1.0000\n",
      "Epoch 140/250\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0145 - binary_accuracy: 1.0000 - val_loss: 0.0142 - val_binary_accuracy: 1.0000\n",
      "Epoch 141/250\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0142 - binary_accuracy: 1.0000 - val_loss: 0.0138 - val_binary_accuracy: 1.0000\n",
      "Epoch 142/250\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0138 - binary_accuracy: 1.0000 - val_loss: 0.0135 - val_binary_accuracy: 1.0000\n",
      "Epoch 143/250\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0135 - binary_accuracy: 1.0000 - val_loss: 0.0132 - val_binary_accuracy: 1.0000\n",
      "Epoch 144/250\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0132 - binary_accuracy: 1.0000 - val_loss: 0.0129 - val_binary_accuracy: 1.0000\n",
      "Epoch 145/250\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0129 - binary_accuracy: 1.0000 - val_loss: 0.0126 - val_binary_accuracy: 1.0000\n",
      "Epoch 146/250\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0126 - binary_accuracy: 1.0000 - val_loss: 0.0124 - val_binary_accuracy: 1.0000\n",
      "Epoch 147/250\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0124 - binary_accuracy: 1.0000 - val_loss: 0.0121 - val_binary_accuracy: 1.0000\n",
      "Epoch 148/250\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0121 - binary_accuracy: 1.0000 - val_loss: 0.0118 - val_binary_accuracy: 1.0000\n",
      "Epoch 149/250\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0118 - binary_accuracy: 1.0000 - val_loss: 0.0115 - val_binary_accuracy: 1.0000\n",
      "Epoch 150/250\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0115 - binary_accuracy: 1.0000 - val_loss: 0.0112 - val_binary_accuracy: 1.0000\n",
      "Epoch 151/250\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0112 - binary_accuracy: 1.0000 - val_loss: 0.0110 - val_binary_accuracy: 1.0000\n",
      "Epoch 152/250\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0110 - binary_accuracy: 1.0000 - val_loss: 0.0107 - val_binary_accuracy: 1.0000\n",
      "Epoch 153/250\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0107 - binary_accuracy: 1.0000 - val_loss: 0.0104 - val_binary_accuracy: 1.0000\n",
      "Epoch 154/250\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0104 - binary_accuracy: 1.0000 - val_loss: 0.0101 - val_binary_accuracy: 1.0000\n",
      "Epoch 155/250\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0101 - binary_accuracy: 1.0000 - val_loss: 0.0099 - val_binary_accuracy: 1.0000\n",
      "Epoch 156/250\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0099 - binary_accuracy: 1.0000 - val_loss: 0.0096 - val_binary_accuracy: 1.0000\n",
      "Epoch 157/250\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0096 - binary_accuracy: 1.0000 - val_loss: 0.0094 - val_binary_accuracy: 1.0000\n",
      "Epoch 158/250\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0094 - binary_accuracy: 1.0000 - val_loss: 0.0091 - val_binary_accuracy: 1.0000\n",
      "Epoch 159/250\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0091 - binary_accuracy: 1.0000 - val_loss: 0.0089 - val_binary_accuracy: 1.0000\n",
      "Epoch 160/250\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0089 - binary_accuracy: 1.0000 - val_loss: 0.0086 - val_binary_accuracy: 1.0000\n",
      "Epoch 161/250\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0086 - binary_accuracy: 1.0000 - val_loss: 0.0084 - val_binary_accuracy: 1.0000\n",
      "Epoch 162/250\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0084 - binary_accuracy: 1.0000 - val_loss: 0.0081 - val_binary_accuracy: 1.0000\n",
      "Epoch 163/250\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0081 - binary_accuracy: 1.0000 - val_loss: 0.0079 - val_binary_accuracy: 1.0000\n",
      "Epoch 164/250\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0079 - binary_accuracy: 1.0000 - val_loss: 0.0077 - val_binary_accuracy: 1.0000\n",
      "Epoch 165/250\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0077 - binary_accuracy: 1.0000 - val_loss: 0.0074 - val_binary_accuracy: 1.0000\n",
      "Epoch 166/250\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0074 - binary_accuracy: 1.0000 - val_loss: 0.0072 - val_binary_accuracy: 1.0000\n",
      "Epoch 167/250\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0072 - binary_accuracy: 1.0000 - val_loss: 0.0070 - val_binary_accuracy: 1.0000\n",
      "Epoch 168/250\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0070 - binary_accuracy: 1.0000 - val_loss: 0.0068 - val_binary_accuracy: 1.0000\n",
      "Epoch 169/250\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0068 - binary_accuracy: 1.0000 - val_loss: 0.0065 - val_binary_accuracy: 1.0000\n",
      "Epoch 170/250\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0065 - binary_accuracy: 1.0000 - val_loss: 0.0063 - val_binary_accuracy: 1.0000\n",
      "Epoch 171/250\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0063 - binary_accuracy: 1.0000 - val_loss: 0.0061 - val_binary_accuracy: 1.0000\n",
      "Epoch 172/250\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0061 - binary_accuracy: 1.0000 - val_loss: 0.0059 - val_binary_accuracy: 1.0000\n",
      "Epoch 173/250\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0059 - binary_accuracy: 1.0000 - val_loss: 0.0057 - val_binary_accuracy: 1.0000\n",
      "Epoch 174/250\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0057 - binary_accuracy: 1.0000 - val_loss: 0.0055 - val_binary_accuracy: 1.0000\n",
      "Epoch 175/250\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0055 - binary_accuracy: 1.0000 - val_loss: 0.0053 - val_binary_accuracy: 1.0000\n",
      "Epoch 176/250\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0053 - binary_accuracy: 1.0000 - val_loss: 0.0051 - val_binary_accuracy: 1.0000\n",
      "Epoch 177/250\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0051 - binary_accuracy: 1.0000 - val_loss: 0.0050 - val_binary_accuracy: 1.0000\n",
      "Epoch 178/250\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0050 - binary_accuracy: 1.0000 - val_loss: 0.0048 - val_binary_accuracy: 1.0000\n",
      "Epoch 179/250\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0048 - binary_accuracy: 1.0000 - val_loss: 0.0046 - val_binary_accuracy: 1.0000\n",
      "Epoch 180/250\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0046 - binary_accuracy: 1.0000 - val_loss: 0.0044 - val_binary_accuracy: 1.0000\n",
      "Epoch 181/250\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0044 - binary_accuracy: 1.0000 - val_loss: 0.0043 - val_binary_accuracy: 1.0000\n",
      "Epoch 182/250\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0043 - binary_accuracy: 1.0000 - val_loss: 0.0041 - val_binary_accuracy: 1.0000\n",
      "Epoch 183/250\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0041 - binary_accuracy: 1.0000 - val_loss: 0.0039 - val_binary_accuracy: 1.0000\n",
      "Epoch 184/250\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0039 - binary_accuracy: 1.0000 - val_loss: 0.0038 - val_binary_accuracy: 1.0000\n",
      "Epoch 185/250\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0038 - binary_accuracy: 1.0000 - val_loss: 0.0036 - val_binary_accuracy: 1.0000\n",
      "Epoch 186/250\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0036 - binary_accuracy: 1.0000 - val_loss: 0.0034 - val_binary_accuracy: 1.0000\n",
      "Epoch 187/250\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0034 - binary_accuracy: 1.0000 - val_loss: 0.0033 - val_binary_accuracy: 1.0000\n",
      "Epoch 188/250\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0033 - binary_accuracy: 1.0000 - val_loss: 0.0032 - val_binary_accuracy: 1.0000\n",
      "Epoch 189/250\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0032 - binary_accuracy: 1.0000 - val_loss: 0.0030 - val_binary_accuracy: 1.0000\n",
      "Epoch 190/250\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0030 - binary_accuracy: 1.0000 - val_loss: 0.0029 - val_binary_accuracy: 1.0000\n",
      "Epoch 191/250\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0029 - binary_accuracy: 1.0000 - val_loss: 0.0027 - val_binary_accuracy: 1.0000\n",
      "Epoch 192/250\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0027 - binary_accuracy: 1.0000 - val_loss: 0.0026 - val_binary_accuracy: 1.0000\n",
      "Epoch 193/250\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0026 - binary_accuracy: 1.0000 - val_loss: 0.0025 - val_binary_accuracy: 1.0000\n",
      "Epoch 194/250\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0025 - binary_accuracy: 1.0000 - val_loss: 0.0024 - val_binary_accuracy: 1.0000\n",
      "Epoch 195/250\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0024 - binary_accuracy: 1.0000 - val_loss: 0.0022 - val_binary_accuracy: 1.0000\n",
      "Epoch 196/250\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0022 - binary_accuracy: 1.0000 - val_loss: 0.0021 - val_binary_accuracy: 1.0000\n",
      "Epoch 197/250\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0021 - binary_accuracy: 1.0000 - val_loss: 0.0020 - val_binary_accuracy: 1.0000\n",
      "Epoch 198/250\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0020 - binary_accuracy: 1.0000 - val_loss: 0.0019 - val_binary_accuracy: 1.0000\n",
      "Epoch 199/250\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0019 - binary_accuracy: 1.0000 - val_loss: 0.0018 - val_binary_accuracy: 1.0000\n",
      "Epoch 200/250\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0018 - binary_accuracy: 1.0000 - val_loss: 0.0017 - val_binary_accuracy: 1.0000\n",
      "Epoch 201/250\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0017 - binary_accuracy: 1.0000 - val_loss: 0.0016 - val_binary_accuracy: 1.0000\n",
      "Epoch 202/250\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0016 - binary_accuracy: 1.0000 - val_loss: 0.0015 - val_binary_accuracy: 1.0000\n",
      "Epoch 203/250\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0015 - binary_accuracy: 1.0000 - val_loss: 0.0014 - val_binary_accuracy: 1.0000\n",
      "Epoch 204/250\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0014 - binary_accuracy: 1.0000 - val_loss: 0.0013 - val_binary_accuracy: 1.0000\n",
      "Epoch 205/250\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0013 - binary_accuracy: 1.0000 - val_loss: 0.0012 - val_binary_accuracy: 1.0000\n",
      "Epoch 206/250\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0012 - binary_accuracy: 1.0000 - val_loss: 0.0012 - val_binary_accuracy: 1.0000\n",
      "Epoch 207/250\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0012 - binary_accuracy: 1.0000 - val_loss: 0.0011 - val_binary_accuracy: 1.0000\n",
      "Epoch 208/250\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0011 - binary_accuracy: 1.0000 - val_loss: 0.0010 - val_binary_accuracy: 1.0000\n",
      "Epoch 209/250\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0010 - binary_accuracy: 1.0000 - val_loss: 9.3797e-04 - val_binary_accuracy: 1.0000\n",
      "Epoch 210/250\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 9.3797e-04 - binary_accuracy: 1.0000 - val_loss: 8.7356e-04 - val_binary_accuracy: 1.0000\n",
      "Epoch 211/250\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 8.7356e-04 - binary_accuracy: 1.0000 - val_loss: 8.0751e-04 - val_binary_accuracy: 1.0000\n",
      "Epoch 212/250\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 8.0751e-04 - binary_accuracy: 1.0000 - val_loss: 7.4903e-04 - val_binary_accuracy: 1.0000\n",
      "Epoch 213/250\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 7.4903e-04 - binary_accuracy: 1.0000 - val_loss: 6.8951e-04 - val_binary_accuracy: 1.0000\n",
      "Epoch 214/250\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 6.8951e-04 - binary_accuracy: 1.0000 - val_loss: 6.3688e-04 - val_binary_accuracy: 1.0000\n",
      "Minimum Validation Loss: 0.00064\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from ann_visualizer.visualize import ann_viz\n",
    "from graphviz import Source\n",
    "from keras.layers import Activation\n",
    "\n",
    "# initially I got val loss 0.07 because Id column present. After removing it I got 0.13\n",
    "# Then I experimented with optimizers, loss and activation functions and the number of layers and neurons and finally got it back to 0.0700\n",
    "\n",
    "# activation_function = 'relu'\n",
    "from keras import backend as K\n",
    "from keras.utils.generic_utils import get_custom_objects\n",
    "\n",
    "\n",
    "def activation_function(tensor):\n",
    "    print(tensor)\n",
    "    return tf.math.round(tensor, name=None)\n",
    "\n",
    "# get_custom_objects().update({'activation_function': Activation(activation_function)})\n",
    "# activation=lambda x: x/5\n",
    "\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(2, activation=\"relu\", input_shape=input_shape),\n",
    "    # layers.Dense(2, activation=activation_function, input_shape=input_shape),\n",
    "    # layers.Dense(2, activation=lambda x: int(x), input_shape=input_shape),\n",
    "    layers.Dense(6, activation=\"relu\"),\n",
    "    layers.Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    # optimizer='adam',\n",
    "    #  loss='mae',\n",
    "    loss='mean_squared_error',\n",
    "    # metrics=['accuracy']\n",
    "    metrics=['binary_accuracy']\n",
    ")\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_valid, y_valid),\n",
    "    batch_size=4,# grupy danych\n",
    "    epochs=250,\n",
    "    callbacks=[early_stopping]\n",
    ")\n",
    "# print(model.summary())\n",
    "\n",
    "# ann_viz(model, title=\"XOR\")\n",
    "# graph = Source.from_file('network.gv')\n",
    "# graph\n",
    "\n",
    "history_df = pd.DataFrame(history.history)\n",
    "print(\"Minimum Validation Loss: {:0.5f}\".format(history_df['val_loss'].min()));"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 42ms/step\n",
      "[[0.94824106]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-10 17:38:10.263980: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "print(model.predict(np.array([[0, 1]])))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-10 17:47:16.989210: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node 'sequential_1/dense_3/MatMul' defined at (most recent call last):\n    File \"/Users/kkepins-macwro_1/.pyenv/versions/3.9.13/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/Users/kkepins-macwro_1/.pyenv/versions/3.9.13/lib/python3.9/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/Users/kkepins-macwro_1/git/machine_learning/env/lib/python3.9/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/Users/kkepins-macwro_1/git/machine_learning/env/lib/python3.9/site-packages/traitlets/config/application.py\", line 976, in launch_instance\n      app.start()\n    File \"/Users/kkepins-macwro_1/git/machine_learning/env/lib/python3.9/site-packages/ipykernel/kernelapp.py\", line 712, in start\n      self.io_loop.start()\n    File \"/Users/kkepins-macwro_1/git/machine_learning/env/lib/python3.9/site-packages/tornado/platform/asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"/Users/kkepins-macwro_1/.pyenv/versions/3.9.13/lib/python3.9/asyncio/base_events.py\", line 601, in run_forever\n      self._run_once()\n    File \"/Users/kkepins-macwro_1/.pyenv/versions/3.9.13/lib/python3.9/asyncio/base_events.py\", line 1905, in _run_once\n      handle._run()\n    File \"/Users/kkepins-macwro_1/.pyenv/versions/3.9.13/lib/python3.9/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/Users/kkepins-macwro_1/git/machine_learning/env/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"/Users/kkepins-macwro_1/git/machine_learning/env/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"/Users/kkepins-macwro_1/git/machine_learning/env/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"/Users/kkepins-macwro_1/git/machine_learning/env/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 730, in execute_request\n      reply_content = await reply_content\n    File \"/Users/kkepins-macwro_1/git/machine_learning/env/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 383, in do_execute\n      res = shell.run_cell(\n    File \"/Users/kkepins-macwro_1/git/machine_learning/env/lib/python3.9/site-packages/ipykernel/zmqshell.py\", line 528, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/Users/kkepins-macwro_1/git/machine_learning/env/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_cell\n      result = self._run_cell(\n    File \"/Users/kkepins-macwro_1/git/machine_learning/env/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2936, in _run_cell\n      return runner(coro)\n    File \"/Users/kkepins-macwro_1/git/machine_learning/env/lib/python3.9/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/Users/kkepins-macwro_1/git/machine_learning/env/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3135, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/Users/kkepins-macwro_1/git/machine_learning/env/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3338, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/Users/kkepins-macwro_1/git/machine_learning/env/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3398, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/var/folders/r3/hdngxsmd2vq391vqv6kg6f7w0000gq/T/ipykernel_96200/1679664756.py\", line 13, in <cell line: 13>\n      Z = model.predict(numpy.array([X_train]))\n    File \"/Users/kkepins-macwro_1/git/machine_learning/env/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/Users/kkepins-macwro_1/git/machine_learning/env/lib/python3.9/site-packages/keras/engine/training.py\", line 2033, in predict\n      tmp_batch_outputs = self.predict_function(iterator)\n    File \"/Users/kkepins-macwro_1/git/machine_learning/env/lib/python3.9/site-packages/keras/engine/training.py\", line 1845, in predict_function\n      return step_function(self, iterator)\n    File \"/Users/kkepins-macwro_1/git/machine_learning/env/lib/python3.9/site-packages/keras/engine/training.py\", line 1834, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/kkepins-macwro_1/git/machine_learning/env/lib/python3.9/site-packages/keras/engine/training.py\", line 1823, in run_step\n      outputs = model.predict_step(data)\n    File \"/Users/kkepins-macwro_1/git/machine_learning/env/lib/python3.9/site-packages/keras/engine/training.py\", line 1791, in predict_step\n      return self(x, training=False)\n    File \"/Users/kkepins-macwro_1/git/machine_learning/env/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/Users/kkepins-macwro_1/git/machine_learning/env/lib/python3.9/site-packages/keras/engine/training.py\", line 490, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"/Users/kkepins-macwro_1/git/machine_learning/env/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/Users/kkepins-macwro_1/git/machine_learning/env/lib/python3.9/site-packages/keras/engine/base_layer.py\", line 1014, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/Users/kkepins-macwro_1/git/machine_learning/env/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"/Users/kkepins-macwro_1/git/machine_learning/env/lib/python3.9/site-packages/keras/engine/sequential.py\", line 374, in call\n      return super(Sequential, self).call(inputs, training=training, mask=mask)\n    File \"/Users/kkepins-macwro_1/git/machine_learning/env/lib/python3.9/site-packages/keras/engine/functional.py\", line 458, in call\n      return self._run_internal_graph(\n    File \"/Users/kkepins-macwro_1/git/machine_learning/env/lib/python3.9/site-packages/keras/engine/functional.py\", line 596, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/Users/kkepins-macwro_1/git/machine_learning/env/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/Users/kkepins-macwro_1/git/machine_learning/env/lib/python3.9/site-packages/keras/engine/base_layer.py\", line 1014, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/Users/kkepins-macwro_1/git/machine_learning/env/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"/Users/kkepins-macwro_1/git/machine_learning/env/lib/python3.9/site-packages/keras/layers/core/dense.py\", line 221, in call\n      outputs = tf.matmul(a=inputs, b=self.kernel)\nNode: 'sequential_1/dense_3/MatMul'\nIn[0] and In[1] has different ndims: [1,4,2] vs. [2,2]\n\t [[{{node sequential_1/dense_3/MatMul}}]] [Op:__inference_predict_function_16293]",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mInvalidArgumentError\u001B[0m                      Traceback (most recent call last)",
      "Input \u001B[0;32mIn [18]\u001B[0m, in \u001B[0;36m<cell line: 13>\u001B[0;34m()\u001B[0m\n\u001B[1;32m     11\u001B[0m resolution \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0.01\u001B[39m\n\u001B[1;32m     12\u001B[0m \u001B[38;5;66;03m# x, y = numpy.meshgrid(numpy.arange(x_min, x_max, resolution), numpy.arange(y_min, y_max, resolution))\u001B[39;00m\n\u001B[0;32m---> 13\u001B[0m Z \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpredict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnumpy\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43marray\u001B[49m\u001B[43m(\u001B[49m\u001B[43m[\u001B[49m\u001B[43mX_train\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     14\u001B[0m Z \u001B[38;5;241m=\u001B[39m Z\u001B[38;5;241m.\u001B[39mreshape(X_train\u001B[38;5;241m.\u001B[39mshape)\n\u001B[1;32m     15\u001B[0m plt\u001B[38;5;241m.\u001B[39mpcolormesh(X_train, y_train, Z, cmap\u001B[38;5;241m=\u001B[39mcmap)\n",
      "File \u001B[0;32m~/git/machine_learning/env/lib/python3.9/site-packages/keras/utils/traceback_utils.py:67\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     65\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:  \u001B[38;5;66;03m# pylint: disable=broad-except\u001B[39;00m\n\u001B[1;32m     66\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[0;32m---> 67\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28mNone\u001B[39m\n\u001B[1;32m     68\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m     69\u001B[0m   \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "File \u001B[0;32m~/git/machine_learning/env/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:54\u001B[0m, in \u001B[0;36mquick_execute\u001B[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[1;32m     52\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m     53\u001B[0m   ctx\u001B[38;5;241m.\u001B[39mensure_initialized()\n\u001B[0;32m---> 54\u001B[0m   tensors \u001B[38;5;241m=\u001B[39m pywrap_tfe\u001B[38;5;241m.\u001B[39mTFE_Py_Execute(ctx\u001B[38;5;241m.\u001B[39m_handle, device_name, op_name,\n\u001B[1;32m     55\u001B[0m                                       inputs, attrs, num_outputs)\n\u001B[1;32m     56\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m core\u001B[38;5;241m.\u001B[39m_NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m     57\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[0;31mInvalidArgumentError\u001B[0m: Graph execution error:\n\nDetected at node 'sequential_1/dense_3/MatMul' defined at (most recent call last):\n    File \"/Users/kkepins-macwro_1/.pyenv/versions/3.9.13/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/Users/kkepins-macwro_1/.pyenv/versions/3.9.13/lib/python3.9/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/Users/kkepins-macwro_1/git/machine_learning/env/lib/python3.9/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/Users/kkepins-macwro_1/git/machine_learning/env/lib/python3.9/site-packages/traitlets/config/application.py\", line 976, in launch_instance\n      app.start()\n    File \"/Users/kkepins-macwro_1/git/machine_learning/env/lib/python3.9/site-packages/ipykernel/kernelapp.py\", line 712, in start\n      self.io_loop.start()\n    File \"/Users/kkepins-macwro_1/git/machine_learning/env/lib/python3.9/site-packages/tornado/platform/asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"/Users/kkepins-macwro_1/.pyenv/versions/3.9.13/lib/python3.9/asyncio/base_events.py\", line 601, in run_forever\n      self._run_once()\n    File \"/Users/kkepins-macwro_1/.pyenv/versions/3.9.13/lib/python3.9/asyncio/base_events.py\", line 1905, in _run_once\n      handle._run()\n    File \"/Users/kkepins-macwro_1/.pyenv/versions/3.9.13/lib/python3.9/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/Users/kkepins-macwro_1/git/machine_learning/env/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"/Users/kkepins-macwro_1/git/machine_learning/env/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"/Users/kkepins-macwro_1/git/machine_learning/env/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"/Users/kkepins-macwro_1/git/machine_learning/env/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 730, in execute_request\n      reply_content = await reply_content\n    File \"/Users/kkepins-macwro_1/git/machine_learning/env/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 383, in do_execute\n      res = shell.run_cell(\n    File \"/Users/kkepins-macwro_1/git/machine_learning/env/lib/python3.9/site-packages/ipykernel/zmqshell.py\", line 528, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/Users/kkepins-macwro_1/git/machine_learning/env/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_cell\n      result = self._run_cell(\n    File \"/Users/kkepins-macwro_1/git/machine_learning/env/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2936, in _run_cell\n      return runner(coro)\n    File \"/Users/kkepins-macwro_1/git/machine_learning/env/lib/python3.9/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/Users/kkepins-macwro_1/git/machine_learning/env/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3135, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/Users/kkepins-macwro_1/git/machine_learning/env/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3338, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/Users/kkepins-macwro_1/git/machine_learning/env/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3398, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/var/folders/r3/hdngxsmd2vq391vqv6kg6f7w0000gq/T/ipykernel_96200/1679664756.py\", line 13, in <cell line: 13>\n      Z = model.predict(numpy.array([X_train]))\n    File \"/Users/kkepins-macwro_1/git/machine_learning/env/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/Users/kkepins-macwro_1/git/machine_learning/env/lib/python3.9/site-packages/keras/engine/training.py\", line 2033, in predict\n      tmp_batch_outputs = self.predict_function(iterator)\n    File \"/Users/kkepins-macwro_1/git/machine_learning/env/lib/python3.9/site-packages/keras/engine/training.py\", line 1845, in predict_function\n      return step_function(self, iterator)\n    File \"/Users/kkepins-macwro_1/git/machine_learning/env/lib/python3.9/site-packages/keras/engine/training.py\", line 1834, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/kkepins-macwro_1/git/machine_learning/env/lib/python3.9/site-packages/keras/engine/training.py\", line 1823, in run_step\n      outputs = model.predict_step(data)\n    File \"/Users/kkepins-macwro_1/git/machine_learning/env/lib/python3.9/site-packages/keras/engine/training.py\", line 1791, in predict_step\n      return self(x, training=False)\n    File \"/Users/kkepins-macwro_1/git/machine_learning/env/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/Users/kkepins-macwro_1/git/machine_learning/env/lib/python3.9/site-packages/keras/engine/training.py\", line 490, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"/Users/kkepins-macwro_1/git/machine_learning/env/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/Users/kkepins-macwro_1/git/machine_learning/env/lib/python3.9/site-packages/keras/engine/base_layer.py\", line 1014, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/Users/kkepins-macwro_1/git/machine_learning/env/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"/Users/kkepins-macwro_1/git/machine_learning/env/lib/python3.9/site-packages/keras/engine/sequential.py\", line 374, in call\n      return super(Sequential, self).call(inputs, training=training, mask=mask)\n    File \"/Users/kkepins-macwro_1/git/machine_learning/env/lib/python3.9/site-packages/keras/engine/functional.py\", line 458, in call\n      return self._run_internal_graph(\n    File \"/Users/kkepins-macwro_1/git/machine_learning/env/lib/python3.9/site-packages/keras/engine/functional.py\", line 596, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/Users/kkepins-macwro_1/git/machine_learning/env/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/Users/kkepins-macwro_1/git/machine_learning/env/lib/python3.9/site-packages/keras/engine/base_layer.py\", line 1014, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/Users/kkepins-macwro_1/git/machine_learning/env/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"/Users/kkepins-macwro_1/git/machine_learning/env/lib/python3.9/site-packages/keras/layers/core/dense.py\", line 221, in call\n      outputs = tf.matmul(a=inputs, b=self.kernel)\nNode: 'sequential_1/dense_3/MatMul'\nIn[0] and In[1] has different ndims: [1,4,2] vs. [2,2]\n\t [[{{node sequential_1/dense_3/MatMul}}]] [Op:__inference_predict_function_16293]"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network._multilayer_perceptron import MLPClassifier\n",
    "import numpy\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "markers = ('*', '^', 'x')\n",
    "colors = ('brown', 'green', 'yellow')\n",
    "cmap = ListedColormap(colors)\n",
    "# x_min, x_max = X_train[:, 0].min() - 1, X_train[:, 0].max() + 1\n",
    "# y_min, y_max = y_train[:, 0].min() - 1, y_train[:, 0].max() + 1\n",
    "\n",
    "resolution = 0.01\n",
    "# x, y = numpy.meshgrid(numpy.arange(x_min, x_max, resolution), numpy.arange(y_min, y_max, resolution))\n",
    "Z = model.predict(numpy.array([X_train]))\n",
    "Z = Z.reshape(X_train.shape)\n",
    "plt.pcolormesh(X_train, y_train, Z, cmap=cmap)\n",
    "plt.xlim(X_train.min(), X_train.max())\n",
    "plt.ylim(y_train.min(), y_train.max())\n",
    "classes = [\"0\", \"1\"]\n",
    "\n",
    "for index, cl in enumerate(numpy.unique(y_train)):\n",
    "    plt.scatter(X_train[y_train == cl, 0], X_train[y_train == cl, 1], c=cmap(index), marker=markers[index], s=50, label=classes[index])\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Y')\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights:  [[-0.34849173  0.7927852   0.5323792  -0.91339725  0.7211224 ]\n",
      " [-0.20247483 -0.3839736   0.91132045  0.8482443   0.10412359]]\n",
      "biases:  [ 0.         -0.00097036 -0.00096259  0.         -0.00097353]\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "history_df.loc[109:, ['loss', 'val_loss']].plot()\n",
    "weights = model.layers[1].get_weights()[0]\n",
    "biases = model.layers[1].get_weights()[1]\n",
    "print('weights: ', weights)\n",
    "print('biases: ', biases)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 600x400 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Change 'relu' to 'elu', 'selu', 'swish'... or something else\n",
    "# How different activation functions look like\n",
    "\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# print(tf.__version__)\n",
    "\n",
    "activation_layer = layers.Activation('relu')\n",
    "\n",
    "x = tf.linspace(-3.0, 3.0, 100)\n",
    "y = activation_layer(x)  # once created, a layer is callable just like a function\n",
    "\n",
    "plt.figure(dpi=100)\n",
    "plt.plot(x, y)\n",
    "plt.xlim(-3, 3)\n",
    "plt.xlabel(\"Input\")\n",
    "plt.ylabel(\"Output\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "env",
   "language": "python",
   "display_name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}