{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-07 17:14:26.330359: W tensorflow/core/platform/cloud/google_auth_provider.cc:184] All attempts to get a Google authentication bearer token failed, returning an empty token. Retrieving token from files failed with \"NOT_FOUND: Could not locate the credentials file.\". Retrieving token from GCE failed with \"FAILED_PRECONDITION: Error executing an HTTP request: libcurl code 6 meaning 'Couldn't resolve host name', error details: Could not resolve host: metadata\".\n"
     ]
    },
    {
     "data": {
      "text/plain": "'abstract_reasoning, accentdb, aeslc, aflw2k3d, ag_news_subset, ai2_arc, ai2_arc_with_ir, amazon_us_reviews, anli, answer_equivalence, arc, asqa, asset, assin2, bair_robot_pushing_small, bccd, beans, bee_dataset, beir, big_patent, bigearthnet, billsum, binarized_mnist, binary_alpha_digits, ble_wind_field, blimp, booksum, bool_q, bucc, c4, c4_wsrs, caltech101, caltech_birds2010, caltech_birds2011, cardiotox, cars196, cassava, cats_vs_dogs, celeb_a, celeb_a_hq, cfq, cherry_blossoms, chexpert, cifar10, cifar100, cifar100_n, cifar10_1, cifar10_corrupted, cifar10_n, citrus_leaves, cityscapes, civil_comments, clevr, clic, clinc_oos, cmaterdb, cnn_dailymail, coco, coco_captions, coil100, colorectal_histology, colorectal_histology_large, common_voice, conll2002, conll2003, controlled_noisy_web_labels, coqa, cos_e, cosmos_qa, covid19, covid19sum, crema_d, criteo, cs_restaurants, curated_breast_imaging_ddsm, cycle_gan, d4rl_adroit_door, d4rl_adroit_hammer, d4rl_adroit_pen, d4rl_adroit_relocate, d4rl_antmaze, d4rl_mujoco_ant, d4rl_mujoco_halfcheetah, d4rl_mujoco_hopper, d4rl_mujoco_walker2d, dart, davis, deep1b, deep_weeds, definite_pronoun_resolution, dementiabank, diabetic_retinopathy_detection, diamonds, div2k, dmlab, doc_nli, dolphin_number_word, domainnet, downsampled_imagenet, drop, dsprites, dtd, duke_ultrasound, e2e_cleaned, efron_morris75, emnist, eraser_multi_rc, esnli, eurosat, fashion_mnist, flic, flores, food101, forest_fires, fuss, gap, geirhos_conflict_stimuli, gem, genomics_ood, german_credit_numeric, gigaword, glove100_angular, glue, goemotions, gov_report, gpt3, gref, groove, grounded_scan, gsm8k, gtzan, gtzan_music_speech, hellaswag, higgs, hillstrom, horses_or_humans, howell, i_naturalist2017, i_naturalist2018, i_naturalist2021, imagenet2012, imagenet2012_corrupted, imagenet2012_fewshot, imagenet2012_multilabel, imagenet2012_real, imagenet2012_subset, imagenet_a, imagenet_lt, imagenet_r, imagenet_resized, imagenet_sketch, imagenet_v2, imagenette, imagewang, imdb_reviews, irc_disentanglement, iris, istella, kddcup99, kitti, kmnist, laion400m, lambada, lfw, librispeech, librispeech_lm, libritts, ljspeech, lm1b, locomotion, lost_and_found, lsun, lvis, malaria, math_dataset, math_qa, mctaco, media_sum, mlqa, mnist, mnist_corrupted, movie_lens, movie_rationales, movielens, moving_mnist, mrqa, mslr_web, mt_opt, mtnt, multi_news, multi_nli, multi_nli_mismatch, natural_instructions, natural_questions, natural_questions_open, newsroom, nsynth, nyu_depth_v2, ogbg_molpcba, omniglot, open_images_challenge2019_detection, open_images_v4, openbookqa, opinion_abstracts, opinosis, opus, oxford_flowers102, oxford_iiit_pet, para_crawl, pass, patch_camelyon, paws_wiki, paws_x_wiki, penguins, pet_finder, pg19, piqa, places365_small, placesfull, plant_leaves, plant_village, plantae_k, protein_net, q_re_cc, qa4mre, qasc, quac, quality, quickdraw_bitmap, race, radon, reddit, reddit_disentanglement, reddit_tifu, ref_coco, resisc45, rlu_atari, rlu_atari_checkpoints, rlu_atari_checkpoints_ordered, rlu_control_suite, rlu_dmlab_explore_object_rewards_few, rlu_dmlab_explore_object_rewards_many, rlu_dmlab_rooms_select_nonmatching_object, rlu_dmlab_rooms_watermaze, rlu_dmlab_seekavoid_arena01, rlu_locomotion, rlu_rwrl, robomimic_ph, robonet, robosuite_panda_pick_place_can, rock_paper_scissors, rock_you, s3o4d, salient_span_wikipedia, samsum, savee, scan, scene_parse150, schema_guided_dialogue, sci_tail, scicite, scientific_papers, scrolls, sentiment140, shapes3d, sift1m, simpte, siscore, smallnorb, smartwatch_gestures, snli, so2sat, speech_commands, spoken_digit, squad, squad_question_generation, stanford_dogs, stanford_online_products, star_cfq, starcraft_video, stl10, story_cloze, summscreen, sun397, super_glue, svhn_cropped, symmetric_solids, tao, tatoeba, ted_hrlr_translate, ted_multi_translate, tedlium, tf_flowers, the300w_lp, tiny_shakespeare, titanic, trec, trivia_qa, tydi_qa, uc_merced, ucf101, unified_qa, universal_dependencies, unnatural_instructions, user_libri_audio, user_libri_text, vctk, visual_domain_decathlon, voc, voxceleb, voxforge, waymo_open_dataset, web_graph, web_nlg, web_questions, wider_face, wiki40b, wiki_auto, wiki_bio, wiki_dialog, wiki_table_questions, wiki_table_text, wikiann, wikihow, wikipedia, wikipedia_toxicity_subtypes, wine_quality, winogrande, wit, wit_kaggle, wmt13_translate, wmt14_translate, wmt15_translate, wmt16_translate, wmt17_translate, wmt18_translate, wmt19_translate, wmt_t2t_translate, wmt_translate, wordnet, wsc273, xnli, xquad, xsum, xtreme_pawsx, xtreme_pos, xtreme_s, xtreme_xnli, yahoo_ltrc, yelp_polarity_reviews, yes_no, youtube_vis, huggingface:acronym_identification, huggingface:ade_corpus_v2, huggingface:adv_glue, huggingface:adversarial_qa, huggingface:aeslc, huggingface:afrikaans_ner_corpus, huggingface:ag_news, huggingface:ai2_arc, huggingface:air_dialogue, huggingface:ajgt_twitter_ar, huggingface:allegro_reviews, huggingface:allocine, huggingface:alt, huggingface:amazon_polarity, huggingface:amazon_reviews_multi, huggingface:amazon_us_reviews, huggingface:ambig_qa, huggingface:americas_nli, huggingface:ami, huggingface:amttl, huggingface:anli, huggingface:app_reviews, huggingface:aqua_rat, huggingface:aquamuse, huggingface:ar_cov19, huggingface:ar_res_reviews, huggingface:ar_sarcasm, huggingface:arabic_billion_words, huggingface:arabic_pos_dialect, huggingface:arabic_speech_corpus, huggingface:arcd, huggingface:arsentd_lev, huggingface:art, huggingface:arxiv_dataset, huggingface:ascent_kb, huggingface:aslg_pc12, huggingface:asnq, huggingface:asset, huggingface:assin, huggingface:assin2, huggingface:atomic, huggingface:autshumato, huggingface:babi_qa, huggingface:banking77, huggingface:bbaw_egyptian, huggingface:bbc_hindi_nli, huggingface:bc2gm_corpus, huggingface:beans, huggingface:best2009, huggingface:bianet, huggingface:bible_para, huggingface:big_patent, huggingface:bigbench, huggingface:billsum, huggingface:bing_coronavirus_query_set, huggingface:biomrc, huggingface:biosses, huggingface:biwi_kinect_head_pose, huggingface:blbooks, huggingface:blbooksgenre, huggingface:blended_skill_talk, huggingface:blimp, huggingface:blog_authorship_corpus, huggingface:bn_hate_speech, huggingface:bnl_newspapers, huggingface:bookcorpus, huggingface:bookcorpusopen, huggingface:boolq, huggingface:bprec, huggingface:break_data, huggingface:brwac, huggingface:bsd_ja_en, huggingface:bswac, huggingface:c3, huggingface:c4, huggingface:cail2018, huggingface:caner, huggingface:capes, huggingface:casino, huggingface:catalonia_independence, huggingface:cats_vs_dogs, huggingface:cawac, huggingface:cbt, huggingface:cc100, huggingface:cc_news, huggingface:ccaligned_multilingual, huggingface:cdsc, huggingface:cdt, huggingface:cedr, huggingface:cfq, huggingface:chr_en, huggingface:cifar10, huggingface:cifar100, huggingface:circa, huggingface:civil_comments, huggingface:clickbait_news_bg, huggingface:climate_fever, huggingface:clinc_oos, huggingface:clue, huggingface:cmrc2018, huggingface:cmu_hinglish_dog, huggingface:cnn_dailymail, huggingface:coached_conv_pref, huggingface:coarse_discourse, huggingface:codah, huggingface:code_search_net, huggingface:code_x_glue_cc_clone_detection_big_clone_bench, huggingface:code_x_glue_cc_clone_detection_poj104, huggingface:code_x_glue_cc_cloze_testing_all, huggingface:code_x_glue_cc_cloze_testing_maxmin, huggingface:code_x_glue_cc_code_completion_line, huggingface:code_x_glue_cc_code_completion_token, huggingface:code_x_glue_cc_code_refinement, huggingface:code_x_glue_cc_code_to_code_trans, huggingface:code_x_glue_cc_defect_detection, huggingface:code_x_glue_ct_code_to_text, huggingface:code_x_glue_tc_nl_code_search_adv, huggingface:code_x_glue_tc_text_to_code, huggingface:code_x_glue_tt_text_to_text, huggingface:com_qa, huggingface:common_gen, huggingface:common_language, huggingface:common_voice, huggingface:commonsense_qa, huggingface:competition_math, huggingface:compguesswhat, huggingface:conceptnet5, huggingface:conceptual_12m, huggingface:conceptual_captions, huggingface:conll2000, huggingface:conll2002, huggingface:conll2003, huggingface:conll2012_ontonotesv5, huggingface:conllpp, huggingface:consumer-finance-complaints, huggingface:conv_ai, huggingface:conv_ai_2, huggingface:conv_ai_3, huggingface:conv_questions, huggingface:coqa, huggingface:cord19, huggingface:cornell_movie_dialog, huggingface:cos_e, huggingface:cosmos_qa, huggingface:counter, huggingface:covid_qa_castorini, huggingface:covid_qa_deepset, huggingface:covid_qa_ucsd, huggingface:covid_tweets_japanese, huggingface:covost2, huggingface:cppe-5, huggingface:craigslist_bargains, huggingface:crawl_domain, huggingface:crd3, huggingface:crime_and_punish, huggingface:crows_pairs, huggingface:cryptonite, huggingface:cs_restaurants, huggingface:cuad, huggingface:curiosity_dialogs, huggingface:daily_dialog, huggingface:dane, huggingface:danish_political_comments, huggingface:dart, huggingface:datacommons_factcheck, huggingface:dbpedia_14, huggingface:dbrd, huggingface:deal_or_no_dialog, huggingface:definite_pronoun_resolution, huggingface:dengue_filipino, huggingface:dialog_re, huggingface:diplomacy_detection, huggingface:disaster_response_messages, huggingface:discofuse, huggingface:discovery, huggingface:disfl_qa, huggingface:doc2dial, huggingface:docred, huggingface:doqa, huggingface:dream, huggingface:drop, huggingface:duorc, huggingface:dutch_social, huggingface:dyk, huggingface:e2e_nlg, huggingface:e2e_nlg_cleaned, huggingface:ecb, huggingface:ecthr_cases, huggingface:eduge, huggingface:ehealth_kd, huggingface:eitb_parcc, huggingface:electricity_load_diagrams, huggingface:eli5, huggingface:eli5_category, huggingface:elkarhizketak, huggingface:emea, huggingface:emo, huggingface:emotion, huggingface:emotone_ar, huggingface:empathetic_dialogues, huggingface:enriched_web_nlg, huggingface:enwik8, huggingface:eraser_multi_rc, huggingface:esnli, huggingface:eth_py150_open, huggingface:ethos, huggingface:ett, huggingface:eu_regulatory_ir, huggingface:eurlex, huggingface:euronews, huggingface:europa_eac_tm, huggingface:europa_ecdc_tm, huggingface:europarl_bilingual, huggingface:event2Mind, huggingface:evidence_infer_treatment, huggingface:exams, huggingface:factckbr, huggingface:fake_news_english, huggingface:fake_news_filipino, huggingface:farsi_news, huggingface:fashion_mnist, huggingface:fever, huggingface:few_rel, huggingface:financial_phrasebank, huggingface:finer, huggingface:flores, huggingface:flue, huggingface:food101, huggingface:fquad, huggingface:freebase_qa, huggingface:gap, huggingface:gem, huggingface:generated_reviews_enth, huggingface:generics_kb, huggingface:german_legal_entity_recognition, huggingface:germaner, huggingface:germeval_14, huggingface:giga_fren, huggingface:gigaword, huggingface:glucose, huggingface:glue, huggingface:gnad10, huggingface:go_emotions, huggingface:gooaq, huggingface:google_wellformed_query, huggingface:grail_qa, huggingface:great_code, huggingface:greek_legal_code, huggingface:gsm8k, huggingface:guardian_authorship, huggingface:gutenberg_time, huggingface:hans, huggingface:hansards, huggingface:hard, huggingface:harem, huggingface:has_part, huggingface:hate_offensive, huggingface:hate_speech18, huggingface:hate_speech_filipino, huggingface:hate_speech_offensive, huggingface:hate_speech_pl, huggingface:hate_speech_portuguese, huggingface:hatexplain, huggingface:hausa_voa_ner, huggingface:hausa_voa_topics, huggingface:hda_nli_hindi, huggingface:head_qa, huggingface:health_fact, huggingface:hebrew_projectbenyehuda, huggingface:hebrew_sentiment, huggingface:hebrew_this_world, huggingface:hellaswag, huggingface:hendrycks_test, huggingface:hind_encorp, huggingface:hindi_discourse, huggingface:hippocorpus, huggingface:hkcancor, huggingface:hlgd, huggingface:hope_edi, huggingface:hotpot_qa, huggingface:hover, huggingface:hrenwac_para, huggingface:hrwac, huggingface:humicroedit, huggingface:hybrid_qa, huggingface:hyperpartisan_news_detection, huggingface:iapp_wiki_qa_squad, huggingface:id_clickbait, huggingface:id_liputan6, huggingface:id_nergrit_corpus, huggingface:id_newspapers_2018, huggingface:id_panl_bppt, huggingface:id_puisi, huggingface:igbo_english_machine_translation, huggingface:igbo_monolingual, huggingface:igbo_ner, huggingface:ilist, huggingface:imagenet-1k, huggingface:imagenet_sketch, huggingface:imdb, huggingface:imdb_urdu_reviews, huggingface:imppres, huggingface:indic_glue, huggingface:indonli, huggingface:indonlu, huggingface:inquisitive_qg, huggingface:interpress_news_category_tr, huggingface:interpress_news_category_tr_lite, huggingface:irc_disentangle, huggingface:isixhosa_ner_corpus, huggingface:isizulu_ner_corpus, huggingface:iwslt2017, huggingface:jeopardy, huggingface:jfleg, huggingface:jigsaw_toxicity_pred, huggingface:jigsaw_unintended_bias, huggingface:jnlpba, huggingface:journalists_questions, huggingface:kan_hope, huggingface:kannada_news, huggingface:kd_conv, huggingface:kde4, huggingface:kelm, huggingface:kilt_tasks, huggingface:kilt_wikipedia, huggingface:kinnews_kirnews, huggingface:klue, huggingface:kor_3i4k, huggingface:kor_hate, huggingface:kor_ner, huggingface:kor_nli, huggingface:kor_nlu, huggingface:kor_qpair, huggingface:kor_sae, huggingface:kor_sarcasm, huggingface:labr, huggingface:lama, huggingface:lambada, huggingface:large_spanish_corpus, huggingface:laroseda, huggingface:lc_quad, huggingface:lccc, huggingface:lener_br, huggingface:lex_glue, huggingface:liar, huggingface:librispeech_asr, huggingface:librispeech_lm, huggingface:limit, huggingface:lince, huggingface:linnaeus, huggingface:liveqa, huggingface:lj_speech, huggingface:lm1b, huggingface:lst20, huggingface:m_lama, huggingface:mac_morpho, huggingface:makhzan, huggingface:masakhaner, huggingface:math_dataset, huggingface:math_qa, huggingface:matinf, huggingface:mbpp, huggingface:mc4, huggingface:mc_taco, huggingface:md_gender_bias, huggingface:mdd, huggingface:med_hop, huggingface:medal, huggingface:medical_dialog, huggingface:medical_questions_pairs, huggingface:medmcqa, huggingface:menyo20k_mt, huggingface:meta_woz, huggingface:metashift, huggingface:metooma, huggingface:metrec, huggingface:miam, huggingface:mkb, huggingface:mkqa, huggingface:mlqa, huggingface:mlsum, huggingface:mnist, huggingface:mocha, huggingface:monash_tsf, huggingface:moroco, huggingface:movie_rationales, huggingface:mrqa, huggingface:ms_marco, huggingface:ms_terms, huggingface:msr_genomics_kbcomp, huggingface:msr_sqa, huggingface:msr_text_compression, huggingface:msr_zhen_translation_parity, huggingface:msra_ner, huggingface:mt_eng_vietnamese, huggingface:muchocine, huggingface:multi_booked, huggingface:multi_eurlex, huggingface:multi_news, huggingface:multi_nli, huggingface:multi_nli_mismatch, huggingface:multi_para_crawl, huggingface:multi_re_qa, huggingface:multi_woz_v22, huggingface:multi_x_science_sum, huggingface:multidoc2dial, huggingface:multilingual_librispeech, huggingface:mutual_friends, huggingface:mwsc, huggingface:myanmar_news, huggingface:narrativeqa, huggingface:narrativeqa_manual, huggingface:natural_questions, huggingface:ncbi_disease, huggingface:nchlt, huggingface:ncslgr, huggingface:nell, huggingface:neural_code_search, huggingface:news_commentary, huggingface:newsgroup, huggingface:newsph, huggingface:newsph_nli, huggingface:newspop, huggingface:newsqa, huggingface:newsroom, huggingface:nkjp-ner, huggingface:nli_tr, huggingface:nlu_evaluation_data, huggingface:norec, huggingface:norne, huggingface:norwegian_ner, huggingface:nq_open, huggingface:nsmc, huggingface:numer_sense, huggingface:numeric_fused_head, huggingface:oclar, huggingface:offcombr, huggingface:offenseval2020_tr, huggingface:offenseval_dravidian, huggingface:ofis_publik, huggingface:ohsumed, huggingface:ollie, huggingface:omp, huggingface:onestop_english, huggingface:onestop_qa, huggingface:open_subtitles, huggingface:openai_humaneval, huggingface:openbookqa, huggingface:openslr, huggingface:openwebtext, huggingface:opinosis, huggingface:opus100, huggingface:opus_books, huggingface:opus_dgt, huggingface:opus_dogc, huggingface:opus_elhuyar, huggingface:opus_euconst, huggingface:opus_finlex, huggingface:opus_fiskmo, huggingface:opus_gnome, huggingface:opus_infopankki, huggingface:opus_memat, huggingface:opus_montenegrinsubs, huggingface:opus_openoffice, huggingface:opus_paracrawl, huggingface:opus_rf, huggingface:opus_tedtalks, huggingface:opus_ubuntu, huggingface:opus_wikipedia, huggingface:opus_xhosanavy, huggingface:orange_sum, huggingface:oscar, huggingface:para_crawl, huggingface:para_pat, huggingface:parsinlu_reading_comprehension, huggingface:pass, huggingface:paws, huggingface:paws-x, huggingface:pec, huggingface:peer_read, huggingface:peoples_daily_ner, huggingface:per_sent, huggingface:persian_ner, huggingface:pg19, huggingface:php, huggingface:piaf, huggingface:pib, huggingface:piqa, huggingface:pn_summary, huggingface:poem_sentiment, huggingface:polemo2, huggingface:poleval2019_cyberbullying, huggingface:poleval2019_mt, huggingface:polsum, huggingface:polyglot_ner, huggingface:prachathai67k, huggingface:pragmeval, huggingface:proto_qa, huggingface:psc, huggingface:ptb_text_only, huggingface:pubmed, huggingface:pubmed_qa, huggingface:py_ast, huggingface:qa4mre, huggingface:qa_srl, huggingface:qa_zre, huggingface:qangaroo, huggingface:qanta, huggingface:qasc, huggingface:qasper, huggingface:qed, huggingface:qed_amara, huggingface:quac, huggingface:quail, huggingface:quarel, huggingface:quartz, huggingface:quickdraw, huggingface:quora, huggingface:quoref, huggingface:race, huggingface:re_dial, huggingface:reasoning_bg, huggingface:recipe_nlg, huggingface:reclor, huggingface:red_caps, huggingface:reddit, huggingface:reddit_tifu, huggingface:refresd, huggingface:reuters21578, huggingface:riddle_sense, huggingface:ro_sent, huggingface:ro_sts, huggingface:ro_sts_parallel, huggingface:roman_urdu, huggingface:roman_urdu_hate_speech, huggingface:ronec, huggingface:ropes, huggingface:rotten_tomatoes, huggingface:russian_super_glue, huggingface:rvl_cdip, huggingface:s2orc, huggingface:samsum, huggingface:sanskrit_classic, huggingface:saudinewsnet, huggingface:sberquad, huggingface:sbu_captions, huggingface:scan, huggingface:scb_mt_enth_2020, huggingface:scene_parse_150, huggingface:schema_guided_dstc8, huggingface:scicite, huggingface:scielo, huggingface:scientific_papers, huggingface:scifact, huggingface:sciq, huggingface:scitail, huggingface:scitldr, huggingface:search_qa, huggingface:sede, huggingface:selqa, huggingface:sem_eval_2010_task_8, huggingface:sem_eval_2014_task_1, huggingface:sem_eval_2018_task_1, huggingface:sem_eval_2020_task_11, huggingface:sent_comp, huggingface:senti_lex, huggingface:senti_ws, huggingface:sentiment140, huggingface:sepedi_ner, huggingface:sesotho_ner_corpus, huggingface:setimes, huggingface:setswana_ner_corpus, huggingface:sharc, huggingface:sharc_modified, huggingface:sick, huggingface:silicone, huggingface:simple_questions_v2, huggingface:siswati_ner_corpus, huggingface:smartdata, huggingface:sms_spam, huggingface:snips_built_in_intents, huggingface:snli, huggingface:snow_simplified_japanese_corpus, huggingface:so_stacksample, huggingface:social_bias_frames, huggingface:social_i_qa, huggingface:sofc_materials_articles, huggingface:sogou_news, huggingface:spanish_billion_words, huggingface:spc, huggingface:species_800, huggingface:speech_commands, huggingface:spider, huggingface:squad, huggingface:squad_adversarial, huggingface:squad_es, huggingface:squad_it, huggingface:squad_kor_v1, huggingface:squad_kor_v2, huggingface:squad_v1_pt, huggingface:squad_v2, huggingface:squadshifts, huggingface:srwac, huggingface:sst, huggingface:stereoset, huggingface:story_cloze, huggingface:stsb_mt_sv, huggingface:stsb_multi_mt, huggingface:style_change_detection, huggingface:subjqa, huggingface:super_glue, huggingface:superb, huggingface:svhn, huggingface:swag, huggingface:swahili, huggingface:swahili_news, huggingface:swda, huggingface:swedish_medical_ner, huggingface:swedish_ner_corpus, huggingface:swedish_reviews, huggingface:swiss_judgment_prediction, huggingface:tab_fact, huggingface:tamilmixsentiment, huggingface:tanzil, huggingface:tapaco, huggingface:tashkeela, huggingface:taskmaster1, huggingface:taskmaster2, huggingface:taskmaster3, huggingface:tatoeba, huggingface:ted_hrlr, huggingface:ted_iwlst2013, huggingface:ted_multi, huggingface:ted_talks_iwslt, huggingface:telugu_books, huggingface:telugu_news, huggingface:tep_en_fa_para, huggingface:text2log, huggingface:textvqa, huggingface:thai_toxicity_tweet, huggingface:thainer, huggingface:thaiqa_squad, huggingface:thaisum, huggingface:the_pile, huggingface:the_pile_books3, huggingface:the_pile_openwebtext2, huggingface:the_pile_stack_exchange, huggingface:tilde_model, huggingface:time_dial, huggingface:times_of_india_news_headlines, huggingface:timit_asr, huggingface:tiny_shakespeare, huggingface:tlc, huggingface:tmu_gfm_dataset, huggingface:tne, huggingface:told-br, huggingface:totto, huggingface:trec, huggingface:trivia_qa, huggingface:truthful_qa, huggingface:tsac, huggingface:ttc4900, huggingface:tunizi, huggingface:tuple_ie, huggingface:turk, huggingface:turkic_xwmt, huggingface:turkish_movie_sentiment, huggingface:turkish_ner, huggingface:turkish_product_reviews, huggingface:turkish_shrinked_ner, huggingface:turku_ner_corpus, huggingface:tweet_eval, huggingface:tweet_qa, huggingface:tweets_ar_en_parallel, huggingface:tweets_hate_speech_detection, huggingface:twi_text_c3, huggingface:twi_wordsim353, huggingface:tydiqa, huggingface:ubuntu_dialogs_corpus, huggingface:udhr, huggingface:um005, huggingface:un_ga, huggingface:un_multi, huggingface:un_pc, huggingface:universal_dependencies, huggingface:universal_morphologies, huggingface:urdu_fake_news, huggingface:urdu_sentiment_corpus, huggingface:vctk, huggingface:visual_genome, huggingface:vivos, huggingface:web_nlg, huggingface:web_of_science, huggingface:web_questions, huggingface:weibo_ner, huggingface:wi_locness, huggingface:wider_face, huggingface:wiki40b, huggingface:wiki_asp, huggingface:wiki_atomic_edits, huggingface:wiki_auto, huggingface:wiki_bio, huggingface:wiki_dpr, huggingface:wiki_hop, huggingface:wiki_lingua, huggingface:wiki_movies, huggingface:wiki_qa, huggingface:wiki_qa_ar, huggingface:wiki_snippets, huggingface:wiki_source, huggingface:wiki_split, huggingface:wiki_summary, huggingface:wikiann, huggingface:wikicorpus, huggingface:wikihow, huggingface:wikipedia, huggingface:wikisql, huggingface:wikitablequestions, huggingface:wikitext, huggingface:wikitext_tl39, huggingface:wili_2018, huggingface:wino_bias, huggingface:winograd_wsc, huggingface:winogrande, huggingface:wiqa, huggingface:wisesight1000, huggingface:wisesight_sentiment, huggingface:wmt14, huggingface:wmt15, huggingface:wmt16, huggingface:wmt17, huggingface:wmt18, huggingface:wmt19, huggingface:wmt20_mlqe_task1, huggingface:wmt20_mlqe_task2, huggingface:wmt20_mlqe_task3, huggingface:wmt_t2t, huggingface:wnut_17, huggingface:wongnai_reviews, huggingface:woz_dialogue, huggingface:wrbsc, huggingface:x_stance, huggingface:xcopa, huggingface:xcsr, huggingface:xed_en_fi, huggingface:xglue, huggingface:xnli, huggingface:xor_tydi_qa, huggingface:xquad, huggingface:xquad_r, huggingface:xsum, huggingface:xsum_factuality, huggingface:xtreme, huggingface:yahoo_answers_qa, huggingface:yahoo_answers_topics, huggingface:yelp_polarity, huggingface:yelp_review_full, huggingface:yoruba_bbc_topics, huggingface:yoruba_gv_ner, huggingface:yoruba_text_c3, huggingface:yoruba_wordsim353, huggingface:youtube_caption_corrections, huggingface:zest, kubric:kubric_frames, kubric:movi_a, kubric:movi_b, kubric:movi_c, kubric:movi_d, kubric:movi_e, kubric:movi_f, kubric:msn_easy_frames, kubric:multi_shapenet_frames, kubric:nerf_synthetic_frames, kubric:nerf_synthetic_scenes, kubric:shapenet_pretraining, robotics:language_table, robotics:language_table_blocktoabsolute_oracle_sim, robotics:language_table_blocktoblock_4block_sim, robotics:language_table_blocktoblock_oracle_sim, robotics:language_table_blocktoblock_sim, robotics:language_table_blocktoblockrelative_oracle_sim, robotics:language_table_blocktorelative_oracle_sim, robotics:language_table_separate_oracle_sim, robotics:language_table_sim, robotics:mt_opt_rlds, robotics:mt_opt_sd'"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example from https://subscription.packtpub.com/book/data/9781800200937/2/ch02lvl1sec09/bi-directional-lstms-bilstms\n",
    "# !pip install tensorflow_datasets\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import numpy as np\n",
    "\n",
    "# datasets in different domains such as images, audio, video, text, summarization, and so on.\n",
    "\", \".join(tfds.list_builders())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n",
      "tfds.core.DatasetInfo(\n",
      "    name='imdb_reviews',\n",
      "    full_name='imdb_reviews/plain_text/1.0.0',\n",
      "    description=\"\"\"\n",
      "    Large Movie Review Dataset. This is a dataset for binary sentiment\n",
      "    classification containing substantially more data than previous benchmark\n",
      "    datasets. We provide a set of 25,000 highly polar movie reviews for training,\n",
      "    and 25,000 for testing. There is additional unlabeled data for use as well.\n",
      "    \"\"\",\n",
      "    config_description=\"\"\"\n",
      "    Plain text\n",
      "    \"\"\",\n",
      "    homepage='http://ai.stanford.edu/~amaas/data/sentiment/',\n",
      "    data_path='/Users/kkepins-macwro_1/tensorflow_datasets/imdb_reviews/plain_text/1.0.0',\n",
      "    file_format=tfrecord,\n",
      "    download_size=80.23 MiB,\n",
      "    dataset_size=129.83 MiB,\n",
      "    features=FeaturesDict({\n",
      "        'label': ClassLabel(shape=(), dtype=int64, num_classes=2),\n",
      "        'text': Text(shape=(), dtype=string),\n",
      "    }),\n",
      "    supervised_keys=('text', 'label'),\n",
      "    disable_shuffling=False,\n",
      "    splits={\n",
      "        'test': <SplitInfo num_examples=25000, num_shards=1>,\n",
      "        'train': <SplitInfo num_examples=25000, num_shards=1>,\n",
      "        'unsupervised': <SplitInfo num_examples=50000, num_shards=1>,\n",
      "    },\n",
      "    citation=\"\"\"@InProceedings{maas-EtAl:2011:ACL-HLT2011,\n",
      "      author    = {Maas, Andrew L.  and  Daly, Raymond E.  and  Pham, Peter T.  and  Huang, Dan  and  Ng, Andrew Y.  and  Potts, Christopher},\n",
      "      title     = {Learning Word Vectors for Sentiment Analysis},\n",
      "      booktitle = {Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies},\n",
      "      month     = {June},\n",
      "      year      = {2011},\n",
      "      address   = {Portland, Oregon, USA},\n",
      "      publisher = {Association for Computational Linguistics},\n",
      "      pages     = {142--150},\n",
      "      url       = {http://www.aclweb.org/anthology/P11-1015}\n",
      "    }\"\"\",\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-07 17:14:32.962976: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-02-07 17:14:32.963794: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "imdb_train, ds_info = tfds.load(name=\"imdb_reviews\", split=\"train\",\n",
    "                                with_info=True, as_supervised=True)\n",
    "imdb_test = tfds.load(name=\"imdb_reviews\", split=\"test\",\n",
    "                      as_supervised=True)\n",
    "\n",
    "print(ds_info)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(b\"This was an absolutely terrible movie. Don't be lured in by Christopher Walken or Michael Ironside. Both are great actors, but this must simply be their worst role in history. Even their great acting could not redeem this movie's ridiculous storyline. This movie is an early nineties US propaganda piece. The most pathetic scenes were those when the Columbian rebels were making their cases for revolutions. Maria Conchita Alonso appeared phony, and her pseudo-love affair with Walken was nothing but a pathetic emotional plug in a movie that was devoid of any real meaning. I am disappointed that there are movies like this, ruining actor's like Christopher Walken's good name. I could barely sit through it.\", shape=(), dtype=string) \n",
      " tf.Tensor(0, shape=(), dtype=int64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-07 17:14:36.110198: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2023-02-07 17:14:36.151701: W tensorflow/core/kernels/data/cache_dataset_ops.cc:856] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    }
   ],
   "source": [
    "for example, label in imdb_train.take(1):\n",
    "    print(example, '\\n', label)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93931 2525\n"
     ]
    }
   ],
   "source": [
    "# Normalization and vectorization\n",
    "\n",
    "tokenizer = tfds.deprecated.text.Tokenizer()\n",
    "vocabulary_set = set()\n",
    "MAX_TOKENS = 0\n",
    "for example, label in imdb_train:\n",
    "    some_tokens = tokenizer.tokenize(example.numpy())\n",
    "    if MAX_TOKENS < len(some_tokens):\n",
    "        MAX_TOKENS = len(some_tokens)\n",
    "    vocabulary_set.update(some_tokens)\n",
    "\n",
    "imdb_encoder = tfds.deprecated.text.TokenTextEncoder(vocabulary_set, tokenizer=tokenizer)\n",
    "vocab_size = imdb_encoder.vocab_size\n",
    "print(vocab_size, MAX_TOKENS)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(b\"This was an absolutely terrible movie. Don't be lured in by Christopher Walken or Michael Ironside. Both are great actors, but this must simply be their worst role in history. Even their great acting could not redeem this movie's ridiculous storyline. This movie is an early nineties US propaganda piece. The most pathetic scenes were those when the Columbian rebels were making their cases for revolutions. Maria Conchita Alonso appeared phony, and her pseudo-love affair with Walken was nothing but a pathetic emotional plug in a movie that was devoid of any real meaning. I am disappointed that there are movies like this, ruining actor's like Christopher Walken's good name. I could barely sit through it.\", shape=(), dtype=string)\n",
      "This was an absolutely terrible movie Don t be lured in by Christopher Walken or Michael Ironside Both are great actors but this must simply be their worst role in history Even their great acting could not redeem this movie s ridiculous storyline This movie is an early nineties US propaganda piece The most pathetic scenes were those when the Columbian rebels were making their cases for revolutions Maria Conchita Alonso appeared phony and her pseudo love affair with Walken was nothing but a pathetic emotional plug in a movie that was devoid of any real meaning I am disappointed that there are movies like this ruining actor s like Christopher Walken s good name I could barely sit through it\n"
     ]
    }
   ],
   "source": [
    "for example, label in imdb_train.take(1):\n",
    "    print(example)\n",
    "    encoded = imdb_encoder.encode(example.numpy())\n",
    "    print(imdb_encoder.decode(encoded))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "'Good case Excellent value'"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_encoder.save_to_file(\"imdb_reviews_vocab\")\n",
    "\n",
    "enc = tfds.deprecated.text.TokenTextEncoder.load_from_file(\"imdb_reviews_vocab\")\n",
    "enc.decode(enc.encode(\"Good case. Excellent value.\"))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[24828 52509 91146 33056 76933 43743 89760 17462 40811   157 43654 18681\n",
      " 64533 30881 45538 70976 29743 46232 37012 80432   109 64064 39837 47785\n",
      " 76726 40811 76153 19654 48328 43654 84908 12953 76153 80432 65773 92389\n",
      " 69454 84734 39837 43743 68337 48754 75445 24828 43743 28313 91146 12918\n",
      "  9229  8799 26990 34201 18917 29600 19443 13767 42369 88431 80360 87848\n",
      " 41606 47793 42369 60067 76153 63873 38753 85413 40248 68733 60041 57835\n",
      " 91054 26081 41091 82365 84520 20591 19253 30881 52509 89193 64064 51726\n",
      " 19443 74004 53542 43654 51726 43743 34912 52509 36574 27524 77984 81633\n",
      " 36281 30426 78686 19260 34912 33659 37012 63558 26101 39837 39840 31573\n",
      " 68337 26101 64533 30881 68337 24656 28819 30426 92389 32968  3090 16611\n",
      " 37068     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0], shape=(150,), dtype=int64) tf.Tensor(0, shape=(), dtype=int64)\n",
      "This was an absolutely terrible movie Don t be lured in by Christopher Walken or Michael Ironside Both are great actors but this must simply be their worst role in history Even their great acting could not redeem this movie s ridiculous storyline This movie is an early nineties US propaganda piece The most pathetic scenes were those when the Columbian rebels were making their cases for revolutions Maria Conchita Alonso appeared phony and her pseudo love affair with Walken was nothing but a pathetic emotional plug in a movie that was devoid of any real meaning I am disappointed that there are movies like this ruining actor s like Christopher Walken s good name I could barely sit through it\n"
     ]
    }
   ],
   "source": [
    "# Tokenization: Reviews need to be tokenized into words.\n",
    "# Encoding: These words need to be mapped to integers using the vocabulary.\n",
    "# Padding: Reviews can have variable lengths, but LSTMs expect vectors of the same length. So, a constant length is chosen. Reviews shorter than this length are padded with a specific vocabulary index, usually 0 in TensorFlow. Reviews longer than this length are truncated. Fortunately, TensorFlow provides such a function out of the box.\n",
    "# Padding is an important step as different layers in TensorFlow cannot handle tensors of different widths. Tensors of different widths are called ragged tensors. There is ongoing work to incorporate support for ragged tensors and the support is improving. However, the support for ragged tensors is not universal in TensorFlow. Consequently, ragged tensors are avoided in this text.\n",
    "#\n",
    "def encode_pad_transform(sample):\n",
    "    encoded = imdb_encoder.encode(sample.numpy())\n",
    "    pad = tf.keras.preprocessing.sequence.pad_sequences([encoded], padding='post',\n",
    "                                 maxlen=150)\n",
    "    return np.array(pad[0], dtype=np.int64)\n",
    "\n",
    "def encode_tf_fn(sample, label):\n",
    "    encoded = tf.py_function(encode_pad_transform,\n",
    "                             inp=[sample],\n",
    "                             Tout=(tf.int64))\n",
    "    encoded.set_shape([None])\n",
    "    label.set_shape([])\n",
    "    return encoded, label\n",
    "\n",
    "subset = imdb_train.take(10)\n",
    "tst = subset.map(encode_tf_fn)\n",
    "for review, label in tst.take(1):\n",
    "    print(review, label)\n",
    "    print(imdb_encoder.decode(review))\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "<ParallelMapDataset element_spec=(TensorSpec(shape=(None,), dtype=tf.int64, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None))>"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Passing the additional parameter enables TensorFlow to use multiple subprocesses to execute the transformation on.\n",
    "encoded_train = imdb_train.map(encode_tf_fn, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "encoded_test = imdb_test.map(encode_tf_fn, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "vocab_size = imdb_encoder.vocab_size\n",
    "# The embedding dimension\n",
    "embedding_dim = 64\n",
    "# Number of RNN units\n",
    "rnn_units = 64\n",
    "# batch size\n",
    "BATCH_SIZE=100\n",
    "\n",
    "encoded_train"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_6 (Embedding)     (100, None, 64)           6011584   \n",
      "                                                                 \n",
      " lstm_6 (LSTM)               (100, 64)                 33024     \n",
      "                                                                 \n",
      " dense_6 (Dense)             (100, 1)                  65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,044,673\n",
      "Trainable params: 6,044,673\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-06 18:16:03.552865: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-02-06 18:16:03.930593: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-02-06 18:16:04.572778: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 58s 217ms/step - loss: 0.4511 - accuracy: 0.7718 - precision: 0.7647 - recall: 0.7853\n",
      "Epoch 2/5\n",
      "250/250 [==============================] - 52s 209ms/step - loss: 0.1981 - accuracy: 0.9264 - precision: 0.9252 - recall: 0.9278\n",
      "Epoch 3/5\n",
      "250/250 [==============================] - 52s 206ms/step - loss: 0.1542 - accuracy: 0.9515 - precision: 0.9532 - recall: 0.9497\n",
      "Epoch 4/5\n",
      "250/250 [==============================] - 48s 193ms/step - loss: 0.1327 - accuracy: 0.9592 - precision: 0.9585 - recall: 0.9601\n",
      "Epoch 5/5\n",
      "250/250 [==============================] - 53s 211ms/step - loss: 0.0788 - accuracy: 0.9776 - precision: 0.9771 - recall: 0.9781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-06 18:20:24.612019: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-02-06 18:20:24.875329: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 35s 136ms/step - loss: 0.7079 - accuracy: 0.8347 - precision: 0.8037 - recall: 0.8856\n",
      "--- 298.0240819454193 seconds ---\n"
     ]
    }
   ],
   "source": [
    "# LSTM\n",
    "\n",
    "import time\n",
    "\n",
    "def build_model_lstm(vocab_size, embedding_dim, rnn_units, batch_size):\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Embedding(vocab_size, embedding_dim, mask_zero=True,\n",
    "                                  batch_input_shape=[batch_size, None]),\n",
    "        tf.keras.layers.LSTM(rnn_units),\n",
    "        tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "lstm = build_model_lstm(\n",
    "    vocab_size = vocab_size,\n",
    "    embedding_dim=embedding_dim,\n",
    "    rnn_units=rnn_units,\n",
    "    batch_size=BATCH_SIZE)\n",
    "# model.summary()\n",
    "\n",
    "lstm.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy', 'Precision', 'Recall'])\n",
    "encoded_train_batched = encoded_train.batch(BATCH_SIZE)\n",
    "lstm.fit(encoded_train_batched, epochs=5)\n",
    "\n",
    "lstm.evaluate(encoded_test.batch(BATCH_SIZE))\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-06 18:21:23.711660: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-02-06 18:21:24.340516: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-02-06 18:21:24.457537: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-02-06 18:21:25.561455: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-02-06 18:21:26.057922: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 98s 351ms/step - loss: 0.4961 - accuracy: 0.7458 - precision: 0.7369 - recall: 0.7646\n",
      "Epoch 2/5\n",
      "250/250 [==============================] - 83s 331ms/step - loss: 0.2268 - accuracy: 0.9171 - precision: 0.9218 - recall: 0.9116\n",
      "Epoch 3/5\n",
      "250/250 [==============================] - 78s 308ms/step - loss: 0.1349 - accuracy: 0.9593 - precision: 0.9603 - recall: 0.9582\n",
      "Epoch 4/5\n",
      "250/250 [==============================] - 89s 354ms/step - loss: 0.1027 - accuracy: 0.9693 - precision: 0.9704 - recall: 0.9682\n",
      "Epoch 5/5\n",
      "250/250 [==============================] - 81s 326ms/step - loss: 0.0723 - accuracy: 0.9814 - precision: 0.9801 - recall: 0.9828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-06 18:28:28.847520: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-02-06 18:28:29.142422: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-02-06 18:28:29.215667: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 46s 174ms/step - loss: 0.7695 - accuracy: 0.8192 - precision: 0.7826 - recall: 0.8838\n",
      "--- 476.38784313201904 seconds ---\n",
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_8 (Embedding)     (100, None, 64)           6011584   \n",
      "                                                                 \n",
      " bidirectional_4 (Bidirectio  (100, 128)               66048     \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dense_8 (Dense)             (100, 1)                  129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,077,761\n",
      "Trainable params: 6,077,761\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-06 18:29:16.739129: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-02-06 18:29:17.317620: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-02-06 18:29:17.422944: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-02-06 18:29:18.443949: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-02-06 18:29:18.534564: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 78s 289ms/step - loss: 0.4522 - accuracy: 0.7702 - precision: 0.7606 - recall: 0.7886\n",
      "Epoch 2/5\n",
      "250/250 [==============================] - 70s 280ms/step - loss: 0.1914 - accuracy: 0.9290 - precision: 0.9280 - recall: 0.9302\n",
      "Epoch 3/5\n",
      "250/250 [==============================] - 70s 280ms/step - loss: 0.1161 - accuracy: 0.9651 - precision: 0.9650 - recall: 0.9653\n",
      "Epoch 4/5\n",
      "250/250 [==============================] - 103s 412ms/step - loss: 0.1033 - accuracy: 0.9682 - precision: 0.9697 - recall: 0.9667\n",
      "Epoch 5/5\n",
      "250/250 [==============================] - 82s 329ms/step - loss: 0.0841 - accuracy: 0.9768 - precision: 0.9769 - recall: 0.9766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-06 18:35:58.487153: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-02-06 18:35:58.802715: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-02-06 18:35:58.883676: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 44s 165ms/step - loss: 0.5229 - accuracy: 0.8208 - precision: 0.7669 - recall: 0.9220\n",
      "--- 447.8993580341339 seconds ---\n"
     ]
    }
   ],
   "source": [
    "# BiLSTM model\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "def build_model_bilstm(vocab_size, embedding_dim, rnn_units, batch_size):\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Embedding(vocab_size, embedding_dim,\n",
    "                                  mask_zero=True,\n",
    "                                  batch_input_shape=[batch_size, None]),\n",
    "        tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(rnn_units)),\n",
    "        tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "bilstm = build_model_bilstm(\n",
    "    vocab_size = vocab_size,\n",
    "    embedding_dim=embedding_dim,\n",
    "    rnn_units=rnn_units,\n",
    "    batch_size=BATCH_SIZE)\n",
    "# bilstm.summary()\n",
    "\n",
    "bilstm.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy', 'Precision', 'Recall'])\n",
    "encoded_train_batched = encoded_train.batch(BATCH_SIZE)\n",
    "\n",
    "bilstm.fit(encoded_train_batched, epochs=5)\n",
    "\n",
    "bilstm.evaluate(encoded_test.batch(BATCH_SIZE))\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/Users/kkepins-macwro_1/.local/share/virtualenvs/data-science-upskills-eseJr18D/lib/python3.10/site-packages/keras/engine/training.py\", line 1160, in train_function  *\n        return step_function(self, iterator)\n    File \"/Users/kkepins-macwro_1/.local/share/virtualenvs/data-science-upskills-eseJr18D/lib/python3.10/site-packages/keras/engine/training.py\", line 1146, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/kkepins-macwro_1/.local/share/virtualenvs/data-science-upskills-eseJr18D/lib/python3.10/site-packages/keras/engine/training.py\", line 1135, in run_step  **\n        outputs = model.train_step(data)\n    File \"/Users/kkepins-macwro_1/.local/share/virtualenvs/data-science-upskills-eseJr18D/lib/python3.10/site-packages/keras/engine/training.py\", line 994, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/Users/kkepins-macwro_1/.local/share/virtualenvs/data-science-upskills-eseJr18D/lib/python3.10/site-packages/keras/engine/training.py\", line 1052, in compute_loss\n        return self.compiled_loss(\n    File \"/Users/kkepins-macwro_1/.local/share/virtualenvs/data-science-upskills-eseJr18D/lib/python3.10/site-packages/keras/engine/compile_utils.py\", line 265, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/Users/kkepins-macwro_1/.local/share/virtualenvs/data-science-upskills-eseJr18D/lib/python3.10/site-packages/keras/losses.py\", line 152, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"/Users/kkepins-macwro_1/.local/share/virtualenvs/data-science-upskills-eseJr18D/lib/python3.10/site-packages/keras/losses.py\", line 272, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/Users/kkepins-macwro_1/.local/share/virtualenvs/data-science-upskills-eseJr18D/lib/python3.10/site-packages/keras/losses.py\", line 2162, in binary_crossentropy\n        backend.binary_crossentropy(y_true, y_pred, from_logits=from_logits),\n    File \"/Users/kkepins-macwro_1/.local/share/virtualenvs/data-science-upskills-eseJr18D/lib/python3.10/site-packages/keras/backend.py\", line 5677, in binary_crossentropy\n        return tf.nn.sigmoid_cross_entropy_with_logits(\n\n    ValueError: `logits` and `labels` must have the same shape, received ((None, None, 93931) vs (None,)).\n",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[13], line 28\u001B[0m\n\u001B[1;32m     23\u001B[0m gru_model\u001B[38;5;241m.\u001B[39mcompile(loss\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mbinary_crossentropy\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[1;32m     24\u001B[0m                optimizer\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124madam\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[1;32m     25\u001B[0m                metrics\u001B[38;5;241m=\u001B[39m[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124maccuracy\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mPrecision\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mRecall\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[1;32m     26\u001B[0m encoded_train_batched \u001B[38;5;241m=\u001B[39m encoded_train\u001B[38;5;241m.\u001B[39mbatch(BATCH_SIZE)\n\u001B[0;32m---> 28\u001B[0m \u001B[43mgru_model\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mencoded_train_batched\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m5\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m     30\u001B[0m gru_model\u001B[38;5;241m.\u001B[39mevaluate(encoded_test\u001B[38;5;241m.\u001B[39mbatch(BATCH_SIZE))\n\u001B[1;32m     32\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m--- \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m seconds ---\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m (time\u001B[38;5;241m.\u001B[39mtime() \u001B[38;5;241m-\u001B[39m start))\n",
      "File \u001B[0;32m~/.local/share/virtualenvs/data-science-upskills-eseJr18D/lib/python3.10/site-packages/keras/utils/traceback_utils.py:70\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[1;32m     68\u001B[0m     \u001B[38;5;66;03m# To get the full stack trace, call:\u001B[39;00m\n\u001B[1;32m     69\u001B[0m     \u001B[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001B[39;00m\n\u001B[0;32m---> 70\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28mNone\u001B[39m\n\u001B[1;32m     71\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m     72\u001B[0m     \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "File \u001B[0;32m/var/folders/r3/hdngxsmd2vq391vqv6kg6f7w0000gq/T/__autograph_generated_filet3325z82.py:15\u001B[0m, in \u001B[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001B[0;34m(iterator)\u001B[0m\n\u001B[1;32m     13\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m     14\u001B[0m     do_return \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m---> 15\u001B[0m     retval_ \u001B[38;5;241m=\u001B[39m ag__\u001B[38;5;241m.\u001B[39mconverted_call(ag__\u001B[38;5;241m.\u001B[39mld(step_function), (ag__\u001B[38;5;241m.\u001B[39mld(\u001B[38;5;28mself\u001B[39m), ag__\u001B[38;5;241m.\u001B[39mld(iterator)), \u001B[38;5;28;01mNone\u001B[39;00m, fscope)\n\u001B[1;32m     16\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m:\n\u001B[1;32m     17\u001B[0m     do_return \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n",
      "\u001B[0;31mValueError\u001B[0m: in user code:\n\n    File \"/Users/kkepins-macwro_1/.local/share/virtualenvs/data-science-upskills-eseJr18D/lib/python3.10/site-packages/keras/engine/training.py\", line 1160, in train_function  *\n        return step_function(self, iterator)\n    File \"/Users/kkepins-macwro_1/.local/share/virtualenvs/data-science-upskills-eseJr18D/lib/python3.10/site-packages/keras/engine/training.py\", line 1146, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/kkepins-macwro_1/.local/share/virtualenvs/data-science-upskills-eseJr18D/lib/python3.10/site-packages/keras/engine/training.py\", line 1135, in run_step  **\n        outputs = model.train_step(data)\n    File \"/Users/kkepins-macwro_1/.local/share/virtualenvs/data-science-upskills-eseJr18D/lib/python3.10/site-packages/keras/engine/training.py\", line 994, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/Users/kkepins-macwro_1/.local/share/virtualenvs/data-science-upskills-eseJr18D/lib/python3.10/site-packages/keras/engine/training.py\", line 1052, in compute_loss\n        return self.compiled_loss(\n    File \"/Users/kkepins-macwro_1/.local/share/virtualenvs/data-science-upskills-eseJr18D/lib/python3.10/site-packages/keras/engine/compile_utils.py\", line 265, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/Users/kkepins-macwro_1/.local/share/virtualenvs/data-science-upskills-eseJr18D/lib/python3.10/site-packages/keras/losses.py\", line 152, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"/Users/kkepins-macwro_1/.local/share/virtualenvs/data-science-upskills-eseJr18D/lib/python3.10/site-packages/keras/losses.py\", line 272, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/Users/kkepins-macwro_1/.local/share/virtualenvs/data-science-upskills-eseJr18D/lib/python3.10/site-packages/keras/losses.py\", line 2162, in binary_crossentropy\n        backend.binary_crossentropy(y_true, y_pred, from_logits=from_logits),\n    File \"/Users/kkepins-macwro_1/.local/share/virtualenvs/data-science-upskills-eseJr18D/lib/python3.10/site-packages/keras/backend.py\", line 5677, in binary_crossentropy\n        return tf.nn.sigmoid_cross_entropy_with_logits(\n\n    ValueError: `logits` and `labels` must have the same shape, received ((None, None, 93931) vs (None,)).\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import time\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "# text_vectorizer = tf.keras.layers.TextVectorization(\n",
    "#     max_tokens=n_vocab, standardize=None,\n",
    "#     split=None, input_shape=(window_size,)\n",
    "# )\n",
    "# Train the model on existing data\n",
    "# text_vectorizer.adapt(train_ds)\n",
    "gru_model = tf.keras.models.Sequential([\n",
    "    # text_vectorizer,\n",
    "    tf.keras.layers.Embedding(vocab_size+2, 96),\n",
    "    tf.keras.layers.GRU(512, return_sequences=True),\n",
    "    tf.keras.layers.GRU(256, return_sequences=True),\n",
    "    tf.keras.layers.Dense(1024, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(vocab_size, activation='softmax')\n",
    "])\n",
    "\n",
    "\n",
    "gru_model.compile(loss='binary_crossentropy',\n",
    "               optimizer='adam',\n",
    "               metrics=['accuracy', 'Precision', 'Recall'])\n",
    "encoded_train_batched = encoded_train.batch(BATCH_SIZE)\n",
    "\n",
    "gru_model.fit(encoded_train_batched, epochs=5)\n",
    "\n",
    "gru_model.evaluate(encoded_test.batch(BATCH_SIZE))\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
